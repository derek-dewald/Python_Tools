{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83afb64d-e401-46b4-891b-8ca39878e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid search and random search\n",
    "SHAP - Shapley additive explanations\n",
    "Z-Score Normalization\n",
    "\n",
    "Function: Mapping Between Sets.\n",
    "Circle Not a Function. Determinism. \n",
    "\n",
    "Feature crosses - add non linear relationships to linear model\n",
    "\n",
    "Information gain-?\n",
    "Curse of Dimensionality - the sparser the space we have, the more difficult it is to draw confidence in the regression line (4 points vs 400 points in 2d space as example).\n",
    "\n",
    "Build up intuition gradually by slowly building model up.\n",
    "Analyze Errors, does it make the mistakes that it’s making.\n",
    "\n",
    "What is Z-Score Scaling ? \n",
    "Missing Values - ?\n",
    "Logistic Function - sigmoid\n",
    "Logistic Regression - Decision Boundary still in line form. NN become more complex, beyond linear decision boundaries.\n",
    "Logistic Loss\n",
    "\n",
    "Accuracy and Error are dependent on a specific chosen threshold and are not differentiable. \n",
    "\n",
    "Logistic Loss. - differentiable and convex\n",
    "Convexity Good - No matter where you are, you will come to global minimum with following the right direction. \n",
    "\n",
    "Multinominal probability distribution - set of numbers equal to 1. \n",
    "\n",
    "Most Bias Model - Mean. Simple, Generalizes Well. Undercuts.\n",
    "Models have noise, if you overfit the noise, it overfits. Variance.\n",
    "\n",
    "Can perfectly fit n points with Polynomial of N-1. Pure Noise.\n",
    "\n",
    "1. Loss Functions - Define, which exist, why some better.\n",
    "    1. RMSE - Eucilidean \n",
    "    2. MAE - Mahhatten\n",
    "    3. The more variables the more focused on large values and ignoring small one, RMSE more sensitive than MAE\n",
    "    4. OLS - Simple Linear Regression - No Model Complexity, Nothing to Constrain or Limit.\n",
    "2. Normalization of Data\n",
    "    1. What methods are there to normalize data?\n",
    "    2. Can you explain more about L1 and L2 normalization. I do not understand\n",
    "    3. Ridge Regression - L2 Penalty - Encourages all coefficients to be small, limits complexity.\n",
    "    4. Alpha controls - Large Alpha, Big Constraint. Small Alpha, Minimal Constraint.\n",
    "    5. Lasso - L1 Penalty. Minimizes number of features used. Sparse.\n",
    "    6. Elastic Net - Includes both L1 and L2.\n",
    "3. Bell Normal Distribution\n",
    "    1. When data is tail heavy how this impacts performance\n",
    "4. Gradient Boosting Decision Trees\n",
    "5. Memory-enhanced Test Driver (MTD(f))\n",
    "6. Data snooping bias \n",
    "    1. occurs when a dataset is used repeatedly during model selection, training, and evaluation, leading to overfitting and overly optimistic performance estimates. This happens because the model may inadvertently learn patterns that are specific to the data it has already seen, rather than general trends that apply to new, unseen data. As a result, the model appears to perform well on the training or validation data but may perform poorly on new, unseen data, as it has been tuned to fit noise or anomalies in the initial dataset. To avoid data snooping bias, it's important to use proper techniques such as train-test splits, cross-validation, and ensuring the model is evaluated on data that hasn't influenced its development.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a675f66-6015-4f60-a577-ac9aea7c7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "An \"autoencoder learning framework for multivariate distributional forecasting\" is a complex concept combining aspects of machine learning, specifically neural networks, and statistical forecasting. Here's a breakdown of what it means:\n",
    "1. Autoencoder:\n",
    "    * An autoencoder is a type of artificial neural network used to learn efficient representations of data, typically for the purpose of dimensionality reduction or feature learning. It consists of two parts: an encoder that compresses the input into a latent-space representation, and a decoder that reconstructs the input from this representation.\n",
    "2. Learning Framework:\n",
    "    * This refers to the overall structure and methodology used for training the autoencoder. It includes the design of the neural network, the loss functions, the optimization algorithms, and the training process.\n",
    "3. Multivariate:\n",
    "    * Multivariate refers to multiple variables or features. In the context of forecasting, it means predicting multiple interrelated time series or data points simultaneously.\n",
    "4. Distributional Forecasting:\n",
    "    * Distributional forecasting involves predicting not just a single value but the entire distribution of possible future values. This provides a probabilistic view of future outcomes rather than a single point estimate.\n",
    "\n",
    "Combining these concepts, an autoencoder learning framework for multivariate distributional forecasting is a system where an autoencoder is trained to model and predict the distribution of multiple interrelated time series or data points. This framework captures the complex relationships between different variables and provides probabilistic forecasts that give a range of possible future values with their associated probabilities.\n",
    "\n",
    "Key Points:\n",
    "* Encoder: Compresses multivariate input data into a lower-dimensional latent space.\n",
    "* Decoder: Reconstructs the input data from the latent space.\n",
    "* Training: The autoencoder learns to minimize the difference between the original data and the reconstructed data.\n",
    "* Forecasting: Instead of predicting single future values, the system forecasts the distribution of possible future outcomes for multiple variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d3be4-a6b3-4d59-b360-b04f9e08ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inputs, predictors, independent, features, variables - X\n",
    "Output, response, dependent, - Y\n",
    "Y =f(X)+ε. \n",
    "\n",
    "Prediction - Guess what Y-hat\n",
    "Inference - Understand what is important\n",
    "\n",
    "reducible error and the irreducible error \n",
    "E(Y −Y) = E[f(X)+ε−f(X)] ˆ2 \n",
    "\n",
    "[f(X) − f(X)] ^2 + Var(ε) , reducible + irreducible\n",
    "\n",
    "parametric or non-parametric \n",
    "Non-parametric methods do not make explicit assumptions about the func- tional form of f. Instead they seek an estimate of f that gets as close to the data points as possible without being too rough or wiggly. \n",
    "\n",
    "There are several reasons that we might prefer a more restrictive model. If we are mainly interested in inference, then restrictive models are much more interpretable. For instance, when inference is the goal, the linear model may be a good choice since it will be quite easy to understand the relationship between Y and X1,X2,...,Xp. In contrast, very flexible approaches, such as the splines discussed in Chapter 7 and displayed in Figures 2.5 and 2.6, and the boosting methods discussed in Chapter 8, can lead to such complicated estimates of f that it is difficult to understand how any individual predictor is associated with the response. \n",
    "\n",
    "Generalized additive models (GAMs) \n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee9c4b-80e1-40a4-8e66-30cb11542d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine Learning\n",
    "\n",
    "There are 4 Primary Types of Machine Learning Approaches.\n",
    "\n",
    "Supervised Learning\n",
    "Unsupervised Learning\n",
    "Semi Supervised Learning\n",
    "Reinforcement Learning\n",
    "\n",
    "They support very different types of problem solving, depending upon the need, which includes availability of data, you can select between them. They each have strengths and weaknesses and are situationally dependent. \n",
    "\n",
    "Supervised Learning\n",
    "\n",
    "Algorithms include:\n",
    "Linear Regression\n",
    "Logistic Regression\n",
    "Decision Trees\n",
    "Neural Networks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Unsupervised Learning\n",
    "Support Vector Machines (SVM)\n",
    "Principle Component Analysis (PCA)\n",
    "\n",
    "\n",
    "Semi-supervised Learning\n",
    "\n",
    "## Semi Supervised Learning\n",
    "\n",
    "\n",
    "\n",
    "Reinforcement Learning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Define a Task.\n",
    "- What are the inputs and Outputs\n",
    "- What is the labelled data\n",
    "- How will you evaluate performance\n",
    "- Consider train/test split\n",
    "- What functions will you use, why?\n",
    "- What is your baseline\n",
    "\n",
    "Output of a prediction, vs output of a bounding window, vs output which highlights area of interest.\n",
    "\n",
    "Training Population and Usage Population\n",
    "- NA Testing Group vs Asian Testing Group. Men vs Women. Etc..\n",
    "\n",
    "Features - Need to generalize. Name of a car vs Engine, Age, Etc.\n",
    "Turn Learning into a numerical optimization task. Computers really good at this. Opposed to Expert Logic.\n",
    "\n",
    "\n",
    "Loss Function. \n",
    "Model is a function of the inputs. \n",
    "Loss is a function of the parameters of the model.\n",
    "For MSE why a Parabolic Shape? - Squared Function.\n",
    "Unlikely to generate a single Linear Function that perfectly fits all data points. Need to generate some super complex function\n",
    "Positive Gradient - Reduce\n",
    "Negative Gradient - Increase\n",
    "Convergence / divergence\n",
    "Greater the slope, the more we want to change\n",
    "\n",
    "Stochastic Gradient Descent - 1 Single Observation\n",
    "Mini Batch Gradient Descent - \n",
    "Epoch - Pass through data\n",
    "\n",
    "Not all loss. Functions differentiable.\n",
    "Global vs Local Minimum. No great solution.\n",
    "Linear regression is convex, always get to global minima\n",
    "Mimentum.\n",
    "\n",
    "When predicting a car, you need to find common features which generalize well.\n",
    "\n",
    "Linear Model limitations\n",
    "- Sensitive to size, color, orientation\n",
    "- No concept of edges\n",
    "- No concept of structure relationship between pixels\n",
    "\n",
    "Edge detection\n",
    "- Sharp change pixel intensity\n",
    "- Spatial gradient\n",
    "- Convolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79229b1-4834-4be7-b9cf-1dce33abb46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2807dc94-7e8d-431a-afae-9bd6b467b4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32536c03-fd04-4c59-9f45-a6426c1d25cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/cosine_similiarity.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655452cf-15b8-49b5-bbb9-e91b81676a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2135824-6ac6-4131-9ce6-5028a97c99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d_py_functions.SharedFolder import ReadDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75689b5f-3551-4dba-8bb2-11b3e3135564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/confusion_matrix.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/bias.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Anscombe_Quartet.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/.DS_Store)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Optimizer_Performance.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Kubernetes.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/cosine_similiarity.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Mnist_Simple_results.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/spark.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Consulting_Fees.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/X_OR.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/SQL_Cheatsheet.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/scikit_learn_models.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/harmonic_mean.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/readme)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/ML_AI_Significance_Chart.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Variance_Not_Equal.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/BiParte_Graph.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/ImpactOutliers.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/MultiClass_LogisticReg.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Log_loss.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/AI_ML_DL_Visual.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/MNist_Results.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Correlation_Visual.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/bias1.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Optimizers.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/DataVsModel.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Boosting_.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Loss_Functions.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Bagging.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Sigmoid.png)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for x in ReadDirectory('/Users/derekdewald/Documents/Python/Github_Repo/images'):\n",
    "    string = '[Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/'\n",
    "    print(f\"!{string}{x})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8da00d-9c08-4247-94fa-cc74d67d3ab9",
   "metadata": {},
   "source": [
    "## Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490e979-e88b-4816-a7e2-437e07ce3e1b",
   "metadata": {},
   "source": [
    "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/bias.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da492a-7671-47fd-9b28-b8fdf8117cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a385ae34-c5bd-4e7a-8ecb-6efe9349dedb",
   "metadata": {},
   "source": [
    "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/bias1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b31079-7efa-458b-995f-327ffcf0fd77",
   "metadata": {},
   "source": [
    "## Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3964acc-fe34-4c19-911f-6918ca740e0c",
   "metadata": {},
   "source": [
    "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Kubernetes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a721beaf-0c59-41bf-a17a-eaffda5a8644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/confusion_matrix.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/bias.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Anscombe_Quartet.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Optimizer_Performance.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/kubernetes.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/cosine_similiarity.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Mnist_Simple_results.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/spark.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Consulting_Fees.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/X_OR.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/SQL_Cheatsheet.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/scikit_learn_models.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/harmonic_mean.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/ML_AI_Significance_Chart.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Variance_Not_Equal.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/BiParte_Graph.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/ImpactOutliers.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/MultiClass_LogisticReg.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Log_loss.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/AI_ML_DL_Visual.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/MNist_Results.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Correlation_Visual.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/bias1.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Optimizers.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/DataVsModel.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Boosting_.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Loss_Functions.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Bagging.png)\n",
      "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Sigmoid.png)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ab6ea66-ed48-46dc-86fe-dd23d591b317",
   "metadata": {},
   "source": [
    "\n",
    "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f680801a-3c84-4306-ad61-b73dc3bd5663",
   "metadata": {},
   "source": [
    "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/DataVsModel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c7d3ca-fe44-45de-8f54-378b57b40225",
   "metadata": {},
   "source": [
    "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/bias1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d011e87-7339-47f3-898b-5bb39e88c068",
   "metadata": {},
   "source": [
    "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/Loss_Functions.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266b1be-c4fa-4d1e-b3f4-ef06cc40ef6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e23ef50c-1f54-4d40-b030-b39c5bbbf9ff",
   "metadata": {},
   "source": [
    "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/scikit_learn_models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0e795-1ccf-4e2f-a450-37c935393671",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa31f0-33e2-4137-9770-83e849d47369",
   "metadata": {},
   "source": [
    "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d300de-d71d-4995-9dee-019aa0e1adca",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e589c-cac0-466a-bde4-f96f22d59cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f217b6b-8bb7-4a4a-bceb-a13ef21db2f7",
   "metadata": {},
   "source": [
    "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/cosine_similiarity.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba99d6-da6f-4967-aeae-87e25b26f3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8d458-8f8d-41f2-8e1f-395bf85bc0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7a888-8248-4f70-a21b-50d7003e0c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc35cb2-1ff0-4170-b05e-c0197b02c362",
   "metadata": {},
   "source": [
    "![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/MNist Results.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4245ab-7e93-43e3-b08e-c5453daf0dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2fad07-2200-4216-8aa1-774ef5005213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "683b23eb-01f9-4a5f-8217-de0cf11e98e4",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "1) Linear Regression\n",
    "2) Logistic Regression\n",
    "3) Decision Trees\n",
    "\n",
    "\n",
    "## Unsupervised Learning\n",
    "1) Support Vector Machines (SVM)\n",
    "2) Principle Component Analysis\n",
    "\n",
    "\n",
    "## Semi Supervised Learning\n",
    "\n",
    "\n",
    "\n",
    "## Reinforcement Learning\n",
    "\n",
    "## Ensemble Methods\n",
    "### Boosting\n",
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5013b91-375a-470b-8a81-90290eeaf185",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343b9d8f-6282-4d8d-b5f1-af51265dcdfa",
   "metadata": {},
   "source": [
    "\n",
    "### Model\n",
    "$f(x) = w_0 + w_1X$\n",
    "\n",
    "### Parameters \n",
    "\n",
    "$[w_0, w_1]$\n",
    "\n",
    "### Loss\n",
    "$J(w_0,w_1) = \\frac{1}{n} \\sum_{i=1}^n \\left( y_i - (w_0 + w_1 x_i) \\right)^2$\n",
    "\n",
    "### Objective \n",
    "Minimize $J(w_0,w_1)$\n",
    "\n",
    "### Mean Square Error\n",
    "$MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f3f82-e081-43c4-bcf0-e5edcfb617dd",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "\n",
    "$\\sigma(x) = \\frac{1}{1 + e^{-x}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720fd8c5-2c59-4b91-9f3b-5631318b9f71",
   "metadata": {},
   "source": [
    "Linear Regression : $\\hat{y} = xw^T + b$ <br>\n",
    "Logistic Regression: $\\hat{y} = \\frac{1}{1 + e^({-xw^T + b})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ce69776-b4c7-4706-8628-73dbe1dd65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2308de-9437-4c0f-9292-72e98ee383db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14156be-49b7-4853-9f06-c0f389ff4b59",
   "metadata": {},
   "source": [
    "## Gradient Descent \n",
    "\n",
    "Predicitions: $\\sigma(XW^T)$\n",
    "\n",
    "Differences: $\\sigma(XW^T) - Y$\n",
    "\n",
    "Gradient: $\\frac{1}{m} (\\sigma(XW^T) -Y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afc58d8-dad3-4813-8d86-5d72ecd3cba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9368f-34f7-4e15-b47a-6cda3ea23052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63112174-349b-4a6b-8648-a28fd09b29d2",
   "metadata": {},
   "source": [
    "$\\text{Log Loss} = -\\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f27cee-cf11-4cd8-acf2-848d970c2793",
   "metadata": {},
   "source": [
    "$\\text{Log Loss} = -\\frac{1}{n} \\sum_{i=1}^n \\sum_{j=1}^k y_{ij} \\log(\\hat{y}_{ij})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4bfc285-7988-491a-9edf-dcf11fb72f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Softmax Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb27f73-0960-42b2-bd53-132ba474c193",
   "metadata": {},
   "source": [
    "$\\sigma(z)_i = \\frac{\\sigma(xW^T_j)}{\\sum_{j=1}^k \\sigma(xW^T_j)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "578c7716-f489-4d25-abec-1d1f93ce316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chain Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771233e3-b440-49cc-b895-a529dde00e9a",
   "metadata": {},
   "source": [
    "$h(x) = f(g(x))$\n",
    "\n",
    "\n",
    "$h'(x) = f'(g(x)) \\cdot g'(x)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d11698-c4e1-4ae0-9632-c475d9f887da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d3a47-7565-4d2b-8a34-e4a1b4cf8d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f75f2b-f398-42e9-9297-17e241f4a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boosting. Train Additive Models in Series Where Each Predicts the Residual from the Previous Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c0e1e-43ee-4613-a1d0-289767ab021c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af72fb-e284-4c4e-9408-bed6c0f1bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bagging. Trains Models in Parallel Via Bootstrap Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c9d7d-9dc2-4b2d-af80-051e671ec9aa",
   "metadata": {},
   "source": [
    "## Distance Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef39068a-b22a-4dfa-8336-8fc6327d5016",
   "metadata": {},
   "source": [
    "$ ||A|| = \\sqrt{\\sum \\left (A_i \\right)^2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a75dcf-0790-4036-9e3b-95fbdde9aaa3",
   "metadata": {},
   "source": [
    "$ L_2(A,B) = \\sqrt{\\sum \\left( A_i - B_i \\right)^2} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab53a3f-3bdd-4812-8f26-b28f3061d4d6",
   "metadata": {},
   "source": [
    "$\\ A \\cdot B = \\sum_{i=1}^n A_i B_i = ||A|| ||B|| cos(\\theta)$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
