Program,Classification,Command_Code,Description,Comments,Unnamed: 5
Anaconda,,conda info,Information on Program,,
Anaconda,,conda --version,Version of Program,,
Anaconda,,conda update conda,Update Program,,
Anaconda,,conda create -n py39 python=3.9,Create Environment,,
Anaconda,,conda activate TimeSeries39,Activate Environment,,
Anaconda,,conda install pandas=1.4.2 | conda install pandas,Install Package,,
Anaconda,,conda env remove -n py39,Delete Environment,,
Anaconda,,conda create --name newpy39 --clone py39,Create Environment from Exising Env,,
Anaconda,,conda env create -f BASE_REQUIREMENTS.yaml,Create Environment from YAML,,
Anaconda,,conda list,List Available Environments,,
Azure,,az login,Log into AKS,,
Azure,,az acr login --name w255mids,Log into ACR,,
Azure,,az account list --output table,Check which AKS Account,,
Azure,,"Log into Azure - az login
Set Subscription to Class - az account set --subscription=""0257ef73-2cbf-424a-af32-f3d41524e705""
Authenticate to the AKS cluster - az aks get-credentials --name w255-aks --resource-group w255 --overwrite-existing
az acr login --name w255mids",Signing in and Calibration Process,,
Debian,,,apt-get,Command-line-centric and might have a steeper learning curve for beginners.,
Debian,,,apt,"User-friendly and intuitive, providing a simpler interface.",
Docker,,docker run -it NAME /bin/sh,Run Image,,
Docker,,docker ps -a,Check Open Containers,,
Docker,,,Docker Image,"An image is a read-only template used to create containers, it contains the application code, runtime, system tools, libraries, and other dependencies required to run the application.",
Docker,,,Docker Container,"A container is a runnable instance of a Docker image, it encapsulates the application and its dependencies, ensuring consistency and isolation from the host system",
Docker,,docker stop CONTAINER_NAME,Stop Container,,
Docker,,docker remove CONTAINER_NAME,Delete Container,Remove a Docker Container,
Docker,,docker rmi IMAGE_NAME,Delete Image,Remove a Docker Image,
Docker,,docker build -t NAME .,Create Image,"Build a Docker Image. Note that the image build is environment specific, as such when buiding on a MAC and deploying to a Windows Machine or Linux, need to be mindful. docker build --platform linux/amd64 -t project .",
Docker,,docker exec -it my_container /bin/sh,,,
Docker,,ARG APP_DIR=/app,,Builds a Document in Docker in this case it is the argument /app,
Docker,,http://localhost:8000/docs,"Connect to Uvicorn, Via Docker",,
Docker,,"export PATH=""$HOME/.local/bin:$PATH""",Docker Image Creation,,
Docker,,docker run -d -p 8000:8000 w255_api,Run,Detached Mode,
Docker,,docker run -d --name temp-redis -p 6379:6379 redis,Create Redis Database,,
Docker,,docker tag project w255mids.azurecr.io/derekdewald/,Tag a Project with a Specific Name,"Must be mindful of issue of using, Latest. Specifically when needing to roll back.",
Docker,,docker push w255mids.azurecr.io/derekdewald/project:64293a0,Push Image to Repo,,
FastAPI,,,FastAPI,,
FastAPI,,,Test a Application End Point from Command Line,"curl -X POST \
  https://derekdewald.mids255.com/project/bulk-predict \
  -H 'Content-Type: application/json' \
  -d '{""text"": [""example 1"", ""example 2""]}'",
Git,,git clone,Clone Directory,"Type of Clone commands depends on authentication method, appears that the primary method is now SSH. git@github.com:derek-dewald/d_functions.git",
Git,,git status,Compare with Main Branch,,
Git,,git add,Include File to be Syncronized with Main Branch,"Variations in add ., add .*png, add .A-",
Git,,"git commit -m ""Include Message""",Commit to Main Branch,,
Git,,git push,Push To Main Branch,,
Git,,,Rename Existing Folder,"Log into Git, go into Folder, Settings. Option to Rename",
Git,,,Delete Exising Folder,"Log into Git, go into Folder, Settings. Option to Delete at Bottom after verification",
Git,,git pull origin,Pull or Update from Main,,
Git,,git stash apply,Apply Stashed Changes,,
Git,,git stash,Stash Pending Changes,,
Git,,git pull --rebase,Apply updates to Repo,"If there is a conflict, it will alert, otherwise all Local and Remote Change will be applied.",
Git,,config pull.rebase true,Apply Updates to Repo,Change default setting to always apply this approach.,
Hadoop,,!hadoop jar {JAR_FILE},,!hadoop jar {JAR_FILE}: This command submits a Hadoop job using the specified JAR file. Replace {JAR_FILE} with the actual path to your MapReduce JAR file.,
Hadoop,,D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator,,"This sets the key comparator class to KeyFieldBasedComparator, which allows you to specify key-based sorting",
Hadoop,,"D mapreduce.partition.keycomparator.options=""-k1,2nr -k2,3nr",,"This sets the key comparator options, specifying the sorting criteria. In this case, it is sorting first on the first and second columns in reverse numerical order (nr), and then on the second and third columns in reverse numerical order.",
Hadoop,,"D mapreduce.partition.keypartitioner.options=""-k1,1",,"This sets the key partitioner options, specifying that the partitioning is based on the first column",
Hadoop,,D mapreduce.job.reduces=1,,"This sets the number of reducers to 1, indicating that the final sorted output will be written by a single reducer.",
Hadoop,,input {HDFS_DIR}/eda-output/part-0000*,,Specifies the input directory for the MapReduce job. It uses wildcard part-0000* to include all files starting with part-0000 in the specified HDFS directory.,
Hadoop,,mapper /bin/cat \,,"Specifies the mapper to be /bin/cat, which means it uses the cat command to output the input data without any modification.",
Hadoop,,reducer /bin/cat,,"Specifies the reducer to be /bin/cat, which means it uses the cat command to concatenate the sorted output from the mapper without any additional processing.",
Jupyter,,![Alt Text](https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/cosine_similiarity.png),Embed Link to Git Image,Must be In Markdown,
Jupyter,,,Create New File,"with open('/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions/__init__.py', ""w"") as file:
    # Optional: Add content to the file
    file.write(""# This is the __init__.py file\n"")",
Kubernetes,,kubectl get namespaces,Retrieve all Namespaces,,
Kubernetes,,kubectl delete namespace w255,Delete All Name Spaces,,
Kubernetes,,kubectl get pods -n w255,Get Pod Name,,
Kubernetes,,kubectl describe deployment redis -n w255,Describe Deployments,,
Kubernetes,,kubectl apply -f filename.yaml,Run .yaml File,,
Kubernetes,,kubectl exec -it redis-7968b47c9-zgdbr  -n w255 -- /bin/bash,Remote into Redis DB,,
Kubernetes,,kubectl delete -k .k8s/base/  .k8s/overlays/prod,Delete Yaml Deployment,,
Kubernetes,,kubectl apply -k .k8s/base/ .k8s/overlays/prod,Apply YAML Deployment,,
Kubernetes,,kubectl config current-context,Check Current Context,,
Kubernetes,,kubectl config view --minify | grep namespace:,Verify Namespace in Context,,
Kubernetes,,kubectl config set-context --current --namespace=derekdewald,Set Context to Specific Namespace,,
Kubernetes,,kubectl config use-context w255-aks,Set Context to Specific Namespace,,
Kubernetes,,,Port Forward to Grafana,"kubectl port-forward -n prometheus svc/grafana 3000:3000
kubectl port-forward svc/prediction-service 8080:8000 -n derekdewald",
Kubernetes,,kubectl get all -n derekdewald,Search All Resources,,
Minikube,,brew install minikube,Install,Install Minikube,
Minikube,,minikube stop,Stop Minikube,,
Minikube,,minikube delete,Delete Minikube,,
Minikube,,minikube start --kubernetes-version=v1.27.3,,,
Minikube,,kubectl delete pods api-deployment-5c488d6dd9-jmwcf -n w255,Delete Pod,,
Minikube,,kubectl rollout pause deployment api-deployment -n w255,Pause Deployment,,
Minikube,,kubectl delete deployment api-deployment -n w255,Stop Deployment,,
Minikube,,kubectl get services -n w255,,,
Minikube,,kubectl describe service redis-service -n w255,,,
Minikube,,kubectl logs pod/api-deployment-5c488d6dd9-2tn6c -c init-verify-redis-service-dns -n w255,Check what,,
Minikube,,kubectl get all,Check Everything,,
Minikube,,kubectl delete all --all --namespace=w255,Delete Everything in NameSpace,,
Minikube,,"kubectl config use-context minikube
kubectl config use-context w255-aks",Configuration Management,,
Nano,,CTRL + X,Save File,,
Nano,,CTRL + O,Close File,,
Nano,,nano FILENAME,Create/ Open File,,
Nano,,CTRL + O,Open File to Edit,Open File to Edit,
Nano,,CTRL + X,Close File,Close File,
Poetry,,poetry install,,,
Poetry,,poetry shell,,,
Poetry,,,poetry install --no-root,"Application would not install without the --no-root addition, claimed to be missing dictories.",
Poetry,,poetry update,Update TOML file,,
Poetry,,poetry install,Install,,
Poetry,,poetry env list --full-path,poetry env list,,
Python,,,Args,,
Python,,,Kwargs,,
Python,,,Generator function,,
Python,,,Classes,,
Python,,"make_pipeline(SimpleImputer(), RobustScaler(), SVR())",Data Pipeline,,
Python,,"grid = GridSearchCV(processing_pipeline, param_grid=params, n_jobs=-1, cv=5, verbose=3)",Grid Search,,
Python,,dock,Decorator,"Is a syntactic sugar that allows you to wrap a function or class with common logic without compromising readability. Itâ€™s roughly equivalent to app.get(""/"")(hello_world).",
Python,,"joblib.dump(model,model_name.pkl)",Export ML Model,,
Python,,,Import ML Model,,
Python,,sys.path.append(path),Add New Path to System Path,,
Redis,,brew install minikube,Install,Install Minikube,
Redis,,redis-server --daemonize yes,,,
Redis,,redis-server,,,
Redis,,redis-cli ping,,,
Redis,,ps aux | grep redis-server,Check Status of Server,,
Redis,,kill process_id,Stop Redis,,
Redis,,redis-server --daemonize yes,Start Redis,,
Redis,,redis-cli monitor,Monitor Redis,,
Redis,,redis-cli -h localhost -p 6379 monitor,,,
Spark,,"from pyspark.sql import SparkSession

try:
  spark
  print(""Spark is already running"")
  print(f""{sc.master} appName: {sc.appName}"")
except NameError:
  print('starting Spark')
  app_name = 'hw3_notebook'
  master = ""local[*]""
  spark = SparkSession\
  .builder\
  .appName(app_name)\
  .master(master)\
  .getOrCreate()
sc = spark.sparkContext",,How to Start A Spark Session.,
Spark,,sp.textFile(FILENAME),Create RDD from File,,
Spark,,sp.parralellize([LISTVALUES]),Create RDD from df,,
Spark,,,Transformations,,
Spark,,,Actions,,
Spark,,trainRDDCached.count(),Total Record Count,,
Spark,,,Total Column Count,,
Spark,,,Spark,"Memory Based. Memory, relatively cheap, 100x faster than HD, Lazy.Resource Management,Data Management,Data Processing,AKA Executor,AKA Cluster Manager. K-Mean, Page Rank, HDFS, RDD",
Spark,,,sc.parallelize,,
Spark,,,DAG,Directed acyclic graph:,
Spark,,"df = df.drop('Id'), df.drop(*columns_to_drop)",Drop Column,,
Spark,,"df = df.withColumn(new_column_name, when(df[""row_number""] == 1, None).otherwise(df[new_column_name]))",If Then With Column,,
Spark,,"df.withColumn(""Result"", col(""Value1"") - col(""Value2""))",Mathamatical Operator on 2 columns,,
Spark,,"perf_df_routes = df_flights2.groupby('OP_CARRIER_AIRLINE_ID','ORIGIN',""DEST"").agg(
  mean('AIR_TIME').alias('Mean Air Time'),
  sum('FLIGHTS').alias('Total Flights'),
  sum('DEP_DEL15').alias('Departure Delays'),
  sum('ARR_DEL15').alias('Arrival Delays')).toPandas()",Groupby,,
Spark,,"df.filter(col(""column_name"") ==1)",Filter Dataframe,,
Spark,,"df.select(""name"", ""age"")",Select Specific Columns,,
Spark,,"test_df.withColumn(""Time_Difference_Minutes"",
  (unix_timestamp(""Previous_Flight_Touchdown_Time"") - unix_timestamp(""CRS_Departure_Timestamp"")) / 60)",,,
Spark,,,Filter,"df_filtered = df.filter(df.column_name.isNotNull() & (df.column_name != """"))",
SparkConf,,"This is used to configure the settings of Spark, such as the master node, application name, etc",,,
SparkContext,,"The entry point to low-level Spark functionalities, including creating and managing RDDs. It provides the connection to the cluster and manages job execution.",,,
Terminal,,rm FILENAME,Delete File,,
Terminal,,mkdir DIRECTORYNAME,Make Directory,,
Terminal,,curl,,"Command-line tool and library for transferring data with URLs. It stands for ""Client for URLs"".",
Terminal,,( > ),,The greater than operator  indicates to the command line that we wish the programs output (or whatever it sends to STDOUT) to be saved in a file instead of printed to the screen. Let's see an example.,
Terminal,,>>,,Append data to existing file,
Terminal,,program -- version,Check Program Version,,
Terminal,,echo,,,
Terminal,,grep,,"A command-line utility used in Unix-like operating systems to search for patterns within files or input text. It is a powerful tool for text pattern matching and is commonly used for searching, filtering, and extracting information from files or command output",
Terminal,,CTRL + C,,To Exit out of Command Line Error,
Terminal,,"!wget -O data/alice.txt ""http://www.gutenberg.org/files/11/11-0.txt""",,,
Terminal,,!head -n 6 data/alice.txt,,,
Terminal,,%%writefile data/alice_test.txt,,,
Terminal,,!ls data | grep test,,,
Terminal,,!python wordCount.py < data/alice_test.txt,,,
Terminal,,!python wordCount.py < data/alice.txt > data/alice_counts.txt,,,
Terminal,,!grep alice data/alice_counts.txt,,,
Terminal,,!head data/alice_counts.txt,,,
Terminal,,!grep hatter data/alice_counts.txt,,,
Terminal,,!wc -l data/alice_counts.txt,,,
Terminal,,sort yourfile.txt or sort -r yourfile.txt,,,
Terminal,,!sort data/alice_counts.txt > data/alice_counts_A-Z.txt,,,
Terminal,,"!sort -k2,2nr data/alice_counts.txt >data/alice_counts_sorted.txt",,,
Terminal,,!conda install -c conda-forge -y wget,,,
Terminal,,!chmod a+x pWordCount_v2.sh,,,
Terminal,,!chmod a+x aggregateCounts_v2.sh,,,
Terminal,,!python aggregateCounts_v1.py < data/alice_pCounts.txt > data/random_test.txt,,,
Terminal,,Piping ( | ),,,
Terminal,,python3 -m venv DATASCI255,,,
Terminal,,source DATASCI255/bin/activate,,,
Terminal,,ls -l,List Authorizations of File,,
Terminal,,echo $SHELL,,,
Terminal,,LL,,"The ll command is not a standard command in all shells. It's often an alias for the ls -l command, which displays detailed information about files and directories",
Terminal,,CHMOD,CHMOD,,
Terminal,,,How to Create Folder,,
Terminal,,,How to Create Document,,
Terminal,,,How to Input Text into Document,,
Terminal,,,How to Copy a File,,
Terminal,,"find ~/ -name ""conda"" 2>/dev/null",Find Word in Directories,,
Terminal,,"""- y""",By Pass Prompting,,
Unix,,bin/cat,,"command is a Unix command-line utility that is commonly used to concatenate and display the content of one or more files. The name ""cat"" is derived from ""concatenate.""",
Uvicorn,,uvicorn src.main:app --reload,sc.parallelize,,
Uvicorn,,ps aux | grep uvicorn,Check Open Program,,
Uvicorn,,kill process_id,Stop Open Programs,,
Uvicorn,,http://localhost:8000,Access while on Docker,,
Anaconda,,conda search scikit-learn,Search Available Packages,,
SQL,,,Cheat Sheet,https://raw.githubusercontent.com/derek-dewald/d_functions/main/images/SQL_Cheatsheet.png,
Python,,df[new_column_name] = df[column_name].ffill(),Force Fill,"Must be Careful with np.nan, """" and blanks. None works.",DF_Functions.FillFromAbove
Python,,%history -f history.txt,,,
SQL,,"with name as ( SQL Query),
name2 as (SQL Query),
name3 as (SQL Query)
select t1.*, t2.*,t3.* 
from name t1
left join name2 t2 t1.key=t2.key
left join name3 t3 on t1.key=t3.key",Joining Series of Subqueries,,
SQL,,max(case when daysdelinq>=90 then 1 else 0 end) as Name,"If then, Single Value",,
SQL,,sum(case when minor = 'ES01' then currbal else 0 end) as Name,If then Aggregation,,
SQL,,1 as Variable Name,Static Value,,
SQL,,"COALESCE(a.CURRENT_ES01, 0) AS CURRENT_ES01",Replace Null Values with 0,,
SQL,,"select top(10) * from table
select * from table fetch first 5 rows only",,,
Regen,,[A-Za-z],Filter for Any Letters,"r""^003[A-Za-z']""",
Regen,,[0-9],Filter for Any Numbers,"r""^003[0-9']""",
Python,,"functools.reduce(functools.partial(pd.merge(on=key,how=left), [list of tables])",Merge Multiple Tables on Same Key,,
Python,,df.sample(frac=.5),Random Sample DF,df.sample(frac=1) Will reset randomly sort the dataframe.,
Python,,"np.random.choice(list,size=n,p=probability)",Random Binary Dataframe,"np.random.choice([0,1],size=10000,p=[.9,.1])",
Pandas,,"pd.set_option('display.max_columns',None)",Dataframe Display All Columns,,
Pandas,,"pd.set_option('display.width',1000)",Dataframe Display Max Width,,
Pandas,,"pd.set_option('display.float_format',lambda x:'%.2f %x)",Dataframe Display Max 2 Decimals,,
Pandas,,"pd.Categorical(df.index,categories = [], ordered = True)",Create Customer Order Series/ Column,,
Git,,git reset --hard HEAD,Restore state before previous Git Add,Deletes files on Computer. Be Careful.,
Git,,"echo ""Clean Up Historical Work.ipynb"" >> .gitignore",Add A file to Ignore,,
Git,,cat .gitignore,See Contents of GitIgnore,,
SQL,,select * from (select * from table),Subquery,"A table, which is comprised of logic made by another query.",
SQL,,"SELECT department, SUM(salary) AS total_salary
FROM employees
GROUP BY department
HAVING SUM(salary) > 100000;",Having,Ability to apply a Condition review statement after a Group By.,
SQL,,"SELECT * from  employees
order by (RIGHT employee_ID)
",Custom Order,"Sort by the Last 3 Digits of a Particular Field, which might not exist in Data",
SQL,,Select * from table where year(date) = 2024,YEAR,,
SQL,,select * from table where dept_id = (select dept_id from other_tabe where name = 'something'),Subquery List,,
SQL,,select * from table where date between day1 and day2,Between,,
SQL,,_,Match Exactly 1,,
SQL,,%,Match Any Number of Characters,,
SQL,,"select a.*, b.* from table1 a inner join table2 b on a.value>b.value2 and a.value3 >= b.value4",Non Equi Joins,Joins on something other than a Primary Key.,
