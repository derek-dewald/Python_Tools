{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccdc485",
   "metadata": {},
   "source": [
    "## Bayes' Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fcdf50",
   "metadata": {},
   "source": [
    "Bayes' theorem describes how to update probabilities based on new evidence. It is given by:\n",
    "\n",
    "$$\n",
    "P(A | B) = \\frac{P(B | A) P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( P(A | B) \\) is the **posterior probability** (probability of \\( A \\) given \\( B \\)).\n",
    "- \\( P(B | A) \\) is the **likelihood** (probability of \\( B \\) given \\( A \\)).\n",
    "- \\( P(A) \\) is the **prior probability** (initial probability of \\( A \\)).\n",
    "- \\( P(B) \\) is the **marginal probability** (total probability of \\( B \\)).\n",
    "\n",
    "### **Example:**\n",
    "Suppose a medical test for a disease has:\n",
    "- **Sensitivity**: \\( P(\\text{Positive} | \\text{Disease}) = 0.99 \\)\n",
    "- **False positive rate**: \\( P(\\text{Positive} | \\neg \\text{Disease}) = 0.05 \\)\n",
    "- **Prevalence**: \\( P(\\text{Disease}) = 0.01 \\)\n",
    "\n",
    "Using Bayes' theorem, the probability that a person actually has the disease given a positive test result is:\n",
    "\n",
    "$$\n",
    "P(\\text{Disease} | \\text{Positive}) = \\frac{0.99 \\times 0.01}{(0.99 \\times 0.01) + (0.05 \\times 0.99)}\n",
    "$$\n",
    "\n",
    "This formula helps in **medical diagnostics, spam filtering, machine learning, and decision-making**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce71f75",
   "metadata": {},
   "source": [
    "## Capital Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531ae5cd",
   "metadata": {},
   "source": [
    "#### Product Notation (Capital Pi) (Π)\n",
    "\n",
    "The product of a sequence is defined as:\n",
    "\n",
    "$$\n",
    "P = \\prod_{i=1}^{n} a_i = a_1 \\cdot a_2 \\cdot \\dots \\cdot a_n\n",
    "$$\n",
    "\n",
    "##### Example Calculation:\n",
    "$$\n",
    "\\prod_{i=1}^{4} i = 1 \\times 2 \\times 3 \\times 4 = 24\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb9837",
   "metadata": {},
   "source": [
    "## Derivative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497f49c",
   "metadata": {},
   "source": [
    "The **derivative** of a function measures the rate at which the function value changes as its input changes. Mathematically, it is defined as:\n",
    "\n",
    "$$\n",
    "f'(x) = \\lim_{{h \\to 0}} \\frac{f(x + h) - f(x)}{h}\n",
    "$$\n",
    "\n",
    "### Example Calculation:\n",
    "For the function \\( f(x) = x^2 \\), the derivative is calculated as:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx} x^2 = 2x\n",
    "$$\n",
    "\n",
    "Thus, at \\( x = 3 \\):\n",
    "\n",
    "$$\n",
    "f'(3) = 2(3) = 6\n",
    "$$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56608fe",
   "metadata": {},
   "source": [
    "## Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac06e50",
   "metadata": {},
   "source": [
    "The **gradient** of a multivariable function is a vector containing its partial derivatives with respect to each variable. It points in the direction of the steepest ascent.\n",
    "\n",
    "For a function \\( f(x, y) \\), the gradient is defined as:\n",
    "\n",
    "$$\n",
    "\\nabla f = \\left( \\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y} \\right)\n",
    "$$\n",
    "\n",
    "### Example Calculation:\n",
    "Given \\( f(x, y) = x^2 + y^2 \\), the gradient is:\n",
    "\n",
    "$$\n",
    "\\nabla f = \\left( \\frac{\\partial}{\\partial x} (x^2 + y^2), \\frac{\\partial}{\\partial y} (x^2 + y^2) \\right)\n",
    "$$\n",
    "\n",
    "Computing the partial derivatives:\n",
    "\n",
    "$$\n",
    "\\nabla f = \\left( 2x, 2y \\right)\n",
    "$$\n",
    "\n",
    "At \\( (x, y) = (1, 2) \\):\n",
    "\n",
    "$$\n",
    "\\nabla f(1,2) = (2(1), 2(2)) = (2, 4)\n",
    "$$\n",
    "\n",
    "This means the function increases most rapidly in the direction of **(2,4)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c42bda",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b396e93",
   "metadata": {},
   "source": [
    "### **Definition:**\n",
    "Linear Regression models the relationship between an independent variable \\( X \\) and a dependent variable \\( Y \\) using a linear function.\n",
    "\n",
    "### **Equation:**\n",
    "The equation for simple linear regression is:\n",
    "\n",
    "$$\n",
    "Y = w_0 + w_1 X + \\epsilon\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( Y \\) is the **predicted output** (dependent variable).\n",
    "- \\( X \\) is the **input feature** (independent variable).\n",
    "- \\( w_0 \\) (intercept) and \\( w_1 \\) (coefficient) are the **parameters** learned from data.\n",
    "- \\( \\epsilon \\) represents the **error term** (residual).\n",
    "\n",
    "For multiple features \\( X_1, X_2, ..., X_n \\), the **multiple linear regression** model is:\n",
    "\n",
    "$$\n",
    "Y = w_0 + w_1 X_1 + w_2 X_2 + \\dots + w_n X_n + \\epsilon\n",
    "$$\n",
    "\n",
    "The **objective** in linear regression is to minimize the **Mean Squared Error (MSE)**:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{N} \\sum_{i=1}^{N} (Y_i - \\hat{Y}_i)^2\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55125061",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684bf19",
   "metadata": {},
   "source": [
    "### **Definition:**\n",
    "Logistic Regression is used for **binary classification**. It predicts the probability that an instance belongs to a particular class.\n",
    "\n",
    "### **Equation:**\n",
    "Logistic regression applies the **sigmoid function** to a linear model:\n",
    "\n",
    "$$\n",
    "P(Y = 1 | X) = \\sigma(w_0 + w_1 X_1 + w_2 X_2 + \\dots + w_n X_n)\n",
    "$$\n",
    "\n",
    "where the **sigmoid function** \\( \\sigma(z) \\) is:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "This ensures that the output is in the range \\( (0,1) \\), representing a probability.\n",
    "\n",
    "### **Decision Rule:**\n",
    "To classify an instance:\n",
    "- If \\( P(Y=1|X) \\geq 0.5 \\), predict class **1**.\n",
    "- Otherwise, predict class **0**.\n",
    "\n",
    "### **Objective Function:**\n",
    "Logistic regression minimizes the **log-loss (cross-entropy loss)**:\n",
    "\n",
    "$$\n",
    "J(\\theta) = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ Y_i \\log(\\hat{Y}_i) + (1 - Y_i) \\log(1 - \\hat{Y}_i) \\right]\n",
    "$$\n",
    "\n",
    "where \\( \\hat{Y}_i \\) is the predicted probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba21c9",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3bb3fd",
   "metadata": {},
   "source": [
    "## Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091db5e1",
   "metadata": {},
   "source": [
    "\n",
    "#### Addition\n",
    "$$\n",
    "A + B =\n",
    "\\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{bmatrix} +\n",
    "\\begin{bmatrix} b_{11} & b_{12} \\\\ b_{21} & b_{22} \\end{bmatrix} =\n",
    "\\begin{bmatrix} a_{11} + b_{11} & a_{12} + b_{12} \\\\ a_{21} + b_{21} & a_{22} + b_{22} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 10 & 8 \\\\ 6 & 4 \\end{bmatrix} +\n",
    "\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} =\n",
    "\\begin{bmatrix} 11 & 10 \\\\ 9 & 8 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### Subtraction\n",
    "\n",
    "$$\n",
    "A - B =\n",
    "\\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{bmatrix} -\n",
    "\\begin{bmatrix} b_{11} & b_{12} \\\\ b_{21} & b_{22} \\end{bmatrix} =\n",
    "\\begin{bmatrix} a_{11} - b_{11} & a_{12} - b_{12} \\\\ a_{21} - b_{21} & a_{22} - b_{22} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 10 & 8 \\\\ 6 & 4 \\end{bmatrix} -\n",
    "\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} =\n",
    "\\begin{bmatrix} 9 & 6 \\\\ 3 & 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Multiplication \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix} \\times\n",
    "\\begin{bmatrix} 7 & 8 \\\\ 9 & 10 \\\\ 11 & 12 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\begin{bmatrix} (1\\cdot7 + 2\\cdot9 + 3\\cdot11) & (1\\cdot8 + 2\\cdot10 + 3\\cdot12) \\\\ (4\\cdot7 + 5\\cdot9 + 6\\cdot11) & (4\\cdot8 + 5\\cdot10 + 6\\cdot12) \\end{bmatrix}$$<br>\n",
    "$$\n",
    "\\begin{bmatrix} 58 & 64 \\\\ 139 & 154 \\end{bmatrix} $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a0efc",
   "metadata": {},
   "source": [
    "## Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf8bd87",
   "metadata": {},
   "source": [
    "A **discrete random variable** is a random variable that takes on a **countable** number of distinct values. These values are typically integers or countable values.\n",
    "\n",
    "### **Mathematical Representation:**\n",
    "A discrete random variable \\( X \\) has a probability mass function (PMF) given by:\n",
    "\n",
    "$$\n",
    "P(X = x) = p(x), \\quad \\sum_{x} p(x) = 1\n",
    "$$\n",
    "\n",
    "where \\( p(x) \\) is the probability of \\( X \\) taking a specific value \\( x \\).\n",
    "\n",
    "### **Example:**\n",
    "Consider rolling a six-sided die. The possible outcomes are:\n",
    "\n",
    "$$\n",
    "X = \\{1, 2, 3, 4, 5, 6\\}\n",
    "$$\n",
    "\n",
    "Each outcome has an equal probability:\n",
    "\n",
    "$$\n",
    "P(X = x) = \\frac{1}{6}, \\quad x \\in \\{1,2,3,4,5,6\\}\n",
    "$$\n",
    "\n",
    "A **continuous random variable** is a random variable that can take on **infinitely many values** within a given range. It is described by a **probability density function (PDF)** instead of a PMF.\n",
    "\n",
    "### **Mathematical Representation:**\n",
    "A continuous random variable \\( X \\) has a probability density function (PDF) \\( f(x) \\), where:\n",
    "\n",
    "$$\n",
    "P(a \\leq X \\leq b) = \\int_{a}^{b} f(x) dx\n",
    "$$\n",
    "\n",
    "and the total probability satisfies:\n",
    "\n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} f(x) dx = 1\n",
    "$$\n",
    "\n",
    "### **Example:**\n",
    "Consider a standard normal distribution \\( X \\sim N(0,1) \\), which has the probability density function:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\n",
    "$$\n",
    "\n",
    "The probability that \\( X \\) lies between -1 and 1 is:\n",
    "\n",
    "$$\n",
    "P(-1 \\leq X \\leq 1) = \\int_{-1}^{1} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}} dx\n",
    "$$\n",
    "\n",
    "This represents the area under the normal curve between -1 and 1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7f909",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "944741ba",
   "metadata": {},
   "source": [
    "## Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44195de",
   "metadata": {},
   "source": [
    "Skewness measures the **asymmetry** of the distribution of a dataset.\n",
    "\n",
    "$$\n",
    "\\text{Skewness} = \\frac{n}{(n-1)(n-2)} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{s} \\right)^3\n",
    "$$\n",
    "\n",
    "### Definitions:\n",
    "- $( n )$ = Number of observations\n",
    "- $( x_i )$ = Individual data point\n",
    "- $\\bar{x} = \\text{Mean of the data}$\n",
    "- $( s )$ = Standard deviation\n",
    "\n",
    "### Interpretation:\n",
    "- **Skewness = 0** → Perfectly symmetric (normal distribution)\n",
    "- **Skewness > 0** → Right-skewed (positive skew, tail on the right)\n",
    "- **Skewness < 0** → Left-skewed (negative skew, tail on the left)\n",
    "- **|Skewness| > 1** → Highly skewed (might need transformation)\n",
    "\n",
    "---\n",
    "\n",
    "####  Fixing Skewness\n",
    "If the data is **highly skewed**, transformations can help make it more normally distributed.\n",
    "\n",
    "#### Fixing Right (Positive) Skewness\n",
    "If the data has a **long right tail**, try these transformations:\n",
    "\n",
    "- **Log Transformation**:  \n",
    "  $[\n",
    "  X' = \\log(X + c)]$\n",
    "  (Useful for right-skewed data, where \\( c \\) is a small constant to avoid log(0))\n",
    "  \n",
    "- **Square Root Transformation**:  \n",
    "  $[\n",
    "  X' = \\sqrt{X}\n",
    "  ]$\n",
    "  (Moderate effect on skewness)\n",
    "  \n",
    "- **Reciprocal Transformation**:  \n",
    "  $[\n",
    "  X' = \\frac{1}{X}\n",
    "  ]$\n",
    "  (Strong effect but inverts the order)\n",
    "  \n",
    "- **Box-Cox Transformation**:  \n",
    "  Best for normalizing skewed data (**requires all positive values**).\n",
    "\n",
    "### Fixing Left (Negative) Skewness\n",
    "\n",
    "If the data has a **long left tail**, it means the majority of values are concentrated on the right side. To correct this, we can apply transformations that **stretch** the left side and **compress** the right side.\n",
    "\n",
    "#### ** Power Transformation**\n",
    "Power transformations raise the values to an exponent greater than 1, making small values grow faster than large ones.\n",
    "\n",
    "$$\n",
    "X' = X^p, \\quad p > 1\n",
    "$$\n",
    "\n",
    "where $ p $ is a power greater than 1. Common choices are:\n",
    "- **Square transformation**: $ X' = X^2 $\n",
    "- **Cube transformation**: $ X' = X^3 $\n",
    "\n",
    "#### Exponential Transformation**\n",
    "Exponential transformation amplifies differences in small values, making the left tail stretch out.\n",
    "\n",
    "$$\n",
    "X' = e^X\n",
    "$$\n",
    "\n",
    "This transformation is particularly useful when dealing with data containing **negative values**.\n",
    "\n",
    "#### **3️⃣ Reflect and Apply Right-Skewness Correction**\n",
    "For datasets containing **negative or zero values**, a simple transformation might not work. Instead, **reflect the data**, apply a right-skew correction (like log or Box-Cox), and then reflect it back.\n",
    "\n",
    "1. Reflect the data:  \n",
    "   $$\n",
    "   X_{\\text{reflected}} = \\max(X) + \\min(X) - X\n",
    "   $$\n",
    "2. Apply **log transformation**:\n",
    "   $$\n",
    "   X' = \\log(X_{\\text{reflected}} + c)\n",
    "   $$\n",
    "3. Reflect back to original scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc8557",
   "metadata": {},
   "source": [
    "## Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef5d631",
   "metadata": {},
   "source": [
    "Skewness measures the asymmetry of the distribution of a dataset. It describes whether the data has **heavy tails (high kurtosis)** or **light tails (low kurtosis)**. A normal distribution has a **kurtosis of 3** (excess kurtosis = 0), lower means there are less extreme observation values, and higher means there are more. More can be a problem as it may impact the distribution (if the values are not consistent with the actual distribution), and not enough can result in the model not sufficiently understanding the distribution.\n",
    "\n",
    "$$\n",
    "\\text{Kurtosis} = \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{s} \\right)^4 - \\frac{3(n-1)^2}{(n-2)(n-3)}\n",
    "$$\n",
    "\n",
    "\n",
    "### Interpretation:\n",
    "- **Kurtosis ≈ 3** → Normal distribution (**Mesokurtic**)\n",
    "- **Kurtosis > 3** → Heavy tails, more extreme outliers (**Leptokurtic**)\n",
    "- **Kurtosis < 3** → Light tails, fewer outliers (**Platykurtic**)\n",
    "\n",
    "---\n",
    "\n",
    "### **1️ Fixing High Kurtosis (Heavy Tails)**\n",
    "\n",
    "#### **1. Winsorization (Clipping Extreme Values)**\n",
    "Winsorization limits extreme values to reduce their impact.\n",
    "\n",
    "$$\n",
    "X' = \n",
    "\\begin{cases} \n",
    "\\text{upper bound}, & X > \\text{upper threshold} \\\\\n",
    "\\text{lower bound}, & X < \\text{lower threshold} \\\\\n",
    "X, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cda889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "\n",
    "df['winsorized'] = winsorize(df['feature'], limits=[0.05, 0.05])  # Trim 5% from both ends\n",
    "\n",
    "df['power_transformed'] = np.power(df['feature'], 2)  # Square transformation\n",
    "df['exp_transformed'] = np.exp(df['feature'])  # Exponential transformation\n",
    "\n",
    "# Reflect and apply log transformation\n",
    "df['reflected'] = df['feature'].max() + df['feature'].min() - df['feature']\n",
    "df['log_reflected'] = np.log(df['reflected'] + 1)\n",
    "df['final_transformed'] = df['feature'].max() + df['feature'].min() - df['log_reflected']\n",
    "\n",
    "df['log_transformed'] = np.log(df['feature'] + 1)  # Avoid log(0)\n",
    "df['sqrt_transformed'] = np.sqrt(df['feature'])\n",
    "df['boxcox_transformed'], _ = boxcox(df['feature'] + 1)  # Apply Box-Cox\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853857f",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3aa0c2",
   "metadata": {},
   "source": [
    "### ** You Should Standardize If:**\n",
    "**You’re Using Distance-Based Algorithms**  \n",
    "   - Algorithms that rely on **distance metrics** (e.g., Euclidean, Manhattan) perform better when features are standardized.\n",
    "   - Examples:\n",
    "     - $K$-Nearest Neighbors (KNN)\n",
    "     - Support Vector Machines (SVM)\n",
    "     - Principal Component Analysis (PCA)\n",
    "     - $K$-Means Clustering\n",
    "     - Linear Regression (if gradient descent is used)\n",
    "\n",
    "**Your Features Have Different Scales**  \n",
    "   - If some features are on **very different scales**, standardization helps **prevent one feature from dominating the model**.\n",
    "   - Example:\n",
    "     - **Feature 1:** Age $(20$ to $80)$\n",
    "     - **Feature 2:** Salary $(20,000$ to $200,000)$\n",
    "   - **Without standardization**, the model might focus too much on salary because it has larger values.\n",
    "\n",
    "**You’re Using Regularization (Lasso, Ridge, ElasticNet)**  \n",
    "   - Standardization ensures that **penalty terms** ($L_1, L_2$) are applied **fairly across all features**.\n",
    "\n",
    " **Your Model is Sensitive to Outliers**  \n",
    "   - Standardizing data **reduces the impact of extreme values** by centering around zero.\n",
    "\n",
    "---\n",
    "\n",
    "### ** You Can Skip Standardization If:**\n",
    "**You’re Using Tree-Based Models**  \n",
    "   - **Decision Trees, Random Forests, Gradient Boosting (XGBoost, LightGBM, CatBoost)** **do not require standardization**.\n",
    "   - These models are not affected by feature magnitudes because they split data **based on thresholds, not distance**.\n",
    "\n",
    "**Your Features Are Already on Similar Scales**  \n",
    "   - If all features are on similar scales (e.g., all between $0$ and $1$), standardization may not add much value.\n",
    "\n",
    "**You’re Working with Categorical Variables**  \n",
    "   - Standardization applies only to **numerical features**.\n",
    "   - **One-hot encoded variables do not need standardization**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6f76e",
   "metadata": {},
   "source": [
    "## Summation Notation (Σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9323493",
   "metadata": {},
   "source": [
    "\n",
    "The summation of a sequence is defined as:\n",
    "\n",
    "$$\n",
    "S = \\sum_{i=1}^{n} a_i = a_1 + a_2 + \\dots + a_n\n",
    "$$\n",
    "\n",
    "##### Example Calculation:\n",
    "$$\n",
    "\\sum_{i=1}^{5} i = 1 + 2 + 3 + 4 + 5 = 15\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2900b669",
   "metadata": {},
   "source": [
    "## Unbiased Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c9e01e",
   "metadata": {},
   "source": [
    "An **unbiased estimator** is a statistical estimator whose expected value is equal to the parameter it is estimating. Formally, an estimator \\( \\hat{\\theta} \\) of a parameter \\( \\theta \\) is **unbiased** if:\n",
    "\n",
    "$$\n",
    "E[\\hat{\\theta}] = \\theta\n",
    "$$\n",
    "\n",
    "This means that, on average, the estimator correctly estimates the true parameter value.\n",
    "\n",
    "### **Example:**\n",
    "Consider a random sample \\( X_1, X_2, \\dots, X_n \\) drawn from a population with mean \\( \\mu \\). The sample mean:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^{n} X_i\n",
    "$$\n",
    "\n",
    "is an **unbiased estimator** of the population mean \\( \\mu \\), since:\n",
    "\n",
    "$$\n",
    "E[\\hat{\\mu}] = \\mu\n",
    "$$\n",
    "\n",
    "This implies that the expected value of the sample mean is equal to the true population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3496c3",
   "metadata": {},
   "source": [
    "## Variance Inflation Factor (VIF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f622a6",
   "metadata": {},
   "source": [
    "$$\n",
    "VIF_i = \\frac{1}{1 - R^2_i}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $VIF_i$ is the Variance Inflation Factor for the $i$th predictor variable.\n",
    "- $R_i^2$ is the coefficient of determination obtained by regressing $X_i$ on all the other independent variables in the model.\n",
    "\n",
    "\n",
    "## Interpretation of VIF\n",
    "\n",
    "\\[\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline\n",
    "\\textbf{VIF Value} & \\textbf{Interpretation} \\\\\n",
    "\\hline\n",
    "1 & No multicollinearity (ideal) \\\\\n",
    "\\hline\n",
    "1 - 5 & Low to moderate multicollinearity (acceptable) \\\\\n",
    "\\hline\n",
    "5 - 10 & High multicollinearity (requires investigation) \\\\\n",
    "\\hline\n",
    "> 10 & Severe multicollinearity (problematic, needs correction) \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\]\n",
    "\n",
    "## Handling High VIF\n",
    "- **Remove one of the correlated variables** (e.g., drop redundant predictors).\n",
    "- **Feature engineering** (e.g., combine correlated variables using PCA).\n",
    "- **Collect more data** (can sometimes reduce collinearity).\n",
    "- **Use Ridge Regression** (adds regularization to limit high coefficient values).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e86de1",
   "metadata": {},
   "source": [
    "## Requirements for Statistical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae89756e",
   "metadata": {},
   "source": [
    "#### Random\n",
    "- The sample must be **randomly selected** to avoid bias.\n",
    "\n",
    "#### Independent\n",
    "- Each observation must be **independent** of others.\n",
    "\n",
    "#### Sufficient Records\n",
    "- A larger sample **reduces variability** and provides **better estimates**. Small samples often lead to **higher standard errors** and **less reliable inferences**.\n",
    "\n",
    "#### Normal Distribution\n",
    "- Many tests (**t-test, ANOVA, regression**) assume **normally distributed data. If n is large**, normality is **less of a concern** (CLT applies).\n",
    "- **Shapiro-Wilk Test:** Checks for normality.\n",
    "- **Q-Q Plot:** Data should align with the diagonal.\n",
    "\n",
    "#### Homoscedasticity (Equal Variance) \n",
    "- The variance should be **constant** across different levels of the independent variable. Unequal variance (heteroscedasticity) can **bias standard errors**.\n",
    "- **Levene’s Test:** Tests for equal variances.\n",
    "- **Residual Plot:** If residuals show a **funnel shape**, variance is **not equal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fcc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "\n",
    "DATASCI203\n",
    "\n",
    "DATASCI 205 - t\n",
    "Difference in expectation\n",
    "Basic Set Up.\n",
    "Suppose (x1…) are I.i.d with mean Ux\n",
    "Suppose (y1…) are I.i.d with mean Uy\n",
    "\n",
    "Null Hyothesis Ux= Uy (the two populations means are equal)\n",
    "\n",
    "Alternative Hypothesis \n",
    "H1: ux ne uy ()\n",
    "H2 ux>uy\n",
    "H3 ux<uy\n",
    "\n",
    "Two-Sample t-Test: Technical whether two populations are the same in expectations while accounting for variability\n",
    "\n",
    "T = X-Y/ Estimate of Standard Deviation\n",
    "\n",
    "Specify Model, Null Hypothesis, Rejection Criteria\n",
    "Calculate Statistic\n",
    "Plot Statistic on the null distribution to get p value\n",
    "\n",
    "Students t-Test - Pooled Estimate\n",
    "Test is mean of X equals mean of Y.\n",
    "Uses pool estimate of Standard Deviation.\n",
    "Only relevant if standard deviations are the same\n",
    "Lavines Test to understand if std dev same. Limited value\n",
    "\n",
    "Welch’s t-Test\n",
    "Dof - complex.\n",
    "More general, don’t need standard deviations same\n",
    "\n",
    "Degrees of freedom - Number of independent pieces of information that vary given estimated parameters\n",
    "1 -sided - df = n-1\n",
    "2-sided - df = n1 +n2 - 2\n",
    "\n",
    "Which to use, Welch. Not worth benefit for limited value of Students.\n",
    "\n",
    "Correlation is a measure of linear dependence. Then, what are the possible values for correlation when one random variable is a linear function of another? To fix terms, suppose that X and Y\n",
    "Y are random variables, and a is a constant where a does not equal 0 and b is any constant in the real numbers. Furthermore, suppose that Y is a function of X that takes the following form: y = ax+b. What are the possible values for correlation between X and Y.\n",
    "\n",
    "Quantitative data is numbers-based, countable, or measurable. \n",
    "Qualitative data is interpretation-based, descriptive, and relating to language\n",
    "Empirical derived from or guided by direct experience or by experiment, rather than abstract principles or theory:\n",
    "\n",
    "Probability: Reasoning under uncertainty\n",
    "\n",
    "]All Models are wrong, some are useful.\n",
    "Subjective Probability: Someones assessment of what the probability is, based on the information that they have available\n",
    "\n",
    "Canonical: Mathematics. (of an equation, coordinate, etc.) in simplest or standard form.\n",
    "\n",
    "Axomatic Approach: (Thomas Kuhn). Start with Axiomatic Statements, move to intermediate statements, end with testable hypothesis \n",
    "Axomatic: pertaining to or of the nature of an axiom; self-evident; obvious.\n",
    "\n",
    "A/B - In A but Not in B\n",
    "AC - Compliment - Everything that isn’t this.\n",
    "\n",
    "Set: Contains Objects, Not Ordered, Can’t Repeat, Colon means such that, {},\n",
    "Is an element of, not an element of, empty set\n",
    "\n",
    "Probability theory is a mathematical construct used to represent processes involving randomness, unpredictability, or intrinsic uncertainty.\n",
    "\n",
    "In a setting in which there are several possible outcomes, each with some probability of occurring, we refer to the process by which the outcome is determined as a random generative process.\n",
    "\n",
    "\n",
    "Efficiency - Mean Square Error \n",
    "Approaches the true value, more quick, or more efficienctly (often) than other estimators\n",
    "\n",
    "Consistency - As you have more observations it progressively gets closer to the estimate\n",
    "\n",
    "IID - Independent and Identically distributed\n",
    "Formal Definition of “Random Sample”\n",
    "If each data you pull our comes from the sample probability distribution, identically distributed\n",
    "If none of the instances in the sample provide information about other instances of same, they are independent\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
