{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80cd7628-a8d5-49ac-9176-24bb758924d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c960a57-e23e-4d4a-9aa4-7eabde0acffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_notes_csv = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vSQF2lNc4WPeTRQ_VzWPkqSZp4RODFkbap8AqmolWp5bKoMaslP2oRVVG21x2POu_JcbF1tGRcBgodu/pub?output=csv'\n",
    "google_definition_csv = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQq1-3cTas8DCWBa2NKYhVFXpl8kLaFDohg0zMfNTAU_Fiw6aIFLWfA5zRem4eSaGPa7UiQvkz05loW/pub?output=csv'\n",
    "\n",
    "notes = pd.read_csv(google_notes_csv).fillna('')\n",
    "definitions = pd.read_csv(google_definition_csv).fillna('')\n",
    "\n",
    "ml_def = definitions.copy()\n",
    "ml_notes = notes[notes['Category']=='Machine Learning']\n",
    "\n",
    "from df_processing import notes_df_to_outline_html,final_dataset_for_markdown\n",
    "d = final_dataset_for_markdown(ml_notes,ml_def)\n",
    "d1 = notes_df_to_outline_html(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01144822-cb80-4ce7-8c67-6ce3d9c40a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<style>\\n    .notes-container {\\n    font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Arial;\\n    }\\n    .notes-item { line-height: 1.45; margin: 2px 0; }\\n\\n    .notes-l0 { font-size: 18px; font-weight: 600; margin-left: 0px; }\\n    .notes-l1 { font-size: 16px; font-weight: 500; margin-left: 18px; }\\n    .notes-l2 { font-size: 14px; font-weight: 400; margin-left: 36px; }\\n    .notes-l3 { font-size: 13px; font-weight: 400; margin-left: 54px; opacity: 0.85; }\\n    .notes-l4 { font-size: 12px; font-weight: 400; margin-left: 72px; opacity: 0.8; }\\n    </style>\\n\\n    <div class=\"notes-container\">\\n    <div class=\"notes-item notes-l0\">Machine Learning</div>\\n<div class=\"notes-item notes-l1\">• Definition</div>\\n<div class=\"notes-item notes-l2\">• Machine Learning</div>\\n<div class=\"notes-item notes-l3\">• Using a process to enable computers to iteratively learn from the data and improve analysis, outcomes or understanding. Intersection of statistics, artificial intelligence and computer science. Machine\\'s don\\'t learn, they find optimal mathematical formulas based on the data it is presented. There is an assumption that this data set is both representative of other data sets,  and possess similiar statistical distributions\\', You can argue this is not learning, because slight variances can result in materially different responses and output, Term synonymous with machines doing tasks without explicitly being programmed. Building a statistical model, based on a dataset</div>\\n<div class=\"notes-item notes-l1\">• Distinct Types of ML</div>\\n<div class=\"notes-item notes-l2\">• Supervised Learning</div>\\n<div class=\"notes-item notes-l3\">• Supervised learning trains a model using labeled data, where the correct answer is known in advance. The model learns a mapping from inputs to outputs by minimizing the difference between its predictions and the true labels. Common examples include classification and regression problems.</div>\\n<div class=\"notes-item notes-l2\">• Unsupervised Learning</div>\\n<div class=\"notes-item notes-l3\">• Unsupervised learning works with unlabeled data and aims to discover hidden patterns or structure. The model groups, compresses, or summarizes the data without being told what the correct outcome is. Typical use cases include clustering, dimensionality reduction, and anomaly detection.</div>\\n<div class=\"notes-item notes-l2\">• Semisupervised Learning</div>\\n<div class=\"notes-item notes-l3\">• Semi-supervised learning combines a small amount of labeled data with a large amount of unlabeled data to improve learning performance. The model leverages the structure in the unlabeled data to generalize better than supervised learning alone. This approach is useful when labeling data is expensive or time-consuming.</div>\\n<div class=\"notes-item notes-l2\">• Reinforcement Learning</div>\\n<div class=\"notes-item notes-l3\">• Reinforcement learning trains an agent to make decisions by interacting with an environment and receiving rewards or penalties. The agent learns a policy that maximizes cumulative reward over time through trial and error. It is commonly used in robotics, game playing, and control systems.</div>\\n<div class=\"notes-item notes-l1\">• Optimization</div>\\n<div class=\"notes-item notes-l2\">• Optimization</div>\\n<div class=\"notes-item notes-l3\">• Optimization is the process of finding the best possible solution to a problem by systematically adjusting inputs or decisions to maximize or minimize a defined objective, subject to given constraints. In machine learning and analytics, optimization involves selecting model parameters that minimize error or maximize performance according to a chosen loss function. Importantly, what is considered “best” depends entirely on how the objective and constraints are defined.</div>\\n<div class=\"notes-item notes-l2\">• Goal</div>\\n<div class=\"notes-item notes-l3\">• What are you attempting to maximize, Training Performance, or ability to Generalize.  Strive to avoid overfitting, maximize ability to Generalize.</div>\\n<div class=\"notes-item notes-l2\">• Approach</div>\\n<div class=\"notes-item notes-l3\">• Curse of Dimensionality</div>\\n<div class=\"notes-item notes-l2\">• Important to Remember</div>\\n<div class=\"notes-item notes-l3\">• Must remember what the Model is actually trying to solve and the approach that it is taking. As an example, when Regularization is imporant, when it is not.</div>\\n<div class=\"notes-item notes-l3\">• Models will cheat and can solve problems which appear to be optimal, but they might not be solving what you expect or require, they might be finding patterns in the data which you do not see.</div>\\n<div class=\"notes-item notes-l3\">• An Example of this would a classification model with Wolves and Dogs,  many wolf photos happened to be taken in snowy environments, while dog photos were often taken indoors or on grass. The model learned to detect snow, not animals.</div>\\n<div class=\"notes-item notes-l2\">• Algorithm</div>\\n<div class=\"notes-item notes-l3\">• Adadelta</div>\\n<div class=\"notes-item notes-l3\">• Adagrad</div>\\n<div class=\"notes-item notes-l3\">• Adam</div>\\n<div class=\"notes-item notes-l3\">• AdamW</div>\\n<div class=\"notes-item notes-l3\">• Hinge Loss</div>\\n<div class=\"notes-item notes-l3\">• Huber Loss</div>\\n<div class=\"notes-item notes-l3\">• Momentum</div>\\n<div class=\"notes-item notes-l3\">• Nadam</div>\\n<div class=\"notes-item notes-l3\">• RMSprop</div>\\n<div class=\"notes-item notes-l1\">• Evaluation</div>\\n<div class=\"notes-item notes-l2\">• Cross Validation</div>\\n<div class=\"notes-item notes-l3\">• Splitting Data into K Folds.</div>\\n<div class=\"notes-item notes-l2\">• Stratified Cross Validation</div>\\n<div class=\"notes-item notes-l3\">• Splitting Data into statistically represented folds. If you can assume data is IID, then generally would not be required or benefitical, however it might be determined necessary and thus can be considered.</div>\\n<div class=\"notes-item notes-l2\">• Confusion Matrix</div>\\n<div class=\"notes-item notes-l2\">• Accuracy</div>\\n<div class=\"notes-item notes-l3\">• Generally not a preferred metric, Especially as it relates to Balance Datasets, where picking the underrepresented class is always a challenge.</div>\\n<div class=\"notes-item notes-l2\">• Decision Scores</div>\\n<div class=\"notes-item notes-l3\">• Scores from the Actual Decision Boundary. Provides Opportunity to Adjust position of Precsion/ Recall Trade Off.</div>\\n<div class=\"notes-item notes-l2\">• predict_proba</div>\\n<div class=\"notes-item notes-l3\">• Specifcally for Decision Trees</div>\\n<div class=\"notes-item notes-l1\">• Concepts</div>\\n<div class=\"notes-item notes-l2\">• Key Terms</div>\\n<div class=\"notes-item notes-l3\">• #### Need to Automate this #####\\nBaggin, Kernel Trick, Momentum, Gradient Propogation, Batch Normalization, Residual Connections, Overfit, Underfit, Bias, Variance, Bias Variance Trade. Off, Depthwise Seperable Connections, Loss Function, Polynominal Regression, Elastic Net, Early Stopping,</div>\\n<div class=\"notes-item notes-l1\">• Models</div>\\n<div class=\"notes-item notes-l2\">• Models</div>\\n<div class=\"notes-item notes-l3\">• Also used as a regularization, sometimes only as regularization. Only added during Training. Model Weights Close to 0.L2</div>\\n<div class=\"notes-item notes-l2\">• Linear Regression</div>\\n<div class=\"notes-item notes-l3\">• Closed Form Solution. Python Linear Regression utilizies Pseudoinverse, which is computationally less expensive. However, it is Big O 2² to 2³, which means doubling features increases computations complexity 4 times.</div>\\n<div class=\"notes-item notes-l2\">• Convolutional Neural Network</div>\\n<div class=\"notes-item notes-l2\">• Large Language Models</div>\\n<div class=\"notes-item notes-l2\">• Recurrent Neural Network</div>\\n<div class=\"notes-item notes-l2\">• Transformers</div>\\n<div class=\"notes-item notes-l1\">• Deep Learning</div>\\n<div class=\"notes-item notes-l3\">• Helps to Automate Feature Engineering</div>\\n<div class=\"notes-item notes-l2\">• Evolution</div>\\n<div class=\"notes-item notes-l3\">• Historical Issue of gradient propogration where signal would fade through the layers was solved through, better activation functions, optimization schemes and weight initializing.</div>\\n<div class=\"notes-item notes-l2\">• Framework</div>\\n<div class=\"notes-item notes-l3\">• Core building block is the layer, a filter which creates a representation, can chain simple layers into a complex one.</div>\\n<div class=\"notes-item notes-l2\">• Model</div>\\n<div class=\"notes-item notes-l3\">• Model starts with determining the number of layers, type of connections, and activation functions. Once model is defined, to comile need to determine, Optimizer, Loss Function and Metric.</div>\\n<div class=\"notes-item notes-l1\">• Lesson Learnt</div>\\n<div class=\"notes-item notes-l2\">• Always Have a Simple Baseline</div>\\n<div class=\"notes-item notes-l3\">• Need a reference to test performance of the model. If dataset is imbalanced, have simple guess. If temperature, guess trailing average, etc, find something simple, often very difficutl to beat, and juice might not be worth the squeeze.</div>\\n<div class=\"notes-item notes-l1\">• Downside</div>\\n<div class=\"notes-item notes-l2\">• Simplicity Not Assumed</div>\\n<div class=\"notes-item notes-l3\">• ML can\\'t look naively for a simple common sense solution. Unless feature engineered or hard coded, model will always just plug forward.</div>\\n<div class=\"notes-item notes-l1\">• Feature Selection</div>\\n<div class=\"notes-item notes-l2\">• Avoid Ambigious Features</div>\\n<div class=\"notes-item notes-l3\">• Is a Banana Ripe? Who Says So.</div>\\n<div class=\"notes-item notes-l2\">• Careful if Genuinely Random</div>\\n<div class=\"notes-item notes-l3\">• Atmospheric Change</div>\\n<div class=\"notes-item notes-l2\">• Data Quality Input</div>\\n<div class=\"notes-item notes-l3\">• MNIST performance when tilting Images, of adding noise.</div>\\n<div class=\"notes-item notes-l2\">• Relevance</div>\\n<div class=\"notes-item notes-l3\">• Any data set can be optimized, even when there is NO relation. It will generalize.</div>\\n<div class=\"notes-item notes-l1\">• Tool</div>\\n<div class=\"notes-item notes-l2\">• PyTorch</div>\\n<div class=\"notes-item notes-l3\">• Favored in research and academia because of its eager execution (you can run and debug step by step like normal Python)</div>\\n<div class=\"notes-item notes-l3\">• Pythonic, intuitive, and integrates seamlessly with libraries like NumPy</div>\\n<div class=\"notes-item notes-l3\">• Great for experimentation, quick prototyping, and custom model development.</div>\\n<div class=\"notes-item notes-l2\">• TensorFlow</div>\\n<div class=\"notes-item notes-l3\">• Stronger in production/industry, especially with enterprise systems.</div>\\n<div class=\"notes-item notes-l3\">• TensorFlow Serving, TensorFlow Lite (for mobile/edge), and TensorFlow.js (for web) make it great for deployment</div>\\n<div class=\"notes-item notes-l3\">• High-level, user-friendly API for building models quickly.</div>\\n</div>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
