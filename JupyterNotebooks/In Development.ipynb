{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db749084-a457-4777-bc10-e5b85ab8843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=10000)\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "d = dict([(value,key) for (key,value) in word_index.items()])\n",
    "\n",
    "\" \".join([d.get(i-3,\"?\") for i in X_train[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931fc797-4d23-4955-a866-ec57a054088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def CreateCalculatedField(df, primary_key, calc_instructions, include_all=1):\n",
    "\n",
    "    '''\n",
    "    calc_instructions = [\n",
    "    {'type': 'sum', 'value1': 'LENDING', 'name': 'TOTAL_LENDING'},\n",
    "    {'type': 'weighted_average', 'value1': 'LENDING', 'value2': 'INTEREST_RATE', 'name': 'WEIGHTED_INTEREST'},\n",
    "    {'type': 'ratio', 'value1': 'RENEWED_AMOUNT', 'value2': 'MATURED_AMOUNT', 'name': 'RENEWAL_RATE'}\n",
    "    ]\n",
    "\n",
    "    output = CreateCalculatedField(final_df, ['BRANCHNAME', 'CITY', 'LOB', 'DURATION'], calc_instructions)\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    base_aggs = {}\n",
    "    \n",
    "    # Collect all fields we need\n",
    "    for calc in calc_instructions:\n",
    "        if calc['type'] == 'sum':\n",
    "            base_aggs[calc['name']] = (calc['value1'], 'sum')\n",
    "        elif calc['type'] == 'weighted_average':\n",
    "            base_aggs[f\"__{calc['name']}_NUM\"] = (\n",
    "                calc['value2'], lambda x, col=calc['value1']: (df.loc[x.index, col] * x).sum()\n",
    "            )\n",
    "            base_aggs[f\"__{calc['name']}_DEN\"] = (calc['value1'], 'sum')\n",
    "        elif calc['type'] == 'ratio':\n",
    "            base_aggs[f\"__{calc['name']}_NUM\"] = (calc['value1'], 'sum')\n",
    "            base_aggs[f\"__{calc['name']}_DEN\"] = (calc['value2'], 'sum')\n",
    "\n",
    "    # Base groupby\n",
    "    grouped = df.groupby(primary_key, dropna=False).agg(**base_aggs).reset_index()\n",
    "\n",
    "    # Compute post-aggregates\n",
    "    for calc in calc_instructions:\n",
    "        if calc['type'] == 'sum':\n",
    "            continue\n",
    "        elif calc['type'] == 'weighted_average':\n",
    "            num = grouped[f\"__{calc['name']}_NUM\"]\n",
    "            den = grouped[f\"__{calc['name']}_DEN\"]\n",
    "            grouped[calc['name']] = np.where(den != 0, num / den, np.nan)\n",
    "            grouped.drop(columns=[f\"__{calc['name']}_NUM\", f\"__{calc['name']}_DEN\"], inplace=True)\n",
    "        elif calc['type'] == 'ratio':\n",
    "            num = grouped[f\"__{calc['name']}_NUM\"]\n",
    "            den = grouped[f\"__{calc['name']}_DEN\"]\n",
    "            grouped[calc['name']] = np.where(den != 0, num / den, np.nan)\n",
    "            grouped.drop(columns=[f\"__{calc['name']}_NUM\", f\"__{calc['name']}_DEN\"], inplace=True)\n",
    "\n",
    "    result_frames = [grouped.copy()]\n",
    "\n",
    "    # Rollup combinations\n",
    "    if include_all:\n",
    "        for r in range(1, len(primary_key)):\n",
    "            for group_cols in combinations(primary_key, r):\n",
    "                temp = df.copy()\n",
    "                for col in primary_key:\n",
    "                    if col not in group_cols:\n",
    "                        temp[col] = 'All'\n",
    "                temp_group = CreateCalculatedField(temp, primary_key, calc_instructions, include_all=0)\n",
    "                result_frames.append(temp_group)\n",
    "\n",
    "        # Full 'All' row\n",
    "        temp = df.copy()\n",
    "        for col in primary_key:\n",
    "            temp[col] = 'All'\n",
    "        temp_group = CreateCalculatedField(temp, primary_key, calc_instructions, include_all=0)\n",
    "        result_frames.append(temp_group)\n",
    "\n",
    "    return pd.concat(result_frames, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "calc_instructions = [\n",
    "    {'type': 'sum', 'value1': 'LENDING', 'name': 'TOTAL_LENDING'},\n",
    "    {'type': 'weighted_average', 'value1': 'LENDING', 'value2': 'INTEREST_RATE', 'name': 'WEIGHTED_INTEREST'},\n",
    "    {'type': 'ratio', 'value1': 'RENEWED_AMOUNT', 'value2': 'MATURED_AMOUNT', 'name': 'RENEWAL_RATE'}\n",
    "]\n",
    "\n",
    "output = CreateCalculatedField(final_df, ['BRANCHNAME', 'CITY', 'LOB', 'DURATION'], calc_instructions)\n",
    "\n",
    "output\n",
    "\\\n",
    "from itertools import product,permutations,combinations\n",
    "\n",
    "\n",
    "branches = ['Fenway Park','Wrigely Field','The Forum','Maple Leaf Gardens','GM Place','Safeco','Lambeau Stadium']\n",
    "city = ['Boston','Chicago','Philly','Toronto','Vancouver','Chicago','Seattle','Green Bay']\n",
    "lob = ['Retail','Corporate','Mid Market']\n",
    "duration = ['1) Less than 30d','2) 30D - 1Y', '3) 1Y - 5Y','4)5Y+']\n",
    "list_of_lists = [branches,city,lob,duration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024edca-2193-4cae-adc0-6b29f5a96c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSets import GenerateFakeMemberDF\n",
    "\n",
    "\n",
    "\n",
    "df = GenerateFakeMemberDF(100,20)\n",
    "\n",
    "\n",
    "branches = ['Fenway Park','Wrigely Field','The Forum','Maple Leaf Gardens','GM Place','Safeco','Lambeau Stadium']\n",
    "city = ['Boston','Chicago','Philly','Toronto','Vancouver','Chicago','Seattle','Green Bay']\n",
    "lob = ['Retail','Corporate','Mid Market']\n",
    "duration = ['1) Less than 30d','2) 30D - 1Y', '3) 1Y - 5Y','4)5Y+']\n",
    "\n",
    "list_of_lists = [branches,city,lob,duration]\n",
    "\n",
    "df1 = pd.DataFrame(df['MEMBERNBR'].unique(),columns=['MEMBERNBR'])\n",
    "df1['BRANCHNAME'] = [np.random.choice(branches) for x in range(len(df1))]\n",
    "df1['CITY'] = [np.random.choice(city) for x in range(len(df1))]\n",
    "df1['LOB'] = [np.random.choice(lob) for x in range(len(df1))]\n",
    "df1['DURATION'] = [np.random.choice(duration) for x in range(len(df1))]\n",
    "\n",
    "final_df = df.merge(df1,on='MEMBERNBR',how='left')\n",
    "final_df['INTEREST_RATE'] = final_df['MONTH'].apply(lambda x:np.random.uniform(0.02, 0.07))\n",
    "final_df['MATURED_AMOUNT'] = final_df['LENDING'].apply(lambda x:x*np.random.uniform(0, 1)) \n",
    "final_df['RENEWED_AMOUNT'] = final_df['MATURED_AMOUNT'].apply(lambda x:x*.95) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f0576-1d0c-484c-a3fb-313b04f102fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import difflib\n",
    "\n",
    "def compare_functions(func1, func2):\n",
    "    f1_lines = inspect.getsource(func1).splitlines()\n",
    "    f2_lines = inspect.getsource(func2).splitlines()\n",
    "    diff = difflib.unified_diff(f1_lines, f2_lines, lineterm='')\n",
    "    return '\\n'.join(diff)\n",
    "\n",
    "compare_functions(ColumnStatisticalReview,ColumnStatisticalReview1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35864245-c2f6-45e9-914c-15cce04a8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSets import GenerateFakeMemberDF\n",
    "from FeatureEngineering import CreateRandomDFColumn\n",
    "df = GenerateFakeMemberDF(10000,12)\n",
    "CreateRandomDFColumn(df,['Fenway','Yankee Stadium','Wrigly'],'Stadium')\n",
    "CreateRandomDFColumn(df,['John','Mark','Harry','Sally'],'Vendor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2fe730-5f75-4915-bb34-00d878c1c555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     text                     cleaned\n",
      "0  Transaction from BCCA001 and ONCA-fund  Transaction from and -fund\n",
      "1                  Nothing to remove here      Nothing to remove here\n",
      "2                    Another bcca999 item                Another item\n",
      "3                   Words withonca inside                Words inside\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text': [\n",
    "        'Transaction from BCCA001 and ONCA-fund',\n",
    "        'Nothing to remove here',\n",
    "        'Another bcca999 item',\n",
    "        'Words withonca inside'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Regex to remove entire words containing 'bcca' or 'onca' (case-insensitive)\n",
    "pattern = r'\\b\\w*(bcca|onca)\\w*\\b'\n",
    "\n",
    "# Clean the text\n",
    "df['cleaned'] = df['text'].str.replace(pattern, '', regex=True, case=False).str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d05a0d3-ab6b-4c87-bb75-9b1b23efc5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "\n",
    "\n",
    "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "plt.vlines(threshold, 0, 1.0, \"k\", \"dotted\", label=\"threshold\")\n",
    "[...]  # beautify the figure: add grid, legend, axis, labels, and circles\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(recalls, precisions, linewidth=2, label=\"Precision/Recall curve\")\n",
    "[...]  # beautify the figure: add labels, grid, legend, arrow, and text\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\n",
    "plt.show()\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,\n",
    "                                        normalize=\"true\", values_format=\".0%\")\n",
    "plt.show()\n",
    "\n",
    "sample_weight = (y_train_pred != y_train)\n",
    "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,\n",
    "                                        sample_weight=sample_weight,\n",
    "                                        normalize=\"true\", values_format=\".0%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8869b7ae-29ce-4244-8d59-12143afaa1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digit(image_data):\n",
    "    image = image_data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "some_digit = X[0]\n",
    "plot_digit(some_digit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb2e90-c48e-4eb4-9fd2-5456c8a3547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['DEPOSIT','LENDING','TXN_COUNT','TXN_VALUE','RECORD_COUNT']\n",
    "index=['BRANCHNAME','CITY','LOB','DURATION']\n",
    "\n",
    "column='MONTH'\n",
    "\n",
    "final_df['RECORD_COUNT']=1\n",
    "\n",
    "def CreateMultiplePivotTableFromTimeSeries(df,index_list,metric_list,column):\n",
    "    '''\n",
    "    Function to utilize when Attempting to Create Multip[le Times Series. Specifically Multiple Metrics, and Multiple Index's\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through all Possible Metrics Selected.\n",
    "    for metric in metric_list:\n",
    "        all_df = CreatePivotTableFromTimeSeries(df=df,index=None,columns=column,values=metric,aggfunc='sum') \n",
    "        cols = list(all_df.columns)\n",
    "        all_df = all_df.reset_index(drop=True)\n",
    "        all_df['METRIC'] = metric\n",
    "        cols.insert(0,'METRIC')\n",
    "\n",
    "        for key in index:\n",
    "            cols.insert(0,key)\n",
    "            all_df[key] = 'All'\n",
    "\n",
    "        final_df = pd.concat([final_df,all_df[cols]])\n",
    "\n",
    "        # Iterate through all Index Items Individually\n",
    "        for key in index_list:\n",
    "            temp = CreatePivotTableFromTimeSeries(df,index=key,\n",
    "                                                  values=metric,\n",
    "                                                  columns=column).reset_index() \n",
    "            for missing in [x for x in index if x != key]:\n",
    "                temp[missing] = 'All'\n",
    "            temp['METRIC'] = metric\n",
    "            final_df = pd.concat([final_df,temp])\n",
    "        \n",
    "        # Add Value for Metric with Entire Index Combination\n",
    "        temp = CreatePivotTableFromTimeSeries(df,index=index_list,values=metric,columns=column).reset_index()\n",
    "        temp['METRIC'] = metric\n",
    "        final_df = pd.concat([final_df,temp])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "e = CreateMultiplePivotTableFromTimeSeries(df=final_df[final_df['MONTH']<3],\n",
    "                                       index_list= index,\n",
    "                                       metric_list=metrics,\n",
    "                                       column= 'MONTH')\n",
    "\n",
    "\n",
    "def CreatePivotTableFromTimeSeries(df,\n",
    "                                   index,\n",
    "                                   columns,\n",
    "                                   values,\n",
    "                                   aggfunc='sum',\n",
    "                                   skipna=True):\n",
    "    \n",
    "    '''\n",
    "    Function to Summaryize a Time Series Dataframe into a Pivot. Creating a number of critical Metrics.\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1. Pivot\n",
    "    if index==None:\n",
    "        df1 = df.pivot_table(columns=columns,values=values,aggfunc=aggfunc)\n",
    "    else:\n",
    "        df1 = df.pivot_table(index=index, columns=columns, values=values, aggfunc=aggfunc)\n",
    "\n",
    "    # 2. Capture original month columns IMMEDIATELY after pivot\n",
    "    month_cols = df1.columns.tolist()\n",
    " \n",
    "    # 3. Add rolling window stats\n",
    "    if len(month_cols) >= 3:\n",
    "        df1['AVG_3M'] = df1[month_cols[-3:]].mean(axis=1, skipna=skipna)\n",
    "        df1['CHG_3M'] = df1[month_cols[-1]]-df1[month_cols[-3]]\n",
    "        try:\n",
    "            df1['PERC_CHG_3M'] = df1['CHG_3M']/df1[month_cols[-3]]\n",
    "        except:\n",
    "            df1['PERC_CHG_3M'] = 0\n",
    "    \n",
    "    if len(month_cols) >= 6:\n",
    "        df1['AVG_6M'] = df1[month_cols[-6:]].mean(axis=1, skipna=skipna)\n",
    "        df1['CHG_6M'] = df1[month_cols[-1]]-df1[month_cols[-6]]\n",
    "        try:\n",
    "            df1['PERC_CHG_6M'] = df1['CHG_6M']/df1[month_cols[-6]]\n",
    "        except:\n",
    "            df1['PERC_CHG_6M'] = 0\n",
    "            \n",
    "    if len(month_cols) >= 12:\n",
    "        df1['AVG_12M'] = df1[month_cols[-12:]].mean(axis=1, skipna=skipna)\n",
    "        df1['CHG_12M'] = df1[month_cols[-1]]-df1[month_cols[-12]]\n",
    "        try:\n",
    "            df1['PERC_CHG_12M'] = df1['CHG_12M']/df1[month_cols[-12]]\n",
    "        except:\n",
    "            df1['PERC_CHG_12M'] = 0\n",
    "\n",
    "    df1['CHG_DF']  = df1[month_cols[-1]]-df1[month_cols[0]]\n",
    "    df1['AVG_DF'] = df1[month_cols[-1:]].mean(axis=1, skipna=skipna)\n",
    "    df1['PERC_CHG_DF'] = df1['AVG_DF']/df1[month_cols[-1]]\n",
    "\n",
    "    \n",
    "    # 4. Now calculate global stats **only using the original month columns**\n",
    "    stats = pd.DataFrame({\n",
    "        'MEAN': df1[month_cols].mean(axis=1, skipna=skipna),\n",
    "        'STD': df1[month_cols].std(axis=1, skipna=skipna),\n",
    "        'MAX': df1[month_cols].max(axis=1, skipna=skipna),\n",
    "        'MIN': df1[month_cols].min(axis=1, skipna=skipna),\n",
    "        'COUNT': df1[month_cols].count(axis=1)\n",
    "    })\n",
    "\n",
    "    # 5. Merge the stats\n",
    "    df1 = pd.concat([df1, stats], axis=1)\n",
    "    \n",
    "    return df1.fillna(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
