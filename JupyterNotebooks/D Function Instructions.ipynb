{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df8f921-74c2-42ed-945b-b7b845cffb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed Multithread Processing from Read Directory. Need to have displine and Principles related to \n",
    "# Creation of Functions, Create Individual functions which do components, opposed to long ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e33665-a40f-4bdb-a2d0-52dc7bf6a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d30fde-68b1-4519-8063-a6f1f5bae569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared_folder import ReadDirectory\n",
    "d_py_function =  '/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions/'\n",
    "ReadDirectory(d_py_function)\n",
    "\n",
    "# Import a .TXT or .PY File\n",
    "location = '/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions/shared_folder.py'\n",
    "\n",
    "from shared_folder import TextFileImport\n",
    "file = TextFileImport(location)\n",
    "\n",
    "from shared_folder import ParseDDotPYFile\n",
    "function_list, function_parameters = ParseDDotPYFile(file)\n",
    "\n",
    "## Generate a Summary File for a Folder.\n",
    "from shared_folder import ParseDDotPYFolder\n",
    "\n",
    "function_list, function_parameters = ParseDDotPYFolder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5884924f-39b5-48f0-8c84-07c076e9b10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Returns</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_last_modified</th>\n",
       "      <th>classification</th>\n",
       "      <th>sub_classification</th>\n",
       "      <th>usage</th>\n",
       "      <th>Folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convert_dict_to_parameters</td>\n",
       "      <td>Convert a .py file containing Lists into a Dat...</td>\n",
       "      <td>[module]</td>\n",
       "      <td>Dataframe</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>import d_dictionaries\\ntemp = convertlisttopar...</td>\n",
       "      <td>dict_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dict_to_dataframe</td>\n",
       "      <td>Function to Simplify the creation of a Diction...</td>\n",
       "      <td>[dict_, key_name, value_name]</td>\n",
       "      <td>Dataframe</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>temp_df = dict_to_dataframe(dict)</td>\n",
       "      <td>dict_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ReadDirectory</td>\n",
       "      <td>Function which reads reads a directory and ret...</td>\n",
       "      <td>[location, file_type, match_str]</td>\n",
       "      <td>Dataframe containing a listing of selected files.</td>\n",
       "      <td>3-Dec-25</td>\n",
       "      <td>3-Dec-25</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>d_py_function =  '/Users/derekdewald/Documents...</td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TextFileImport</td>\n",
       "      <td>Function Used to Import .txt or .py File into ...</td>\n",
       "      <td>[file_name, encoding]</td>\n",
       "      <td>Str</td>\n",
       "      <td>3-Dec-25</td>\n",
       "      <td>3-Dec-25</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>location = '/Users/derekdewald/Documents/Pytho...</td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ParseDDotPYFile</td>\n",
       "      <td>Function which reads a Python file (as text) a...</td>\n",
       "      <td>[file_text]</td>\n",
       "      <td>function_list (DataFrame): One row per functio...</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>function_list, function_parameters = ParseDDot...</td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ParseDDotPYFolder</td>\n",
       "      <td>Function which Allows for the Quick Review of ...</td>\n",
       "      <td>[location]</td>\n",
       "      <td>DataFrame</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>function_list, function_parameters = ParseDDot...</td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>create_py_table_dict</td>\n",
       "      <td>Function which Generates a Dataframe represent...</td>\n",
       "      <td>[base_location]</td>\n",
       "      <td>DataFrame</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>python_function_dict_df = create_py_table_dict()</td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convert_list_to_parameters</td>\n",
       "      <td>Convert a .py file containing Lists into a Dat...</td>\n",
       "      <td>[module]</td>\n",
       "      <td>Dataframe</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>import d_lists\\ntemp = convertlisttoparameters...</td>\n",
       "      <td>list_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list_to_dataframe</td>\n",
       "      <td>Function to Simplify the creation of a Diction...</td>\n",
       "      <td>[list_, column_name_list]</td>\n",
       "      <td>Object Type</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>temp_df = list_to_dataframe(dict)</td>\n",
       "      <td>list_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convert_str_to_parameters</td>\n",
       "      <td>Convert a .py file containing Strings into a D...</td>\n",
       "      <td>[module]</td>\n",
       "      <td>Dataframe</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>4-Dec-25</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>import d_strings`aaax\\ntemp = convertlisttopar...</td>\n",
       "      <td>string_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvertListtoSQLText</td>\n",
       "      <td>Function to convert a python list into SQL cod...</td>\n",
       "      <td>[list_, return_value, column_name, sql_query]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>generate_create_table_sql</td>\n",
       "      <td>Function to create a SQL Statement to Create a...</td>\n",
       "      <td>[df, table_name, schema, db]</td>\n",
       "      <td>- str: SQL CREATE TABLE statement</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TableRecordCountByDate</td>\n",
       "      <td>Generate a SQL Server query to count records b...</td>\n",
       "      <td>[table_dict, end_date, total_days]</td>\n",
       "      <td>str: A full SQL query string.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Function  \\\n",
       "0  convert_dict_to_parameters   \n",
       "1           dict_to_dataframe   \n",
       "0               ReadDirectory   \n",
       "1              TextFileImport   \n",
       "2             ParseDDotPYFile   \n",
       "3           ParseDDotPYFolder   \n",
       "4        create_py_table_dict   \n",
       "0  convert_list_to_parameters   \n",
       "1           list_to_dataframe   \n",
       "0   convert_str_to_parameters   \n",
       "0        ConvertListtoSQLText   \n",
       "1   generate_create_table_sql   \n",
       "2      TableRecordCountByDate   \n",
       "\n",
       "                                             Purpose  \\\n",
       "0  Convert a .py file containing Lists into a Dat...   \n",
       "1  Function to Simplify the creation of a Diction...   \n",
       "0  Function which reads reads a directory and ret...   \n",
       "1  Function Used to Import .txt or .py File into ...   \n",
       "2  Function which reads a Python file (as text) a...   \n",
       "3  Function which Allows for the Quick Review of ...   \n",
       "4  Function which Generates a Dataframe represent...   \n",
       "0  Convert a .py file containing Lists into a Dat...   \n",
       "1  Function to Simplify the creation of a Diction...   \n",
       "0  Convert a .py file containing Strings into a D...   \n",
       "0  Function to convert a python list into SQL cod...   \n",
       "1  Function to create a SQL Statement to Create a...   \n",
       "2  Generate a SQL Server query to count records b...   \n",
       "\n",
       "                                      Parameters  \\\n",
       "0                                       [module]   \n",
       "1                  [dict_, key_name, value_name]   \n",
       "0               [location, file_type, match_str]   \n",
       "1                          [file_name, encoding]   \n",
       "2                                    [file_text]   \n",
       "3                                     [location]   \n",
       "4                                [base_location]   \n",
       "0                                       [module]   \n",
       "1                      [list_, column_name_list]   \n",
       "0                                       [module]   \n",
       "0  [list_, return_value, column_name, sql_query]   \n",
       "1                   [df, table_name, schema, db]   \n",
       "2             [table_dict, end_date, total_days]   \n",
       "\n",
       "                                             Returns date_created  \\\n",
       "0                                          Dataframe     4-Dec-25   \n",
       "1                                          Dataframe     4-Dec-25   \n",
       "0  Dataframe containing a listing of selected files.     3-Dec-25   \n",
       "1                                                Str     3-Dec-25   \n",
       "2  function_list (DataFrame): One row per functio...     4-Dec-25   \n",
       "3                                          DataFrame     4-Dec-25   \n",
       "4                                          DataFrame     4-Dec-25   \n",
       "0                                          Dataframe     4-Dec-25   \n",
       "1                                        Object Type     4-Dec-25   \n",
       "0                                          Dataframe     4-Dec-25   \n",
       "0                                               None         None   \n",
       "1                  - str: SQL CREATE TABLE statement         None   \n",
       "2                      str: A full SQL query string.         None   \n",
       "\n",
       "  date_last_modified classification sub_classification  \\\n",
       "0           4-Dec-25            TBD                TBD   \n",
       "1           4-Dec-25            TBD                TBD   \n",
       "0           3-Dec-25            TBD                TBD   \n",
       "1           3-Dec-25            TBD                TBD   \n",
       "2           4-Dec-25            TBD                TBD   \n",
       "3           4-Dec-25            TBD                TBD   \n",
       "4           4-Dec-25            TBD                TBD   \n",
       "0           4-Dec-25            TBD                TBD   \n",
       "1           4-Dec-25            TBD                TBD   \n",
       "0           4-Dec-25            TBD                TBD   \n",
       "0               None           None               None   \n",
       "1               None           None               None   \n",
       "2               None           None               None   \n",
       "\n",
       "                                               usage                Folder  \n",
       "0  import d_dictionaries\\ntemp = convertlisttopar...    dict_processing.py  \n",
       "1                  temp_df = dict_to_dataframe(dict)    dict_processing.py  \n",
       "0  d_py_function =  '/Users/derekdewald/Documents...      shared_folder.py  \n",
       "1  location = '/Users/derekdewald/Documents/Pytho...      shared_folder.py  \n",
       "2  function_list, function_parameters = ParseDDot...      shared_folder.py  \n",
       "3  function_list, function_parameters = ParseDDot...      shared_folder.py  \n",
       "4   python_function_dict_df = create_py_table_dict()      shared_folder.py  \n",
       "0  import d_lists\\ntemp = convertlisttoparameters...    list_processing.py  \n",
       "1                  temp_df = list_to_dataframe(dict)    list_processing.py  \n",
       "0  import d_strings`aaax\\ntemp = convertlisttopar...  string_processing.py  \n",
       "0                                               None               sql_.py  \n",
       "1                                               None               sql_.py  \n",
       "2                                               None               sql_.py  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a589e37-c6f7-47bd-b6e6-67e882e75ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Type</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convert_dict_to_parameters</td>\n",
       "      <td>module</td>\n",
       "      <td>module</td>\n",
       "      <td>Py file containing Lists.</td>\n",
       "      <td>dict_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dict_to_dataframe</td>\n",
       "      <td>dict_</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>dict_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dict_to_dataframe</td>\n",
       "      <td>key_name</td>\n",
       "      <td>str</td>\n",
       "      <td>Name of Column which will include values from ...</td>\n",
       "      <td>dict_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dict_to_dataframe</td>\n",
       "      <td>value_name</td>\n",
       "      <td>str</td>\n",
       "      <td>Name of Column which will include values from ...</td>\n",
       "      <td>dict_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ReadDirectory</td>\n",
       "      <td>location</td>\n",
       "      <td>str</td>\n",
       "      <td>The path to the directory. Defaults to the cur...</td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ReadDirectory</td>\n",
       "      <td>file_type</td>\n",
       "      <td>str</td>\n",
       "      <td>The file extension or type to filter by (e.g.,...</td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ReadDirectory</td>\n",
       "      <td>match_str</td>\n",
       "      <td>str</td>\n",
       "      <td></td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TextFileImport</td>\n",
       "      <td>file_name</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TextFileImport</td>\n",
       "      <td>encoding</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ParseDDotPYFile</td>\n",
       "      <td>file_text</td>\n",
       "      <td>str</td>\n",
       "      <td>Full text of a .py file.</td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ParseDDotPYFolder</td>\n",
       "      <td>location</td>\n",
       "      <td>str</td>\n",
       "      <td>Windows or Mac OS Folder Directory (defaults t...</td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>create_py_table_dict</td>\n",
       "      <td>base_location</td>\n",
       "      <td>str</td>\n",
       "      <td>Location of Windows Directory containing .py F...</td>\n",
       "      <td>shared_folder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convert_list_to_parameters</td>\n",
       "      <td>module</td>\n",
       "      <td>module</td>\n",
       "      <td>Py file containing Lists.</td>\n",
       "      <td>list_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list_to_dataframe</td>\n",
       "      <td>list_</td>\n",
       "      <td>list</td>\n",
       "      <td>List of Values to be iterated into Row.</td>\n",
       "      <td>list_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>list_to_dataframe</td>\n",
       "      <td>column_name_list</td>\n",
       "      <td>list</td>\n",
       "      <td>Name of Column to be added, add as List.</td>\n",
       "      <td>list_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convert_str_to_parameters</td>\n",
       "      <td>module</td>\n",
       "      <td>module</td>\n",
       "      <td>Py file containing Strings.</td>\n",
       "      <td>string_processing.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvertListtoSQLText</td>\n",
       "      <td>list_</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ConvertListtoSQLText</td>\n",
       "      <td>return_value</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConvertListtoSQLText</td>\n",
       "      <td>column_name</td>\n",
       "      <td>str</td>\n",
       "      <td>In combination with Return Value, name of colu...</td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvertListtoSQLText</td>\n",
       "      <td>sql_query</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>generate_create_table_sql</td>\n",
       "      <td>df</td>\n",
       "      <td>df</td>\n",
       "      <td>Any DataFrame</td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>generate_create_table_sql</td>\n",
       "      <td>table_name</td>\n",
       "      <td>str</td>\n",
       "      <td>desired name for the SQL table</td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>generate_create_table_sql</td>\n",
       "      <td>schema</td>\n",
       "      <td>str</td>\n",
       "      <td>Target Schema Name</td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>generate_create_table_sql</td>\n",
       "      <td>db</td>\n",
       "      <td>str</td>\n",
       "      <td>Database Name (function designed for Analytics...</td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TableRecordCountByDate</td>\n",
       "      <td>table_dict</td>\n",
       "      <td>Dict[str, str]</td>\n",
       "      <td>Mapping of table name -&gt; date column name.</td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TableRecordCountByDate</td>\n",
       "      <td>end_date</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TableRecordCountByDate</td>\n",
       "      <td>total_days</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>sql_.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reference String</td>\n",
       "      <td>template_doc_string</td>\n",
       "      <td>str</td>\n",
       "      <td>\\n\\n    Definition of Function\\n\\n    Paramete...</td>\n",
       "      <td>data_d_strings.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>function_table_dictionary</td>\n",
       "      <td>data_d_dicts</td>\n",
       "      <td>dict</td>\n",
       "      <td>Repository of Dictionaries which have been sav...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>function_table_dictionary</td>\n",
       "      <td>data_d_lists</td>\n",
       "      <td>dict</td>\n",
       "      <td>Repository of Lists which have been saved for ...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>function_table_dictionary</td>\n",
       "      <td>data_d_strings</td>\n",
       "      <td>dict</td>\n",
       "      <td>Repository of Strings which have been saved fo...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>function_table_dictionary</td>\n",
       "      <td>dict_processing</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related to Manipulating, Transformin...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>function_table_dictionary</td>\n",
       "      <td>list_processing</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related to Manipulating, Transformin...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>function_table_dictionary</td>\n",
       "      <td>string_processing</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related to Manipulating, Transformin...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>function_table_dictionary</td>\n",
       "      <td>shared_folder</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related to Management, Maintenance a...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>function_table_dictionary</td>\n",
       "      <td>sql_</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related to Processing of SQL</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tbd</td>\n",
       "      <td>data_creation</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related to the creation of Data, for...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tbd</td>\n",
       "      <td>df_eda</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related to the Structured Exploratio...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tbd</td>\n",
       "      <td>date_functions</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related Manipulation, Change and pro...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tbd</td>\n",
       "      <td>df_processing</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related to dataframe Transformations...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tbd</td>\n",
       "      <td>df_stats</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions utilizing Statistical Concepts, and ...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tbd</td>\n",
       "      <td>ex_connections</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions Connecting to External Data Sources</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tbd</td>\n",
       "      <td>feature_engineering</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related to the creation of New Colum...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tbd</td>\n",
       "      <td>ml_pipeline</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related to Custom Build ML Pipelines...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tbd</td>\n",
       "      <td>validations</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions related to Validation of Dataframes,...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tbd</td>\n",
       "      <td>utility_functions</td>\n",
       "      <td>dict</td>\n",
       "      <td>Functions which are in development, do not nic...</td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FunctionFields</td>\n",
       "      <td>date_created</td>\n",
       "      <td>str</td>\n",
       "      <td></td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FunctionFields</td>\n",
       "      <td>date_last_modified</td>\n",
       "      <td>str</td>\n",
       "      <td></td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FunctionFields</td>\n",
       "      <td>classification</td>\n",
       "      <td>str</td>\n",
       "      <td></td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FunctionFields</td>\n",
       "      <td>sub_classification</td>\n",
       "      <td>str</td>\n",
       "      <td></td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FunctionFields</td>\n",
       "      <td>usage</td>\n",
       "      <td>str</td>\n",
       "      <td></td>\n",
       "      <td>data_d_lists.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Function           Parameters            Type  \\\n",
       "0   convert_dict_to_parameters               module          module   \n",
       "1            dict_to_dataframe                dict_                   \n",
       "2            dict_to_dataframe             key_name             str   \n",
       "3            dict_to_dataframe           value_name             str   \n",
       "0                ReadDirectory             location             str   \n",
       "1                ReadDirectory            file_type             str   \n",
       "2                ReadDirectory            match_str             str   \n",
       "3               TextFileImport            file_name                   \n",
       "4               TextFileImport             encoding                   \n",
       "5              ParseDDotPYFile            file_text             str   \n",
       "6            ParseDDotPYFolder             location             str   \n",
       "7         create_py_table_dict        base_location             str   \n",
       "0   convert_list_to_parameters               module          module   \n",
       "1            list_to_dataframe                list_            list   \n",
       "2            list_to_dataframe     column_name_list            list   \n",
       "0    convert_str_to_parameters               module          module   \n",
       "0         ConvertListtoSQLText                list_                   \n",
       "1         ConvertListtoSQLText         return_value                   \n",
       "2         ConvertListtoSQLText          column_name             str   \n",
       "3         ConvertListtoSQLText            sql_query                   \n",
       "4    generate_create_table_sql                   df              df   \n",
       "5    generate_create_table_sql           table_name             str   \n",
       "6    generate_create_table_sql               schema             str   \n",
       "7    generate_create_table_sql                   db             str   \n",
       "8       TableRecordCountByDate           table_dict  Dict[str, str]   \n",
       "9       TableRecordCountByDate             end_date                   \n",
       "10      TableRecordCountByDate           total_days                   \n",
       "0             Reference String  template_doc_string             str   \n",
       "0    function_table_dictionary         data_d_dicts            dict   \n",
       "1    function_table_dictionary         data_d_lists            dict   \n",
       "2    function_table_dictionary       data_d_strings            dict   \n",
       "3    function_table_dictionary      dict_processing            dict   \n",
       "4    function_table_dictionary      list_processing            dict   \n",
       "5    function_table_dictionary    string_processing            dict   \n",
       "6    function_table_dictionary        shared_folder            dict   \n",
       "7    function_table_dictionary                 sql_            dict   \n",
       "8                          tbd        data_creation            dict   \n",
       "9                          tbd               df_eda            dict   \n",
       "10                         tbd       date_functions            dict   \n",
       "11                         tbd        df_processing            dict   \n",
       "12                         tbd             df_stats            dict   \n",
       "13                         tbd       ex_connections            dict   \n",
       "14                         tbd  feature_engineering            dict   \n",
       "15                         tbd          ml_pipeline            dict   \n",
       "16                         tbd          validations            dict   \n",
       "17                         tbd    utility_functions            dict   \n",
       "0               FunctionFields         date_created             str   \n",
       "1               FunctionFields   date_last_modified             str   \n",
       "2               FunctionFields       classification             str   \n",
       "3               FunctionFields   sub_classification             str   \n",
       "4               FunctionFields                usage             str   \n",
       "\n",
       "                                           Definition                Folder  \n",
       "0                           Py file containing Lists.    dict_processing.py  \n",
       "1                                                        dict_processing.py  \n",
       "2   Name of Column which will include values from ...    dict_processing.py  \n",
       "3   Name of Column which will include values from ...    dict_processing.py  \n",
       "0   The path to the directory. Defaults to the cur...      shared_folder.py  \n",
       "1   The file extension or type to filter by (e.g.,...      shared_folder.py  \n",
       "2                                                          shared_folder.py  \n",
       "3                                                          shared_folder.py  \n",
       "4                                                          shared_folder.py  \n",
       "5                            Full text of a .py file.      shared_folder.py  \n",
       "6   Windows or Mac OS Folder Directory (defaults t...      shared_folder.py  \n",
       "7   Location of Windows Directory containing .py F...      shared_folder.py  \n",
       "0                           Py file containing Lists.    list_processing.py  \n",
       "1             List of Values to be iterated into Row.    list_processing.py  \n",
       "2            Name of Column to be added, add as List.    list_processing.py  \n",
       "0                         Py file containing Strings.  string_processing.py  \n",
       "0                                                                   sql_.py  \n",
       "1                                                                   sql_.py  \n",
       "2   In combination with Return Value, name of colu...               sql_.py  \n",
       "3                                                                   sql_.py  \n",
       "4                                       Any DataFrame               sql_.py  \n",
       "5                      desired name for the SQL table               sql_.py  \n",
       "6                                  Target Schema Name               sql_.py  \n",
       "7   Database Name (function designed for Analytics...               sql_.py  \n",
       "8          Mapping of table name -> date column name.               sql_.py  \n",
       "9                                                                   sql_.py  \n",
       "10                                                                  sql_.py  \n",
       "0   \\n\\n    Definition of Function\\n\\n    Paramete...     data_d_strings.py  \n",
       "0   Repository of Dictionaries which have been sav...       data_d_lists.py  \n",
       "1   Repository of Lists which have been saved for ...       data_d_lists.py  \n",
       "2   Repository of Strings which have been saved fo...       data_d_lists.py  \n",
       "3   Functions related to Manipulating, Transformin...       data_d_lists.py  \n",
       "4   Functions related to Manipulating, Transformin...       data_d_lists.py  \n",
       "5   Functions related to Manipulating, Transformin...       data_d_lists.py  \n",
       "6   Functions related to Management, Maintenance a...       data_d_lists.py  \n",
       "7              Functions related to Processing of SQL       data_d_lists.py  \n",
       "8   Functions related to the creation of Data, for...       data_d_lists.py  \n",
       "9   Functions related to the Structured Exploratio...       data_d_lists.py  \n",
       "10  Functions related Manipulation, Change and pro...       data_d_lists.py  \n",
       "11  Functions related to dataframe Transformations...       data_d_lists.py  \n",
       "12  Functions utilizing Statistical Concepts, and ...       data_d_lists.py  \n",
       "13      Functions Connecting to External Data Sources       data_d_lists.py  \n",
       "14  Functions related to the creation of New Colum...       data_d_lists.py  \n",
       "15  Functions related to Custom Build ML Pipelines...       data_d_lists.py  \n",
       "16  Functions related to Validation of Dataframes,...       data_d_lists.py  \n",
       "17  Functions which are in development, do not nic...       data_d_lists.py  \n",
       "0                                                           data_d_lists.py  \n",
       "1                                                           data_d_lists.py  \n",
       "2                                                           data_d_lists.py  \n",
       "3                                                           data_d_lists.py  \n",
       "4                                                           data_d_lists.py  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3eeafa4-c4d3-4554-8067-c0f8b949b263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Source</th>\n",
       "      <th>Function Name</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>connections.py</td>\n",
       "      <td>PY File</td>\n",
       "      <td>connections</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_d_dicts.py</td>\n",
       "      <td>PY File</td>\n",
       "      <td>data_d_dicts</td>\n",
       "      <td>Repository of Dictionaries which have been sav...</td>\n",
       "      <td>Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_d_lists.py</td>\n",
       "      <td>PY File</td>\n",
       "      <td>data_d_lists</td>\n",
       "      <td>Repository of Lists which have been saved for ...</td>\n",
       "      <td>Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_d_strings.py</td>\n",
       "      <td>PY File</td>\n",
       "      <td>data_d_strings</td>\n",
       "      <td>Repository of Strings which have been saved fo...</td>\n",
       "      <td>Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df_processing.py</td>\n",
       "      <td>PY File</td>\n",
       "      <td>df_processing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dict_processing.py</td>\n",
       "      <td>PY File</td>\n",
       "      <td>dict_processing</td>\n",
       "      <td>Functions related to Manipulating, Transformin...</td>\n",
       "      <td>Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>list_processing.py</td>\n",
       "      <td>PY File</td>\n",
       "      <td>list_processing</td>\n",
       "      <td>Functions related to Manipulating, Transformin...</td>\n",
       "      <td>Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shared_folder.py</td>\n",
       "      <td>PY File</td>\n",
       "      <td>shared_folder</td>\n",
       "      <td>Functions related to Management, Maintenance a...</td>\n",
       "      <td>Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sql_.py</td>\n",
       "      <td>PY File</td>\n",
       "      <td>sql_</td>\n",
       "      <td>Functions related to Processing of SQL</td>\n",
       "      <td>Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>string_processing.py</td>\n",
       "      <td>PY File</td>\n",
       "      <td>string_processing</td>\n",
       "      <td>Functions related to Manipulating, Transformin...</td>\n",
       "      <td>Definition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              File Name   Source      Function Name  \\\n",
       "0        connections.py  PY File        connections   \n",
       "1       data_d_dicts.py  PY File       data_d_dicts   \n",
       "2       data_d_lists.py  PY File       data_d_lists   \n",
       "3     data_d_strings.py  PY File     data_d_strings   \n",
       "4      df_processing.py  PY File      df_processing   \n",
       "5    dict_processing.py  PY File    dict_processing   \n",
       "6    list_processing.py  PY File    list_processing   \n",
       "7      shared_folder.py  PY File      shared_folder   \n",
       "8               sql_.py  PY File               sql_   \n",
       "9  string_processing.py  PY File  string_processing   \n",
       "\n",
       "                                          Definition        Type  \n",
       "0                                                NaN         NaN  \n",
       "1  Repository of Dictionaries which have been sav...  Definition  \n",
       "2  Repository of Lists which have been saved for ...  Definition  \n",
       "3  Repository of Strings which have been saved fo...  Definition  \n",
       "4                                                NaN         NaN  \n",
       "5  Functions related to Manipulating, Transformin...  Definition  \n",
       "6  Functions related to Manipulating, Transformin...  Definition  \n",
       "7  Functions related to Management, Maintenance a...  Definition  \n",
       "8             Functions related to Processing of SQL  Definition  \n",
       "9  Functions related to Manipulating, Transformin...  Definition  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shared_folder import create_py_table_dict\n",
    "\n",
    "create_py_table_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf86a05-63e8-4cfb-9296-0605898282ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine Learning\n",
    "- Linear Regression\n",
    "-- Definition\n",
    "-- Closed Form\n",
    "-- Standardization\n",
    "-- Other Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e175bb46-c581-489d-a467-64f0dd31b615",
   "metadata": {},
   "source": [
    "### Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b910ee8-bd2d-4da0-ac9b-6de5dc29535c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608111c6-80ca-4f15-8c57-4436819de2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import webbrowser\n",
    "import datetime\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def DownloadFilesFromGit(user='derek-dewald',\n",
    "                        repo='Python_Tools',\n",
    "                        folder='d_py_functions',\n",
    "                        output_folder=\"\"):\n",
    "    '''\n",
    "    Function to Download Files from Github to a dedicated folder. Specifically used when i DO NOT want to formally link to Github.\n",
    "    \n",
    "    Parameters:\n",
    "        User:\n",
    "        Repo:\n",
    "        folder:\n",
    "        output_folder:\n",
    "        \n",
    "    Returns:\n",
    "        Saves files to Output Folder.\n",
    "    \n",
    "\n",
    "    '''\n",
    "    \n",
    "    if len(output_folder) == 0:\n",
    "        output_folder = os.getcwd()\n",
    "    \n",
    "    api_url = f\"https://api.github.com/repos/{user}/{repo}/contents/{folder}\"\n",
    "    response = requests.get(api_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        files = response.json()\n",
    "        py_files = [file for file in files if file['name'].endswith('.py')]\n",
    "\n",
    "        for file in py_files:\n",
    "            file_url = file['download_url']\n",
    "            file_name = file['name']\n",
    "            file_response = requests.get(file_url)\n",
    "\n",
    "            if file_response.status_code == 200:\n",
    "                with open(os.path.join(output_folder, file_name), \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(file_response.text)\n",
    "                    \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ParamterMapping(Definition=\"\"):\n",
    "    \n",
    "    '''\n",
    "    Function to Google Mapping Sheet, which is used to store Mappings, Links, etc.\n",
    "    For both simplicity and Organization\n",
    "    \n",
    "    Args:\n",
    "        Definition (Str): Key word used to Access individual elements\n",
    "        \n",
    "    Returns:\n",
    "        Dataframe, unless Definition is defined, in which case it might be Str.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSwDznLz-GKgWFT1uN0XZYm3bsos899I9MS-pSvEoDC-Cjqo9CWeEuSdjitxjqzF3O39LmjJB0_Fg-B/pub?output=csv')\n",
    "    \n",
    "    # If user has not included a definition, the return entire DF\n",
    "    if len(Definition)==0:\n",
    "        return df\n",
    "    else:\n",
    "        try:\n",
    "            df1 = df[df['Definition']==Definition]\n",
    "            if len(df1)==1:\n",
    "                if df1['TYPE'].item()=='csv':\n",
    "                    return pd.read_csv(df1['VALUE'].item())\n",
    "                else:\n",
    "                    return df1['VALUE'].item()\n",
    "        except:\n",
    "            return df[df['Definition']==Definition] \n",
    "\n",
    "\n",
    "def BackUpGoogleSheets(location='/Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/'):\n",
    "    '''\n",
    "    Function to Create a Backup of Information Stored in Google Sheets.\n",
    "    \n",
    "    Parameters:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        CSV Files \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df = ParamterMapping()\n",
    "    \n",
    "    for row in range(len(df)):\n",
    "        try:\n",
    "            file_name = df['Definition'][row]\n",
    "            file_location = df['CSV'][row]\n",
    "            month = datetime.datetime.now().strftime('%b-%y')\n",
    "            \n",
    "            temp_df = pd.read_csv(file_location)\n",
    "            temp_df.to_csv(f'{location}{file_name}_{month}.csv',index=False)\n",
    "            print(f'Back Up Saved, {location}{file_name}')\n",
    "        except:\n",
    "            print(f'Counld Not Print Record {row}')\n",
    "\n",
    "\n",
    "\n",
    "def GoogleProcessSheetLinks():\n",
    "     \n",
    "    '''\n",
    "    Function to Google Mapping Sheet, Navigate to Specific Sites.\n",
    "    Provides Options, Enable Selection based on inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "    \n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSwDznLz-GKgWFT1uN0XZYm3bsos899I9MS-pSvEoDC-Cjqo9CWeEuSdjitxjqzF3O39LmjJB0_Fg-B/pub?output=csv')\n",
    "    \n",
    "    display(df)\n",
    "    \n",
    "    p = input('Which Process would You like to review?')\n",
    "    v = input('What would you like to return?')\n",
    "    \n",
    "    df1 = df[df['Definition']==p]\n",
    "    \n",
    "    if v.lower() =='link':\n",
    "        webbrowser.open(df1['Link'].item())\n",
    "    elif v.lower() == 'csv':\n",
    "        return pd.read_csv(df1['CSV'].item())\n",
    "    elif v.lower()=='streamlit':\n",
    "        webbrowser.open(df1['Streamlit'].item())\n",
    "\n",
    "def NavigateUsingDMap():\n",
    "     \n",
    "    '''\n",
    "    Function to Google Mapping Sheet, Navigate to Specific Sites.\n",
    "    Provides Options, Enable Selection based on inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "    \n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSwDznLz-GKgWFT1uN0XZYm3bsos899I9MS-pSvEoDC-Cjqo9CWeEuSdjitxjqzF3O39LmjJB0_Fg-B/pub?output=csv')\n",
    "    \n",
    "    display(df)\n",
    "    \n",
    "    p = input('Which Process would You like to review?')\n",
    "    v = input('What would you like to return?')\n",
    "    \n",
    "    df1 = df[df['Definition']==p]\n",
    "    \n",
    "    if v.lower() =='link':\n",
    "        webbrowser.open(df1['Link'].item())\n",
    "    elif v.lower() == 'csv':\n",
    "        return pd.read_csv(df1['CSV'].item())\n",
    "    elif v.lower()=='streamlit':\n",
    "        webbrowser.open(df1['Streamlit'].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44ca27-7fdb-4e21-96a2-f0ee20c8012c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52975ea-0a61-42bb-8d61-7b3e1ed6e52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a6ee9-ba12-4b58-b766-59bba6bef5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c54f1ee6-04c2-43fa-84ba-d815df516898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Definition of Function\n",
      "\n",
      "    Parameters:\n",
      "        List of Parameters\n",
      "\n",
      "    Returns:\n",
      "        Object Type\n",
      "\n",
      "    date_created:3-Dec-25\n",
      "    date_last_modified: 3-Dec-25\n",
      "    classification:TBD\n",
      "    sub_classification:TBD\n",
      "    usage:\n",
      "        Example Function Call\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_d_strings import template_doc_string\n",
    "print(template_doc_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6112d250-5da6-48b4-bae0-9005cde7e167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Title</th>\n",
       "      <th>Header</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLUE</td>\n",
       "      <td>Linearity</td>\n",
       "      <td>Relationship between Independent and Dependent...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLUE</td>\n",
       "      <td>Independence.</td>\n",
       "      <td>Observations should be independent of each oth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLUE</td>\n",
       "      <td>Homoscedasticity</td>\n",
       "      <td>Variance of the residuals should be constant.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLUE</td>\n",
       "      <td>Normality of Residuals</td>\n",
       "      <td>Residuals should be normally distributed.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLUE</td>\n",
       "      <td>No Perfect Collinearity</td>\n",
       "      <td>No perfect linear relationship between residuals</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Solution Adoption</td>\n",
       "      <td>Step 1: Definition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Solution Adoption</td>\n",
       "      <td>Step 1: Communication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Solution Adoption</td>\n",
       "      <td>Step 2: Monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Solution Adoption</td>\n",
       "      <td>Step 3: Analyze Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Solution Adoption</td>\n",
       "      <td>Step 4: Document Lessons Learnt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Process                            Title  \\\n",
       "0                BLUE                        Linearity   \n",
       "1                BLUE                    Independence.   \n",
       "2                BLUE                 Homoscedasticity   \n",
       "3                BLUE           Normality of Residuals   \n",
       "4                BLUE          No Perfect Collinearity   \n",
       "..                ...                              ...   \n",
       "66  Solution Adoption               Step 1: Definition   \n",
       "67  Solution Adoption            Step 1: Communication   \n",
       "68  Solution Adoption               Step 2: Monitoring   \n",
       "69  Solution Adoption          Step 3: Analyze Success   \n",
       "70  Solution Adoption  Step 4: Document Lessons Learnt   \n",
       "\n",
       "                                               Header Description  \n",
       "0   Relationship between Independent and Dependent...         NaN  \n",
       "1   Observations should be independent of each oth...         NaN  \n",
       "2       Variance of the residuals should be constant.         NaN  \n",
       "3           Residuals should be normally distributed.         NaN  \n",
       "4    No perfect linear relationship between residuals         NaN  \n",
       "..                                                ...         ...  \n",
       "66                                                NaN         NaN  \n",
       "67                                                NaN         NaN  \n",
       "68                                                NaN         NaN  \n",
       "69                                                NaN         NaN  \n",
       "70                                                NaN         NaN  \n",
       "\n",
       "[71 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def google_sheet_links(return_value = None):\n",
    "    \n",
    "    '''\n",
    "    Function which Extracts Information Directly From D Google Sheet. If return value is populated and matches one of the Definitions, it will return \n",
    "    the File, if not it will return a Dictionary with the Default Arguments. \n",
    "\n",
    "    There dictionary was not hard coded as it is subject to continual and preputual change.\n",
    "\n",
    "    Parameters:\n",
    "        return_value (str): Value is based on Definition in D Sheet. If value is populated and matched it will return the Google Sheet as a \n",
    "        Dataframe, otherwise it will fail and return a dict.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame/Dict (Depending on Input)\n",
    "\n",
    "    date_created:5-Dec-25\n",
    "    date_last_modified: 5-Dec-25\n",
    "    classification:TBD\n",
    "    sub_classification:TBD\n",
    "    usage:\n",
    "        d_process_df = google_sheet_links('Processes')\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Download CSV from D Google Site\n",
    "    df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSwDznLz-GKgWFT1uN0XZYm3bsos899I9MS-pSvEoDC-Cjqo9CWeEuSdjitxjqzF3O39LmjJB0_Fg-B/pub?output=csv')\n",
    "\n",
    "    # Return A Dictionary of Google Sheet Objects\n",
    "    dict_ = df[df['Classification']=='Google Sheet'][['Definition','CSV']].set_index('Definition').to_dict()['CSV']\n",
    "\n",
    "    if not return_value:\n",
    "        return dict_\n",
    "\n",
    "    if return_value:\n",
    "        try:\n",
    "            return pd.read_csv(dict_[return_value])\n",
    "        except:\n",
    "            print('Could Not Import File from Google')\n",
    "            return dict_\n",
    "\n",
    "google_sheet_links('Processes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b33d0f46-7b79-41fc-b298-45f28c0a93c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Definition</th>\n",
       "      <th>Classification</th>\n",
       "      <th>Description</th>\n",
       "      <th>KEY</th>\n",
       "      <th>Link</th>\n",
       "      <th>CSV</th>\n",
       "      <th>Streamlit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Processes</td>\n",
       "      <td>Google Sheet</td>\n",
       "      <td>Defined Processes to Follow. To serve as a fra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1iXlm49...</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/e/2PACX...</td>\n",
       "      <td>https://process-powerpoint-presenetation.strea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Definitions</td>\n",
       "      <td>Google Sheet</td>\n",
       "      <td>Data Defintions, Links, Images, Etc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1tZ-_5V...</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/e/2PACX...</td>\n",
       "      <td>https://derek-dewald-datadashboard.streamlit.app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notes</td>\n",
       "      <td>Google Sheet</td>\n",
       "      <td>Notes on a subject, helpful information, thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1jddkkF...</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/e/2PACX...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technical Notes</td>\n",
       "      <td>Google Sheet</td>\n",
       "      <td>Notes Specifically related to Coding, Computer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1FpYYq4...</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/e/2PACX...</td>\n",
       "      <td>https://derekdewald-codedboard.streamlit.app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mapping Sheet</td>\n",
       "      <td>Google Sheet</td>\n",
       "      <td>THIS SHEET.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1Wfr7Ds...</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/e/2PACX...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d_py_functions</td>\n",
       "      <td>Folder</td>\n",
       "      <td>Derek's Primary Python Library. \\nOriginal Ver...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Job Search</td>\n",
       "      <td>Google Sheet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1sMdgmp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://bconnected.berkeley.edu/services/alumn...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OurWorldData</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>www.ourworlddata.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KaggelDatasets</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.kaggle.com/datasets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>StLouisFed</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://fred.stlouisfed.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GoggleResearch</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://datasetsearch.research.google.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UCI</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://archive.ics.uci.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AWS</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://registry.opendata.aws/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AWSDataExchange</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://aws.amazon.com/data-exchange/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AWSPublicData</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://aws.amazon.com/public-datasets/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SKlearn Model Parameters</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1GhIiuE...</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/e/2PACX...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sklearn Models</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/e/2PACX...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Consolidated Dashboard</td>\n",
       "      <td>Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://knowledgedashboard.streamlit.app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TensorFlow Playground</td>\n",
       "      <td>External Site</td>\n",
       "      <td>Displaying How Tensor Flow Works.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://playground.tensorflow.org/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Definition Classification  \\\n",
       "0                  Processes   Google Sheet   \n",
       "1                Definitions   Google Sheet   \n",
       "2                      Notes   Google Sheet   \n",
       "3            Technical Notes   Google Sheet   \n",
       "4              Mapping Sheet   Google Sheet   \n",
       "5             d_py_functions         Folder   \n",
       "6                 Job Search   Google Sheet   \n",
       "7                        NaN            NaN   \n",
       "8               OurWorldData           Data   \n",
       "9             KaggelDatasets           Data   \n",
       "10                StLouisFed           Data   \n",
       "11            GoggleResearch           Data   \n",
       "12                       UCI           Data   \n",
       "13                       AWS           Data   \n",
       "14           AWSDataExchange           Data   \n",
       "15             AWSPublicData           Data   \n",
       "16  SKlearn Model Parameters           Data   \n",
       "17            Sklearn Models           Data   \n",
       "18    Consolidated Dashboard           Data   \n",
       "19     TensorFlow Playground  External Site   \n",
       "\n",
       "                                          Description  KEY  \\\n",
       "0   Defined Processes to Follow. To serve as a fra...  NaN   \n",
       "1                Data Defintions, Links, Images, Etc.  NaN   \n",
       "2   Notes on a subject, helpful information, thing...  NaN   \n",
       "3   Notes Specifically related to Coding, Computer...  NaN   \n",
       "4                                         THIS SHEET.  NaN   \n",
       "5   Derek's Primary Python Library. \\nOriginal Ver...  NaN   \n",
       "6                                                 NaN  NaN   \n",
       "7                                                 NaN  NaN   \n",
       "8                                                 NaN  NaN   \n",
       "9                                                 NaN  NaN   \n",
       "10                                                NaN  NaN   \n",
       "11                                                NaN  NaN   \n",
       "12                                                NaN  NaN   \n",
       "13                                                NaN  NaN   \n",
       "14                                                NaN  NaN   \n",
       "15                                                NaN  NaN   \n",
       "16                                                NaN  NaN   \n",
       "17                                                NaN  NaN   \n",
       "18                                                NaN  NaN   \n",
       "19                  Displaying How Tensor Flow Works.  NaN   \n",
       "\n",
       "                                                 Link  \\\n",
       "0   https://docs.google.com/spreadsheets/d/1iXlm49...   \n",
       "1   https://docs.google.com/spreadsheets/d/1tZ-_5V...   \n",
       "2   https://docs.google.com/spreadsheets/d/1jddkkF...   \n",
       "3   https://docs.google.com/spreadsheets/d/1FpYYq4...   \n",
       "4   https://docs.google.com/spreadsheets/d/1Wfr7Ds...   \n",
       "5                                                 NaN   \n",
       "6   https://docs.google.com/spreadsheets/d/1sMdgmp...   \n",
       "7                                                 NaN   \n",
       "8                                www.ourworlddata.org   \n",
       "9                     https://www.kaggle.com/datasets   \n",
       "10                        https://fred.stlouisfed.org   \n",
       "11          https://datasetsearch.research.google.com   \n",
       "12                        https://archive.ics.uci.edu   \n",
       "13                     https://registry.opendata.aws/   \n",
       "14              https://aws.amazon.com/data-exchange/   \n",
       "15            https://aws.amazon.com/public-datasets/   \n",
       "16  https://docs.google.com/spreadsheets/d/1GhIiuE...   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                 https://playground.tensorflow.org/   \n",
       "\n",
       "                                                  CSV  \\\n",
       "0   https://docs.google.com/spreadsheets/d/e/2PACX...   \n",
       "1   https://docs.google.com/spreadsheets/d/e/2PACX...   \n",
       "2   https://docs.google.com/spreadsheets/d/e/2PACX...   \n",
       "3   https://docs.google.com/spreadsheets/d/e/2PACX...   \n",
       "4   https://docs.google.com/spreadsheets/d/e/2PACX...   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7   https://bconnected.berkeley.edu/services/alumn...   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16  https://docs.google.com/spreadsheets/d/e/2PACX...   \n",
       "17  https://docs.google.com/spreadsheets/d/e/2PACX...   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "                                            Streamlit  \n",
       "0   https://process-powerpoint-presenetation.strea...  \n",
       "1    https://derek-dewald-datadashboard.streamlit.app  \n",
       "2                                                 NaN  \n",
       "3        https://derekdewald-codedboard.streamlit.app  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18           https://knowledgedashboard.streamlit.app  \n",
       "19                                                NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d7f896-8280-40e7-bcd6-04ce91bb16ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Title</th>\n",
       "      <th>Header</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agentic AI</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>Direct User Interaction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agentic AI</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>Agent/ Assistant Proxy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agentic AI</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>Agent/ Assistant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agentic AI</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>Autonomous Agent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agentic AI</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>LLM</td>\n",
       "      <td>Understanding and Generatic Human Like Text vs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Type of Problems</td>\n",
       "      <td>Common Types of Problems</td>\n",
       "      <td>Creative</td>\n",
       "      <td>Innovation, Future Design, where Data might su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Visualizations</td>\n",
       "      <td>Visualizations</td>\n",
       "      <td>How people Interpret</td>\n",
       "      <td>Christ at Emmaus - Feelings can trump expertis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Visualizations</td>\n",
       "      <td>Visualizations</td>\n",
       "      <td>What Am I looking at.</td>\n",
       "      <td>The bigger display with a wider array of jams ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Visualizations</td>\n",
       "      <td>Visualizations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Has the performance of the algorithm been asse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Visualizations</td>\n",
       "      <td>Visualizations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When someone tells a joke poorly it is more li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Process                     Title                   Header  \\\n",
       "0          Agentic AI                Approaches  Direct User Interaction   \n",
       "1          Agentic AI                Approaches   Agent/ Assistant Proxy   \n",
       "2          Agentic AI                Approaches         Agent/ Assistant   \n",
       "3          Agentic AI                Approaches         Autonomous Agent   \n",
       "4          Agentic AI                Comparison                      LLM   \n",
       "..                ...                       ...                      ...   \n",
       "304  Type of Problems  Common Types of Problems                 Creative   \n",
       "305    Visualizations            Visualizations     How people Interpret   \n",
       "306    Visualizations            Visualizations    What Am I looking at.   \n",
       "307    Visualizations            Visualizations                      NaN   \n",
       "308    Visualizations            Visualizations                      NaN   \n",
       "\n",
       "                                           Description  \n",
       "0                                                  NaN  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4    Understanding and Generatic Human Like Text vs...  \n",
       "..                                                 ...  \n",
       "304  Innovation, Future Design, where Data might su...  \n",
       "305  Christ at Emmaus - Feelings can trump expertis...  \n",
       "306  The bigger display with a wider array of jams ...  \n",
       "307  Has the performance of the algorithm been asse...  \n",
       "308  When someone tells a joke poorly it is more li...  \n",
       "\n",
       "[309 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSQF2lNc4WPeTRQ_VzWPkqSZp4RODFkbap8AqmolWp5bKoMaslP2oRVVG21x2POu_JcbF1tGRcBgodu/pub?output=csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ae407-20b4-4975-8652-4a0772d46149",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276a453-7008-43be-988f-2c758cf65f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoogleProcessSheetLinks():\n",
    "     \n",
    "    '''\n",
    "    Function to Google Mapping Sheet, Navigate to Specific Sites.\n",
    "    Provides Options, Enable Selection based on inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "    \n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSwDznLz-GKgWFT1uN0XZYm3bsos899I9MS-pSvEoDC-Cjqo9CWeEuSdjitxjqzF3O39LmjJB0_Fg-B/pub?output=csv')\n",
    "    \n",
    "    display(df)\n",
    "    \n",
    "    p = input('Which Process would You like to review?')\n",
    "    v = input('What would you like to return?')\n",
    "    \n",
    "    df1 = df[df['Definition']==p]\n",
    "    \n",
    "    if v.lower() =='link':\n",
    "        webbrowser.open(df1['Link'].item())\n",
    "    elif v.lower() == 'csv':\n",
    "        return pd.read_csv(df1['CSV'].item())\n",
    "    elif v.lower()=='streamlit':\n",
    "        webbrowser.open(df1['Streamlit'].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ab21e-f5f6-44b2-ac79-19dce7c32cda",
   "metadata": {},
   "source": [
    "#### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c8974-f4a0-40a8-a5b5-bb4d7d8d348a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc8435-ed47-4a8d-8809-cbba05916c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f192bca2-ca2b-48e8-b44c-3f001d7d9f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe30ad21-0513-41df-9899-cab57a78d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Notes = {\n",
    "    'Topic':'The High Level Topic',\n",
    "    'Record Type':\"Definition of the type of record\",\n",
    "    'Record':'The individual classification to which ',\n",
    "    'Record Notes':\"Detailed Description of related item\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c884636d-e535-4ebb-a7bb-5cfb73669777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Title</th>\n",
       "      <th>Header</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Overview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>Supervised Learning</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>Unsupervised Learning</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>SemiSupervised Learning</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>Reinforcement Learning</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>General</td>\n",
       "      <td>In 9 dimensions, might not be global minimum, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Requirements</td>\n",
       "      <td>Small change hypothesis must hold.  Example We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Reminders</td>\n",
       "      <td>Models will cheat. Self-driving car, multi lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>L1 Regularization, L2 Regularization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Goal</td>\n",
       "      <td>What are you attempting to maximize, Training ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>Cross Validation</td>\n",
       "      <td>Splitting Data into K Folds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>Stratified Cross Validation</td>\n",
       "      <td>Splitting Data into statistically represented ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>Confusion Matrix</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>Generally not a preferred metric, Especially a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>Decision Scores</td>\n",
       "      <td>Scores from the Actual Decision Boundary. Prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>predict_proba</td>\n",
       "      <td>Specifcally for Decision Trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Concepts</td>\n",
       "      <td>Key Terms</td>\n",
       "      <td>#### Need to Automate this #####\\nBaggin, Kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Models</td>\n",
       "      <td>Models</td>\n",
       "      <td>Also used as a regularization, sometimes only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Models</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>Closed Form Solution. Python Linear Regression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Models</td>\n",
       "      <td>Reinforcement Learning</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Models</td>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Models</td>\n",
       "      <td>Large Language Models</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Models</td>\n",
       "      <td>Recurrent Neural Network</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Models</td>\n",
       "      <td>Transformers</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td></td>\n",
       "      <td>Helps to Automate Feature Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Evolution</td>\n",
       "      <td>Historical Issue of gradient propogration wher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Framework</td>\n",
       "      <td>Core building block is the layer, a filter whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Model</td>\n",
       "      <td>Model starts with determining the number of la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Lesson Learnt</td>\n",
       "      <td>Always Have a Simple Baseline</td>\n",
       "      <td>Need a reference to test performance of the mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Downside</td>\n",
       "      <td>Simplicity Not Assumed</td>\n",
       "      <td>ML can't look naively for a simple common sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Feature Selection</td>\n",
       "      <td>Avoid Ambigious Features</td>\n",
       "      <td>Is a Banana Ripe? Who Says So.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Feature Selection</td>\n",
       "      <td>Careful if Genuinely Random</td>\n",
       "      <td>Atmospheric Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Feature Selection</td>\n",
       "      <td>Data Quality Input</td>\n",
       "      <td>MNIST performance when tilting Images, of addi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Feature Selection</td>\n",
       "      <td>Relevance</td>\n",
       "      <td>Any data set can be optimized, even when there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Tool</td>\n",
       "      <td>PyTorch</td>\n",
       "      <td>Favored in research and academia because of it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Tool</td>\n",
       "      <td>PyTorch</td>\n",
       "      <td>Pythonic, intuitive, and integrates seamlessly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Tool</td>\n",
       "      <td>PyTorch</td>\n",
       "      <td>Great for experimentation, quick prototyping, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Tool</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>Stronger in production/industry, especially wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Tool</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>TensorFlow Serving, TensorFlow Lite (for mobil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Tool</td>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>High-level, user-friendly API for building mod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Process              Title                         Header  \\\n",
       "91   Machine Learning           Overview                            NaN   \n",
       "92   Machine Learning         Approaches            Supervised Learning   \n",
       "93   Machine Learning         Approaches          Unsupervised Learning   \n",
       "94   Machine Learning         Approaches        SemiSupervised Learning   \n",
       "95   Machine Learning         Approaches         Reinforcement Learning   \n",
       "96   Machine Learning       Optimization                        General   \n",
       "97   Machine Learning       Optimization                   Requirements   \n",
       "98   Machine Learning       Optimization                      Reminders   \n",
       "99   Machine Learning       Optimization                     Approaches   \n",
       "100  Machine Learning       Optimization                           Goal   \n",
       "101  Machine Learning         Evaluation               Cross Validation   \n",
       "102  Machine Learning         Evaluation    Stratified Cross Validation   \n",
       "103  Machine Learning         Evaluation               Confusion Matrix   \n",
       "104  Machine Learning         Evaluation                       Accuracy   \n",
       "105  Machine Learning         Evaluation                Decision Scores   \n",
       "106  Machine Learning         Evaluation                  predict_proba   \n",
       "107  Machine Learning           Concepts                      Key Terms   \n",
       "108  Machine Learning             Models                         Models   \n",
       "109  Machine Learning             Models              Linear Regression   \n",
       "110  Machine Learning             Models         Reinforcement Learning   \n",
       "111  Machine Learning             Models   Convolutional Neural Network   \n",
       "112  Machine Learning             Models          Large Language Models   \n",
       "113  Machine Learning             Models       Recurrent Neural Network   \n",
       "114  Machine Learning             Models                   Transformers   \n",
       "115  Machine Learning      Deep Learning                                  \n",
       "116  Machine Learning      Deep Learning                      Evolution   \n",
       "117  Machine Learning      Deep Learning                      Framework   \n",
       "118  Machine Learning      Deep Learning                          Model   \n",
       "119  Machine Learning      Lesson Learnt  Always Have a Simple Baseline   \n",
       "120  Machine Learning           Downside         Simplicity Not Assumed   \n",
       "121  Machine Learning  Feature Selection       Avoid Ambigious Features   \n",
       "122  Machine Learning  Feature Selection    Careful if Genuinely Random   \n",
       "123  Machine Learning  Feature Selection             Data Quality Input   \n",
       "124  Machine Learning  Feature Selection                      Relevance   \n",
       "125  Machine Learning               Tool                        PyTorch   \n",
       "126  Machine Learning               Tool                        PyTorch   \n",
       "127  Machine Learning               Tool                        PyTorch   \n",
       "128  Machine Learning               Tool                     TensorFlow   \n",
       "129  Machine Learning               Tool                     TensorFlow   \n",
       "130  Machine Learning               Tool                     TensorFlow   \n",
       "\n",
       "                                           Description  \n",
       "91                                                 NaN  \n",
       "92                                                 NaN  \n",
       "93                                                 NaN  \n",
       "94                                                 NaN  \n",
       "95                                                 NaN  \n",
       "96   In 9 dimensions, might not be global minimum, ...  \n",
       "97   Small change hypothesis must hold.  Example We...  \n",
       "98   Models will cheat. Self-driving car, multi lan...  \n",
       "99                L1 Regularization, L2 Regularization  \n",
       "100  What are you attempting to maximize, Training ...  \n",
       "101                       Splitting Data into K Folds.  \n",
       "102  Splitting Data into statistically represented ...  \n",
       "103                                                NaN  \n",
       "104  Generally not a preferred metric, Especially a...  \n",
       "105  Scores from the Actual Decision Boundary. Prov...  \n",
       "106                     Specifcally for Decision Trees  \n",
       "107  #### Need to Automate this #####\\nBaggin, Kern...  \n",
       "108  Also used as a regularization, sometimes only ...  \n",
       "109  Closed Form Solution. Python Linear Regression...  \n",
       "110                                                NaN  \n",
       "111                                                NaN  \n",
       "112                                                NaN  \n",
       "113                                                NaN  \n",
       "114                                                NaN  \n",
       "115              Helps to Automate Feature Engineering  \n",
       "116  Historical Issue of gradient propogration wher...  \n",
       "117  Core building block is the layer, a filter whi...  \n",
       "118  Model starts with determining the number of la...  \n",
       "119  Need a reference to test performance of the mo...  \n",
       "120  ML can't look naively for a simple common sens...  \n",
       "121                     Is a Banana Ripe? Who Says So.  \n",
       "122                                 Atmospheric Change  \n",
       "123  MNIST performance when tilting Images, of addi...  \n",
       "124  Any data set can be optimized, even when there...  \n",
       "125  Favored in research and academia because of it...  \n",
       "126  Pythonic, intuitive, and integrates seamlessly...  \n",
       "127  Great for experimentation, quick prototyping, ...  \n",
       "128  Stronger in production/industry, especially wi...  \n",
       "129  TensorFlow Serving, TensorFlow Lite (for mobil...  \n",
       "130  High-level, user-friendly API for building mod...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Process']=='Machine Learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23bceef0-701e-49a6-9bed-ca1eb56c86eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Title</th>\n",
       "      <th>Header</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agentic AI</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>Direct User Interaction</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agentic AI</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>Agent/ Assistant Proxy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agentic AI</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>Agent/ Assistant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agentic AI</td>\n",
       "      <td>Approaches</td>\n",
       "      <td>Autonomous Agent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agentic AI</td>\n",
       "      <td>Comparison</td>\n",
       "      <td>LLM</td>\n",
       "      <td>Understanding and Generatic Human Like Text vs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Type of Problems</td>\n",
       "      <td>Common Types of Problems</td>\n",
       "      <td>Creative</td>\n",
       "      <td>Innovation, Future Design, where Data might su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Visualizations</td>\n",
       "      <td>Visualizations</td>\n",
       "      <td>How people Interpret</td>\n",
       "      <td>Christ at Emmaus - Feelings can trump expertis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Visualizations</td>\n",
       "      <td>Visualizations</td>\n",
       "      <td>What Am I looking at.</td>\n",
       "      <td>The bigger display with a wider array of jams ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Visualizations</td>\n",
       "      <td>Visualizations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Has the performance of the algorithm been asse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Visualizations</td>\n",
       "      <td>Visualizations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When someone tells a joke poorly it is more li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Process                     Title                   Header  \\\n",
       "0          Agentic AI                Approaches  Direct User Interaction   \n",
       "1          Agentic AI                Approaches   Agent/ Assistant Proxy   \n",
       "2          Agentic AI                Approaches         Agent/ Assistant   \n",
       "3          Agentic AI                Approaches         Autonomous Agent   \n",
       "4          Agentic AI                Comparison                      LLM   \n",
       "..                ...                       ...                      ...   \n",
       "304  Type of Problems  Common Types of Problems                 Creative   \n",
       "305    Visualizations            Visualizations     How people Interpret   \n",
       "306    Visualizations            Visualizations    What Am I looking at.   \n",
       "307    Visualizations            Visualizations                      NaN   \n",
       "308    Visualizations            Visualizations                      NaN   \n",
       "\n",
       "                                           Description  \n",
       "0                                                  NaN  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4    Understanding and Generatic Human Like Text vs...  \n",
       "..                                                 ...  \n",
       "304  Innovation, Future Design, where Data might su...  \n",
       "305  Christ at Emmaus - Feelings can trump expertis...  \n",
       "306  The bigger display with a wider array of jams ...  \n",
       "307  Has the performance of the algorithm been asse...  \n",
       "308  When someone tells a joke poorly it is more li...  \n",
       "\n",
       "[309 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8c56a79-658f-4d6f-8806-0236a0e41d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Story Telling               35\n",
       "Evaluation                  17\n",
       "Tensor                      12\n",
       "Decision Making             11\n",
       "Presentation Tenants        10\n",
       "                            ..\n",
       "Tweak Model                  1\n",
       "Validate Model               1\n",
       "Regression                   1\n",
       "Dimensionality Reduction     1\n",
       "Measure Change.              1\n",
       "Name: count, Length: 89, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d13106-4ad8-4814-a098-50a1d0e8e3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process\n",
       "TensorFlow                           55\n",
       "Machine Learning                     40\n",
       "Communication                        33\n",
       "Presentation                         24\n",
       "Tools                                18\n",
       "Confusion Matrix                     16\n",
       "Model Types                          13\n",
       "Kubernetes Production Environment    11\n",
       "Persuasion                           11\n",
       "Decision Making                      11\n",
       "Experimentation                       9\n",
       "ML Pipeline Cheat Sheet               9\n",
       "Time Series                           7\n",
       "ML Tasks                              7\n",
       "Type of Problems                      6\n",
       "ML Calculation                        5\n",
       "Agentic AI                            5\n",
       "Tensorflow                            4\n",
       "Sklearn                               4\n",
       "Visualizations                        4\n",
       "StoryTelling                          3\n",
       "Python                                2\n",
       "Research Design                       2\n",
       "Math                                  2\n",
       "ETL                                   2\n",
       "Data Processing                       2\n",
       "Model Selection                       1\n",
       "Feature Engineering                   1\n",
       "EDA                                   1\n",
       "Model Evaluation                      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Process'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326b8d0-949b-4803-ad6f-aab9cce16276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Description: \n",
    "from IPython.display import display, Markdown, Math, HTML\n",
    "from Connections import ParamterMapping\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def D_Notes_Reader(topic=None):\n",
    "    '''\n",
    "    Function to read Notes Files Saved in Google Docs\n",
    "\n",
    "    Parameters: \n",
    "        topic (str): Argument to enable Filtering of Returned Dataframe to a Specific Topic. If a Filter is not applied it can be difficult\n",
    "        to read the output as it's one continuous text without the Header Comments.\n",
    "\n",
    "    Returns:\n",
    "        Printed version of Notes (Powerpoint Like Format)\n",
    "\n",
    "    Date Created: August 17, 2025\n",
    "    Date Last Modified: \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSQF2lNc4WPeTRQ_VzWPkqSZp4RODFkbap8AqmolWp5bKoMaslP2oRVVG21x2POu_JcbF1tGRcBgodu/pub?output=csv')\n",
    "    if topic:\n",
    "        temp = df[df['Process']==topic]\n",
    "        if len(temp)>0:\n",
    "            return JupyterNotebookMarkdown(temp)\n",
    "    else:\n",
    "        return JupyterNotebookMarkdown(df)\n",
    "            \n",
    "\n",
    "def JupyterNotebookMarkdown(df, column_order = ['Title','Header','Description'],return_value=\"\"):\n",
    "    '''\n",
    "    Function to Create a Markdown file from Process DF, which is a data frame of the structure, \n",
    "    Title, Header, Description\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Must include columns Title, Header, Description\n",
    "        return_value (str): \n",
    "            If \"\", renders HTML in notebook.\n",
    "            If text, returns HTML Markdown string.\n",
    "    \n",
    "    Returns:\n",
    "        str or display: Based on return_value\n",
    "\n",
    "\n",
    "    Date Created:\n",
    "    Date Last Maintained: August 17, 2025\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        df1 = df[column_order]\n",
    "    except:\n",
    "        print('DataFrame must include columns: Title, Header, Description')\n",
    "        return ''\n",
    "\n",
    "    text = \"\"\n",
    "    step_number = 1\n",
    "    last_title = None\n",
    "    last_header = None\n",
    "    open_l2 = False  # Track if L2 <ul> is open\n",
    "    open_l3 = False  # Track if L3 <ul> is open\n",
    "\n",
    "    for _, row in df1.iterrows():\n",
    "        curr_title = row[column_order[0]]\n",
    "        curr_header = row[column_order[1]]\n",
    "        curr_description = row[column_order[2]]\n",
    "\n",
    "        # If new Title\n",
    "        if curr_title != last_title:\n",
    "            if open_l3:\n",
    "                text += \"</ul>\\n\"\n",
    "                open_l3 = False\n",
    "            if open_l2:\n",
    "                text += \"</ul>\\n\"\n",
    "                open_l2 = False\n",
    "            if last_title is not None:\n",
    "                text += \"</ul>\\n\"  # Close previous title's outer <ul>\n",
    "\n",
    "            text += f\"<h4>{step_number}. {curr_title}</h4>\\n<ul>\\n\"\n",
    "            step_number += 1\n",
    "            last_title = curr_title\n",
    "            last_header = None  # Reset header context\n",
    "\n",
    "        # If new Header\n",
    "        if curr_header != last_header and isinstance(curr_header, str) and curr_header.strip():\n",
    "            if open_l3:\n",
    "                text += \"</ul>\\n\"\n",
    "                open_l3 = False\n",
    "            if open_l2:\n",
    "                text += \"</ul>\\n\"\n",
    "                open_l2 = False\n",
    "\n",
    "            text += f\"  <ul><li>{curr_header}</li>\\n\"\n",
    "            open_l2 = True\n",
    "            last_header = curr_header\n",
    "\n",
    "        # If Description exists\n",
    "        if isinstance(curr_description, str) and curr_description.strip():\n",
    "            if not open_l3:\n",
    "                text += \"    <ul>\\n\"\n",
    "                open_l3 = True\n",
    "            text += f\"      <li>{curr_description}</li>\\n\"\n",
    "\n",
    "    # Close any open lists at the end\n",
    "    if open_l3:\n",
    "        text += \"    </ul>\\n\"\n",
    "    if open_l2:\n",
    "        text += \"  </ul>\\n\"\n",
    "    text += \"</ul>\\n\"\n",
    "\n",
    "    if return_value == \"\":\n",
    "        display(HTML(text))\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "\n",
    "# File Description: Default Storage Location. Should try my absolute Best NOT to use. But can be a temporary holding spot.\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Will Not work on GitHub\n",
    "import sys\n",
    "sys.path.append(\"/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions/\")\n",
    "\n",
    "from Connections import ParamterMapping\n",
    "\n",
    "def JupyterNotebookMarkdown(df,return_value=\"\"):\n",
    "    \n",
    "    '''\n",
    "    Function to Create a Markdown file from Process DF, which is a data frame of the structure, \n",
    "    Title,Header,Description\n",
    "    \n",
    "    Args:\n",
    "        Dataframe( Must be of format, Title, Header, Description)\n",
    "        return_value (str: \"\" or text):\n",
    "            If Blank, will render text in HTML Format. \n",
    "            If text, then will return text for rendering in HTML Markdown\n",
    "    \n",
    "    Returns:\n",
    "        Conditional on Return Value. Please read Args.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        df1 = df[['Title','Header','Description']]\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        print('DataFrame does not meet structure requirement, which must include 3 Column: Title, Header, Description')\n",
    "        return ''\n",
    "    \n",
    "    title= \"\"\n",
    "    step_number = 1\n",
    "    text = \"\"\n",
    "\n",
    "    l2_bullet = '-'  # Level 2 Bullet\n",
    "    l3_bullet = '*'  # Level 3 Bullet\n",
    "\n",
    "    for index, row in df1.iterrows():\n",
    "        # Ensure previous list is closed before starting a new title\n",
    "        if title and title != row.iloc[0]:  \n",
    "            text += \"</ul>\\n\"  # Close the last unordered list before switching to a new title\n",
    "\n",
    "        # If it's a new title, start a new section\n",
    "        if title == \"\" or title != row.iloc[0]:\n",
    "            text += f\"<h4>{step_number}. {row.iloc[0]}</h4>\\n<ul>\\n\"  # Reset indentation\n",
    "            step_number += 1\n",
    "            title = row.iloc[0]  # Store the new title\n",
    "\n",
    "        # Add Level 2 content (Column 2)\n",
    "        if isinstance(row.iloc[1], str) and row.iloc[1].strip():\n",
    "            text += f\"  <li>{row.iloc[1]}</li>\\n\"  # L2 starts here\n",
    "\n",
    "            # Add Level 3 content (Column 3) only if it exists\n",
    "            if isinstance(row.iloc[2], str) and row.iloc[2].strip():\n",
    "                text += f\"    <ul><li>{row.iloc[2]}</li></ul>\\n\"  # L3 indented under L2\n",
    "\n",
    "    text += \"</ul>\\n\"  # Close any remaining lists\n",
    "\n",
    "    if return_value ==\"\":# Display the formatted HTML output in Jupyter Notebook\n",
    "        display(HTML(text))\n",
    "        \n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "\n",
    "def DataFrameFromProcess(process_name=None,\n",
    "                        return_value = 'Markdown'):\n",
    "    \n",
    "    '''\n",
    "    Function to Extract Data from Process Sheet and Return Markdown Text in Jupyter Notebook.\n",
    "    Created because Streamlit functionality Changed and could not support HTML Display functionality.\n",
    "    \n",
    "    Parameters:\n",
    "        process_name (str): Value in Column Process, From Google SHeet Process.\n",
    "        return_value (str): Markdown (returns Markdown value), otherwise it returns filtered dataframe\n",
    "    \n",
    "    Returns: \n",
    "        Based on return_value and process name. Dataframe, Filtered Data Frame or HTML Markdown text.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(ParamterMapping('ProcessSheet')['CSV'].item())\n",
    "    except:\n",
    "        print('Could Not Extract DataFrame')\n",
    "    \n",
    "    if process_name ==None:\n",
    "        return JupyterNotebookMarkdown(df)\n",
    "    \n",
    "    try:\n",
    "        df1 = df[df['Process']==process_name].copy()\n",
    "    except:\n",
    "        print('Could Not Filter Process Name')\n",
    "        return df\n",
    "    \n",
    "    if return_value == 'Markdown':\n",
    "        try:\n",
    "            return JupyterNotebookMarkdown(df1)\n",
    "        except:\n",
    "            print('Could Not Render JupyterNotebookMarkdown')\n",
    "            return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a625e6-b74b-4221-b8e3-c86ac80d5d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa59ba-13f1-400a-9742-36bb03a5ef49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8e3a9-4920-4e12-bf32-58f97e778d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff69b0-c69c-461d-ac01-3da82bd9bb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db4215-d821-4838-88af-6c7a729d7e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def TranposeNonTimeSeriesDF(df, index, columns=None):\n",
    "    '''\n",
    "    Transposes a non-time-series DataFrame from wide to long format by melting specified columns.\n",
    "\n",
    "    This is especially useful for flattening columns into a single column to support tools \n",
    "    like Power BI, where long format enables dynamic pivoting and aggregation.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input pandas DataFrame.\n",
    "        index (list): Columns to retain as identifiers (will remain unchanged).\n",
    "        columns (list): Columns to unpivot into key-value pairs.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A long-format DataFrame with 'variable' and 'value' columns.\n",
    "    '''\n",
    "    if not columns:\n",
    "        columns = [col for col in final_df1.columns if (isinstance(col, pd.Timestamp))|(isinstance(col, datetime.datetime))]\n",
    "    \n",
    "    return df.melt(id_vars=index, value_vars=columns)\n",
    "\n",
    "def CreatePivotTableFromTimeSeries(df,\n",
    "                                   index,\n",
    "                                   columns,\n",
    "                                   values,\n",
    "                                   aggfunc='sum',\n",
    "                                   skipna=True):\n",
    "    \n",
    "    '''\n",
    "    Function to Summaryize a Time Series Dataframe into a Pivot. Creating a number of critical Metrics.\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1. Pivot\n",
    "    if index==None:\n",
    "        df1 = df.pivot_table(columns=columns,values=values,aggfunc=aggfunc)\n",
    "    else:\n",
    "        df1 = df.pivot_table(index=index, columns=columns, values=values, aggfunc=aggfunc)\n",
    "\n",
    "    # 2. Capture original month columns IMMEDIATELY after pivot\n",
    "    month_cols = df1.columns.tolist()\n",
    " \n",
    "    # 3. Add rolling window stats\n",
    "    if len(month_cols) >= 3:\n",
    "        df1['AVG_3M'] = df1[month_cols[-3:]].mean(axis=1, skipna=skipna)\n",
    "        df1['CHG_3M'] = df1[month_cols[-1]]-df1[month_cols[-3]]\n",
    "        try:\n",
    "            df1['PERC_CHG_3M'] = df1['CHG_3M']/df1[month_cols[-3]]\n",
    "        except:\n",
    "            df1['PERC_CHG_3M'] = 0\n",
    "    \n",
    "    if len(month_cols) >= 6:\n",
    "        df1['AVG_6M'] = df1[month_cols[-6:]].mean(axis=1, skipna=skipna)\n",
    "        df1['CHG_6M'] = df1[month_cols[-1]]-df1[month_cols[-6]]\n",
    "        try:\n",
    "            df1['PERC_CHG_6M'] = df1['CHG_6M']/df1[month_cols[-6]]\n",
    "        except:\n",
    "            df1['PERC_CHG_6M'] = 0\n",
    "            \n",
    "    if len(month_cols) >= 12:\n",
    "        df1['AVG_12M'] = df1[month_cols[-12:]].mean(axis=1, skipna=skipna)\n",
    "        df1['CHG_12M'] = df1[month_cols[-1]]-df1[month_cols[-12]]\n",
    "        try:\n",
    "            df1['PERC_CHG_12M'] = df1['CHG_12M']/df1[month_cols[-12]]\n",
    "        except:\n",
    "            df1['PERC_CHG_12M'] = 0\n",
    "\n",
    "    df1['CHG_DF']  = df1[month_cols[-1]]-df1[month_cols[0]]\n",
    "    df1['AVG_DF'] = df1[month_cols[-1:]].mean(axis=1, skipna=skipna)\n",
    "    df1['PERC_CHG_DF'] = df1['AVG_DF']/df1[month_cols[-1]]\n",
    "\n",
    "    \n",
    "    # 4. Now calculate global stats **only using the original month columns**\n",
    "    stats = pd.DataFrame({\n",
    "        'MEAN': df1[month_cols].mean(axis=1, skipna=skipna),\n",
    "        'STD': df1[month_cols].std(axis=1, skipna=skipna),\n",
    "        'MAX': df1[month_cols].max(axis=1, skipna=skipna),\n",
    "        'MIN': df1[month_cols].min(axis=1, skipna=skipna),\n",
    "        'COUNT': df1[month_cols].count(axis=1)\n",
    "    })\n",
    "\n",
    "    # 5. Merge the stats\n",
    "    df1 = pd.concat([df1, stats], axis=1)\n",
    "    \n",
    "    return df1.fillna(0)\n",
    "\n",
    "\n",
    "def CreateMultiplePivotTableFromTimeSeries(df,\n",
    "                                           index_list,\n",
    "                                           metric_list,\n",
    "                                           column):\n",
    "    '''\n",
    "    Function to utilize when Attempting to Create Multip[le Times Series. Specifically Multiple Metrics, and Multiple Index's\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through all Possible Metrics Selected.\n",
    "    \n",
    "    for metric in metric_list:\n",
    "        print(f'Attempting to Process:{metric}')\n",
    "        try:\n",
    "            all_df = CreatePivotTableFromTimeSeries(df=df,index=None,columns=column,values=metric,aggfunc='sum') \n",
    "            cols = list(all_df.columns)\n",
    "            all_df = all_df.reset_index(drop=True)\n",
    "            all_df['METRIC'] = metric\n",
    "            cols.insert(0,'METRIC')\n",
    "\n",
    "            for key in index_list:\n",
    "                cols.insert(0,key)\n",
    "                all_df[key] = 'All'\n",
    "\n",
    "            final_df = pd.concat([final_df,all_df[cols]])\n",
    "            # Iterate through all Index Items Individually\n",
    "            for key in index_list:\n",
    "                temp = CreatePivotTableFromTimeSeries(df,\n",
    "                                                      index=key,\n",
    "                                                      values=metric,\n",
    "                                                      columns=column).reset_index() \n",
    "                for missing in [x for x in index_list if x != key]:\n",
    "                    temp[missing] = 'All'\n",
    "                temp['METRIC'] = metric\n",
    "                final_df = pd.concat([final_df,temp])\n",
    "\n",
    "            # Add Value for Metric with Entire Index Combination\n",
    "            temp = CreatePivotTableFromTimeSeries(df,index=index_list,values=metric,columns=column).reset_index()\n",
    "            temp['METRIC'] = metric\n",
    "            final_df = pd.concat([final_df,temp])\n",
    "        except:\n",
    "            print(f'Could Not Process Metric:{metric}.')\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def CreateMultiplePivotTableFromTimeSeries(df,index_list,metric_list,column):\n",
    "    '''\n",
    "    Function to utilize when Attempting to Create Multip[le Times Series. Specifically Multiple Metrics, and Multiple Index's\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through all Possible Metrics Selected.\n",
    "    for metric in metric_list:\n",
    "        all_df = CreatePivotTableFromTimeSeries(df=df,index=None,columns=column,values=metric,aggfunc='sum') \n",
    "        cols = list(all_df.columns)\n",
    "        all_df = all_df.reset_index(drop=True)\n",
    "        all_df['METRIC'] = metric\n",
    "        cols.insert(0,'METRIC')\n",
    "\n",
    "        for key in index:\n",
    "            cols.insert(0,key)\n",
    "            all_df[key] = 'All'\n",
    "\n",
    "        final_df = pd.concat([final_df,all_df[cols]])\n",
    "\n",
    "        # Iterate through all Index Items Individually\n",
    "        for key in index_list:\n",
    "            temp = CreatePivotTableFromTimeSeries(df,index=key,\n",
    "                                                  values=metric,\n",
    "                                                  columns=column).reset_index() \n",
    "            for missing in [x for x in index if x != key]:\n",
    "                temp[missing] = 'All'\n",
    "            temp['METRIC'] = metric\n",
    "            final_df = pd.concat([final_df,temp])\n",
    "        \n",
    "        # Add Value for Metric with Entire Index Combination\n",
    "        temp = CreatePivotTableFromTimeSeries(df,index=index_list,values=metric,columns=column).reset_index()\n",
    "        temp['METRIC'] = metric\n",
    "        final_df = pd.concat([final_df,temp])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "def SummarizeTimeSeriesDf(df,\n",
    "                          summary_cols,\n",
    "                          primary_key_list):\n",
    "    '''\n",
    "    Function to Summarize a Time Series dataframe based on a finite number of identified Columns.\n",
    "    \n",
    "    Parameters\n",
    "        df (Dataframe): TimeSeries in Nature\n",
    "        summary_cols (List): List of Columns which are to be included in SUmmary\n",
    "        primary_key_list (list): Primary Key of Dataframe\n",
    "    \n",
    "    Returns\n",
    "        temp_df1: Raw Data of SUmmary Cols with a Count of Observations. If include Month Variable Easy to add to Pivot Table\n",
    "        summary: Summary (Excluding Primary Key). including Total Observations, MEan, Max, Min.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    temp_df = df[summary_cols].copy()\n",
    "    temp_df['COUNT'] = 1\n",
    "    \n",
    "    # Unique Occurances by Pivot Criteria. Important to Include Month\n",
    "    temp_df1 = temp_df.groupby(summary_cols).sum().reset_index().rename(columns={'COUNT':'TOTAL_DAYS'})\n",
    "    \n",
    "    pivot_columns1 = [x for x in summary_cols if x not in primary_key_list]\n",
    "    \n",
    "    summary = temp_df1.groupby(pivot_columns1).agg(\n",
    "        TOTAL=('TOTAL_DAYS', 'count'),\n",
    "        AVG_DAYS_OPEN=('TOTAL_DAYS', 'mean'),\n",
    "        MAX_OBS=('TOTAL_DAYS', 'min'),\n",
    "        MIN_OBS=('TOTAL_DAYS', 'max')).reset_index()\n",
    "    \n",
    "    return temp_df1,summary\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def SampleDataFrame(df, \n",
    "                    conf=.95, \n",
    "                    me=0.05,\n",
    "                    mv=0.5,\n",
    "                    print_=0,\n",
    "                    new_column_name=\"\"):\n",
    "    \"\"\"\n",
    "    Returns a random sample from a DataFrame based on confidence level and margin of error.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The dataset to sample from.\n",
    "        conf(float): Desired Confidence Percentage Level (e.g., 90, 95, 99).\n",
    "        me (float): Margin of Error, (default is 5%).\n",
    "        mv (float): Maximum Variability (Expected Level of Default)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A random sample of the required size.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if not 0 <= mv <= 1:\n",
    "        raise ValueError(\"mv (failure rate) must be between 0 and 1.\")\n",
    "\n",
    "    N = len(df)\n",
    "    if N == 0:\n",
    "        raise ValueError(\"DataFrame is empty\")\n",
    "\n",
    "    # Calculate the Z-score based on the confidence level\n",
    "    z = norm.ppf(1 - (1 - conf) / 2)\n",
    "    \n",
    "\n",
    "    # Calculate the initial sample size (without finite population correction)\n",
    "    n0 = (z**2 * mv * (1 - mv)) / (me**2)\n",
    "    \n",
    "    # Apply finite population correction if the population is smaller than 100,000\n",
    "    if N >= 10000:  # For large populations, skip the correction\n",
    "        n = int(n0)\n",
    "    else:\n",
    "        n = int((n0 * N) / (n0 + N - 1))\n",
    "\n",
    "    if print_==1:\n",
    "        print(f\"Z-score: {z}\")  # Debug Z-score\n",
    "        print(f\"Initial sample size (n0): {n0}\")  # Debug n0\n",
    "        print(f\"Sample size with FPC: {n}\")  # Debug final sample size\n",
    "    \n",
    "    sample = df.sample(n=n, random_state=42)\n",
    "    \n",
    "    if len(new_column_name)==0:\n",
    "        return sample \n",
    "\n",
    "    else:\n",
    "        sample_index = sample.index\n",
    "        df[new_column_name] = 0\n",
    "        df.loc[sample_index, new_column_name] = 1\n",
    "        return df\n",
    "\n",
    "def ReviewEntireDataframe(df,file_name=None):\n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    \n",
    "    for column in df.columns:\n",
    "        start_time = timeit.default_timer()\n",
    "        temp_df = ColumnStatisticalReview(df,column)\n",
    "        print(f'Elapsed time to process {column}:{timeit.default_timer() - start_time:,.2f}')\n",
    "        final_df = pd.concat([final_df,temp_df],axis=1)\n",
    "    if file_name:\n",
    "        final_df.to_csv(f\"{file_name}.csv\")\n",
    "        \n",
    "    return final_df\n",
    "\n",
    "def ColumnStatisticalReview(df,\n",
    "                            column_name,\n",
    "                            partitions=10,\n",
    "                            top_x_records=10,\n",
    "                            exclude_blanks_from_segments=1,\n",
    "                            exclude_zeroes_from_segments=1):\n",
    "\n",
    "    '''\n",
    "    Function to Conduct a Simple Statistical Review of a Column, Including Understanding the positional distribution\n",
    "    of values. \n",
    "\n",
    "    Args:\n",
    "        column_name (str): Name of Column\n",
    "\n",
    "        partitions (int): Number of partitions to include (Decile 10)\n",
    "\n",
    "        exclude_blanks_from_segments (int): Binary Flag, whether to exclude Blank Values from Segment determination.\n",
    "        If blank values are excluded it gives a better representation for the members of the set, however it might \n",
    "        provide a misleading representation of the population.\n",
    "\n",
    "        exclude_zeroes_from_segments (int): As above, with respect to 0 values. Is processed after exclude_blanks, as\n",
    "        such it can include both blanks and true 0 values. \n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    temp_dict = {}\n",
    "    \n",
    "    is_numeric = pd.api.types.is_numeric_dtype(df[column_name])\n",
    "    \n",
    "    if is_numeric:\n",
    "        temp_dict['SUM'] = df[column_name].sum()\n",
    "        temp_dict['MEAN'] = df[column_name].mean()\n",
    "        temp_dict['STD_DEV'] =  df[column_name].std()\n",
    "        temp_dict['MEDIAN'] = df[column_name].median()\n",
    "        temp_dict['MAX'] = df[column_name].max()\n",
    "        temp_dict['MIN'] = df[column_name].min()\n",
    "        \n",
    "    temp_dict['TOTAL_RECORDS'] = len(df)\n",
    "    temp_dict['UNIQUE_RECORDS'] = len(df.drop_duplicates(column_name))\n",
    "    temp_dict['NA_RECORDS'] = len(df[df[column_name].isna()])\n",
    "    temp_dict['NULL_RECORDS'] = len(df[df[column_name].isnull()])\n",
    "    \n",
    "    if is_numeric:\n",
    "        temp_dict['ZERO_RECORDS'] = len(df[df[column_name]==0])\n",
    "        temp_dict['NON_ZERO_RECORDS'] = len(df[df[column_name]!=0])    \n",
    "\n",
    "    temp_df = pd.DataFrame(temp_dict.values(),index=temp_dict.keys(),columns=[column_name])\n",
    "    \n",
    "    if temp_dict['TOTAL_RECORDS']==len(df[df[column_name].isnull()]):\n",
    "        return temp_df\n",
    "\n",
    "    # Add top X records Based on Frequency\n",
    "    if top_x_records>0:\n",
    "        top_instances = pd.DataFrame(df[column_name].value_counts(dropna=False).head(top_x_records)).reset_index().rename(columns={column_name:'count','index':column_name})\n",
    "        if len(top_instances)>0:\n",
    "            top_instances[column_name] = top_instances.apply(lambda row: f\"Value: {row[column_name]}, Frequency: {row['count']}\", axis=1)\n",
    "            top_instances['index'] = [f\"Top {x+1}\" for x in range(len(top_instances[column_name]))]\n",
    "            top_instances = top_instances.drop('count',axis=1).set_index('index')\n",
    "            temp_df = pd.concat([temp_df,top_instances])\n",
    "        \n",
    "    if (partitions>0)&(pd.api.types.is_numeric_dtype(df[column_name]))&(temp_dict['UNIQUE_RECORDS']>1):\n",
    "        segment_df = ColumnPartitioner(df=df,\n",
    "                                       column_name=column_name,\n",
    "                                       partitions=partitions,\n",
    "                                       exclude_blanks=exclude_blanks_from_segments,\n",
    "                                       exclude_zeros=exclude_zeroes_from_segments,\n",
    "                                       return_value='')\n",
    "        \n",
    "        seg_val_df = ColumnPartitioner(df=df,\n",
    "                                           column_name=column_name,\n",
    "                                           partitions=partitions,\n",
    "                                           exclude_blanks=exclude_blanks_from_segments,\n",
    "                                           exclude_zeros=exclude_zeroes_from_segments,\n",
    "                                           return_value='agg_value').rename(columns={'VALUE':column_name})\n",
    "\n",
    "        return pd.concat([temp_df,segment_df.T,seg_val_df])\n",
    "    return temp_df\n",
    "\n",
    "def CompareFunction(func1,func2,additional_records=20):\n",
    "    \n",
    "    '''\n",
    "    Function which Compares 2 Functions and determines if they are different. Specifically, it can help to easily\n",
    "    Manage Version control of Functions outside of a More robust environment such as GIT.\n",
    "    \n",
    "\n",
    "    '''\n",
    "    \n",
    "    list1 = FunctionToSTR(func1)\n",
    "    list2 = FunctionToSTR(func2)\n",
    "    \n",
    "    length = max(len(list1),len(list2))\n",
    "    \n",
    "    for record in range(0,length):\n",
    "        if list1[record]==list2[record]:\n",
    "            if record == (length-1):\n",
    "                print(\"All Records Reconcile\")\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                print(list1[record:record+additional_records])\n",
    "                print(list2[record:record+additional_records])\n",
    "            except:\n",
    "                print(list1[record:record:])\n",
    "                print(list2[record:record:])\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7f03f7-6c88-43bd-85d0-05dfb969eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import webbrowser\n",
    "import datetime\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n",
    "def DownloadFilesFromGit(user='derek-dewald',\n",
    "                        repo='Python_Tools',\n",
    "                        folder='d_py_functions',\n",
    "                        output_folder=\"\"):\n",
    "    '''\n",
    "    Function to Download Files from Github to a dedicated folder. Specifically used when i DO NOT want to formally link to Github.\n",
    "    \n",
    "    Parameters:\n",
    "        User:\n",
    "        Repo:\n",
    "        folder:\n",
    "        output_folder:\n",
    "        \n",
    "    Returns:\n",
    "        Saves files to Output Folder.\n",
    "    \n",
    "\n",
    "    '''\n",
    "    \n",
    "    if len(output_folder) == 0:\n",
    "        output_folder = os.getcwd()\n",
    "    \n",
    "    api_url = f\"https://api.github.com/repos/{user}/{repo}/contents/{folder}\"\n",
    "    response = requests.get(api_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        files = response.json()\n",
    "        py_files = [file for file in files if file['name'].endswith('.py')]\n",
    "\n",
    "        for file in py_files:\n",
    "            file_url = file['download_url']\n",
    "            file_name = file['name']\n",
    "            file_response = requests.get(file_url)\n",
    "\n",
    "            if file_response.status_code == 200:\n",
    "                with open(os.path.join(output_folder, file_name), \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(file_response.text)\n",
    "                    \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ParamterMapping(Definition=\"\"):\n",
    "    \n",
    "    '''\n",
    "    Function to Google Mapping Sheet, which is used to store Mappings, Links, etc.\n",
    "    For both simplicity and Organization\n",
    "    \n",
    "    Args:\n",
    "        Definition (Str): Key word used to Access individual elements\n",
    "        \n",
    "    Returns:\n",
    "        Dataframe, unless Definition is defined, in which case it might be Str.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSwDznLz-GKgWFT1uN0XZYm3bsos899I9MS-pSvEoDC-Cjqo9CWeEuSdjitxjqzF3O39LmjJB0_Fg-B/pub?output=csv')\n",
    "    \n",
    "    # If user has not included a definition, the return entire DF\n",
    "    if len(Definition)==0:\n",
    "        return df\n",
    "    else:\n",
    "        try:\n",
    "            df1 = df[df['Definition']==Definition]\n",
    "            if len(df1)==1:\n",
    "                if df1['TYPE'].item()=='csv':\n",
    "                    return pd.read_csv(df1['VALUE'].item())\n",
    "                else:\n",
    "                    return df1['VALUE'].item()\n",
    "        except:\n",
    "            return df[df['Definition']==Definition] \n",
    "\n",
    "\n",
    "def BackUpGoogleSheets(location='/Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/'):\n",
    "    '''\n",
    "    Function to Create a Backup of Information Stored in Google Sheets.\n",
    "    \n",
    "    Parameters:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        CSV Files \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df = ParamterMapping()\n",
    "    \n",
    "    for row in range(len(df)):\n",
    "        try:\n",
    "            file_name = df['Definition'][row]\n",
    "            file_location = df['CSV'][row]\n",
    "            month = datetime.datetime.now().strftime('%b-%y')\n",
    "            \n",
    "            temp_df = pd.read_csv(file_location)\n",
    "            temp_df.to_csv(f'{location}{file_name}_{month}.csv',index=False)\n",
    "            print(f'Back Up Saved, {location}{file_name}')\n",
    "        except:\n",
    "            print(f'Counld Not Print Record {row}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def NavigateUsingDMap():\n",
    "     \n",
    "    '''\n",
    "    Function to Google Mapping Sheet, Navigate to Specific Sites.\n",
    "    Provides Options, Enable Selection based on inputs.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "    \n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSwDznLz-GKgWFT1uN0XZYm3bsos899I9MS-pSvEoDC-Cjqo9CWeEuSdjitxjqzF3O39LmjJB0_Fg-B/pub?output=csv')\n",
    "    \n",
    "    display(df)\n",
    "    \n",
    "    p = input('Which Process would You like to review?')\n",
    "    v = input('What would you like to return?')\n",
    "    \n",
    "    df1 = df[df['Definition']==p]\n",
    "    \n",
    "    if v.lower() =='link':\n",
    "        webbrowser.open(df1['Link'].item())\n",
    "    elif v.lower() == 'csv':\n",
    "        return pd.read_csv(df1['CSV'].item())\n",
    "    elif v.lower()=='streamlit':\n",
    "        webbrowser.open(df1['Streamlit'].item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
