Process,Categorization,Word,Definition,C1_ORDER,C12_ORDER,C3_ORDER
ML Project,Process Step,Problem Definition,"Define, Quantify and Articulate Problem.",1.0,1,1
ML Project,Process Step,Problem Definition,"Project Goal Explicitly stated in 3-4 Sentences, can include exclusion items in addendum, not in original statement, which sould be positive, optimistic and include a value creating definition.",1.0,1,1
ML Project,Process Step,Problem Definition,Explicilty Defined Business Delieverables,1.0,1,1
ML Project,Process Step,Problem Definition,Explicilty Defined Expected Outcomes and KPIs,1.0,1,1
ML Project,Process Step,Problem Definition,"Identify Model Baseline, or who is responsible for defining if not available.",1.0,1,1
ML Project,Definition,Data Collection,"Data collection involves identifying, sourcing, and acquiring the datasets required to solve the defined problem. This may include internal databases, APIs, logs, third-party data, or manually collected data. Key considerations include data availability, coverage, granularity, freshness, and legal or privacy constraints. The quality and relevance of collected data fundamentally limit the ceiling of model performance.",1.0,0,2
ML Project,Process Step,Data Collection,Need to Create Definition and Requirements,1.0,1,2
ML Project,Definition,Data Preparation,"Data preparation focuses on cleaning and structuring raw data into a usable format for modeling. This includes handling missing values, correcting errors, standardizing formats, encoding categorical variables, and aligning labels with features. It also often involves train/validation/test splitting to prevent data leakage. This step is critical because most models assume clean, well-structured inputs and are highly sensitive to data issues.",1.0,0,3
ML Project,Process Step,Data Preparation,"Identify Data Elements which appear relevant (Can be either based on desired, or what is currently Available).",1.0,1,3
ML Project,Process Step,Data Preparation,"Label, and Document all data elements in Model (Semantic, Functional, Business Definitions and Theoretircal Inclusion)",1.0,1,3
ML Project,Process Step,Data Preparation,"Document data omissions, known data quality issues, or assumptions (including Imbalances).",1.0,1,3
ML Project,Process Step,Data Preparation,"Document all Imputation, Deletion, Standardization to be applied.",1.0,1,3
ML Project,Process Step,Data Preparation,"Define Approach for Training, Testing and Validation. Create Final Dataset to proceed forward.",1.0,1,3
ML Project,Process Step,Data Preparation,Complete EDA on Dataset.,1.0,1,3
ML Project,Process Step,Exploratory Data Analysis,NNNNNNNEEEEEWWWWWWW .Needs comments.,1.0,1,4
ML Project,Definition,Feature Engineering,"Feature engineering is the process of creating new input variables that better represent the underlying patterns in the data. It may include transformations (log, scaling), aggregations, interactions, temporal features, or domain-specific encodings. Effective feature engineering can significantly improve model performance even with simple algorithms. It embeds domain knowledge into the model and often provides more value than algorithmic complexity.",1.0,0,5
ML Project,Process Step,Feature Engineering,"Create Aggregation Data, Rations, PCA, etc. Note these should be identified and defined in Data Prepartion, this is simple technical execution and creation.",1.0,1,5
ML Project,Process Step,Model,"Define Models which will be included in Pipeline, include explanation as to explicitly what the Model does, why it is relevant for this problem and what it will solve as it relates to this problem. Where this differs across models, must explain and document the differences.",1.0,1,6
ML Project,Process Step,Model,"Define how model will be evaluated, what metrics will be minimized (or maximized) balance between training results versus ability to generalize, balancing overfitting and performance.",1.0,1,6
ML Project,Process Step,Model,"If certain models are not considered, explicitly state why, what would need ot change in order to review or reconsider this model and who in the business would be responsible for next steps where obvious omissions, data quality, process or procedure gaps exist.",1.0,1,6
ML Project,Process Step,Model,"Define how feature evaluation will occur, explicitly state KPIs and document how they relate to project delieverables, business goals and expected outcomes.",1.0,1,6
ML Project,Consideration,Model,Is your Data Structured in a way that is conducive to your Model.,1.0,2,6
ML Project,Consideration,Model,"Any data set can be optimized, even when there is NO relation. It will generalize.",1.0,2,6
ML Project,Consideration,Model,"An Example of this would a classification model with Wolves and Dogs,  many wolf photos happened to be taken in snowy environments, while dog photos were often taken indoors or on grass. The model learned to detect snow, not animals.",1.0,2,6
ML Project,Consideration,Model,"Models will cheat and can solve problems which appear to be optimal, but they might not be solving what you expect or require, they might be finding patterns in the data which you do not see. An Example of this would a classification model with Wolves and Dogs,  many wolf photos happened to be taken in snowy environments, while dog photos were often taken indoors or on grass. The model learned to detect snow, not animals.",1.0,2,6
ML Project,Definition,Feature Selection,"Feature selection involves choosing a subset of relevant features to include in the model. This can be done using statistical tests, model-based importance scores, correlation analysis, or regularization techniques. The goal is to reduce noise, improve generalization, and simplify the model. Fewer, more informative features often lead to better performance and easier interpretability.",1.0,0,7
ML Project,Process Step,Feature Selection,"Create Pipeline which automates selection, or document where it will be manual for Cost/Benefit reasons.",1.0,1,7
ML Project,Consideration,Feature Selection,"Avoid ambigious features. Is a Banana ripe, who says so?",1.0,2,7
ML Project,Consideration,Feature Selection,"Careful when something is truly random generated, Atmospheric Change, Earthquakes, Stocks. Very difficult, if not impossible to predict.",1.0,2,7
ML Project,Consideration,Feature Selection,"MNIST performance when tilting Images, of adding noise.",1.0,2,7
ML Project,Definition,Feature Selection,"Area Under the Curve: AUC (Area Under the Curve) measures a model’s ability to distinguish between classes by summarizing the performance of the ROC (Receiver Operating Characteristic) curve. It represents the probability that the model ranks a randomly chosen positive example higher than a randomly chosen negative one. AUC ranges from 0.5 (no better than chance) to 1.0 (perfect separation), with higher values indicating better classification performance.
AUC is primarily a binary classification metric, so when using against a multivariate challenge must determine how to score, OVR, OVO. One Vs Rest, One vs One. Using MNist as an example, OVR evaluates 10 0 vs (1,2,3,4,5,6,7,8,9), 1 vs () ... etc, Where OVO measures 45 0 Vs 1, 0 vs 2, etc..",1.0,1000,7
ML Project,Definition,Feature Selection,"Bias: Bias refers to the systematic error in a model that causes it to consistently deviate from the true value or correct predictions. It occurs when an algorithm makes incorrect assumptions or omissions about the data, leading to errors.
High Bias (Underfitting): The model is too simple and cannot capture patterns. 
Low Bias, High Variance (Overfitting). The model memorizes the data but does not generalize.",1.0,1000,7
ML Project,Definition,Feature Selection,"Bias - Variance Trade Off: The bias-variance trade-off is a key concept in machine learning that highlights the balance between two sources of error: bias and variance, tuning the relationship between a model's complexity, the accuracy of its predictions, and how well it can make predictions on previously unseen data that were not used to train the model The challenge is to find a model that strikes the right balance between bias and variance, as reducing one typically increases the other. The ultimate goal is to minimize the total error, which is the sum of bias error, variance error, and irreducible noise inherent in the data. Achieving this balance ensures the model generalizes well to new, unseen data, avoiding both underfitting and overfitting. More Data vs More Data Science - Bias vs Variance 
It can often be explained by the Trade-Off (Bias - Data Scientist, Variance - Data), where to invest.

In general, as we increase the number of tunable parameters in a model, it becomes more flexible, and can better fit a training data set. It is said to have lower error, or bias. However, for more flexible models, there will tend to be greater variance to the model fit each time we take a set of samples to create a new training data set. It is said that there is greater variance in the model's estimated parameters.High-variance learning methods may be able to represent their training set well but are at risk of overfitting to noisy or unrepresentative training data. In contrast, algorithms with high bias typically produce simpler models that may fail to capture important regularities (i.e. underfit) in the data.",1.0,1000,7
ML Project,Definition,Feature Selection,"Variance: Variance refers to errors caused by models that are too sensitive to small fluctuations in the training data, often resulting in overfitting. High-variance models are overly flexible, capturing noise as if it were meaningful patterns. A model with many degrees of freedom (such as a high-degree polynomial model) is likely to have high variance and thus overfit the training data. As an example, if you created a model of How Predicting Housing Prices in 1 Neighbourhood would work and applied it to different neighbourhoods, if your model was simple, it wouldn’t work well anywhere and thus would be Wrong, but consistently-ish wrong. If your model was Good, it would work similarly well every well. If you model was overfit, it would work really well in 1 place, not so well elsewhere.
",1.0,1000,7
ML Project,Process Step,Training,Define Mock 0 Pipeline Once available. Insure to follow Standardized Amendment process once created. ,1.0,1,8
ML Project,Process Step,Training,,1.0,1,8
ML Project,Definition,Hyperparameter Tuning,"Hyperparameter tuning involves selecting optimal configuration values that control model behavior but are not learned directly from data. Examples include learning rate, tree depth, number of layers, or regularization strength. Techniques such as grid search, random search, or Bayesian optimization are commonly used. This step can materially improve performance and stability without changing the underlying model.",1.0,0,9
ML Project,Process Step,Hyperparameter Tuning,"Identify Paramaters before implementing and running Mock 0. If results of Training change Hyperparameter tuning, document explicitly why.",1.0,1,9
ML Project,Process Step,Hyperparameter Tuning,"Run through Hyperparameter tuning process, documenting all findings, assumptions.",1.0,1,9
ML Project,Process Step,Hyperparameter Tuning,"Finding must be communicated at this point of time, via Dashboard. Make Explicit determination if business approval is required before proceeding forward.",1.0,1,9
ML Project,Process Step,Model Evaluation,NNNNNNNEEEEEWWWWWWW .Needs comments.,1.0,1,10
ML Project,Process Step,Model Selection,"Includes Determination of Final Model to be used, and parameters included within Model.",1.0,1,11
ML Project,Process Step,Model Selection,"Must be formally documented, with all underlying results, documents and finding available in a clear and consistent documented process.",1.0,1,11
ML Project,Process Step,Model Selection,"Decision should include an expected Performance Change, an deployment plan, and owners, in addition to agreement of go forward KPI monitoring.",1.0,1,11
ML Project,Process Step,Validation,"Run hold back data after all decisions have been made, before approval. Need to COMMUNICATE this to people to avoid confusion. It is important as this should not bias or be done before the model is created, part of healthy Business Decisions.",1.0,1,12
ML Project,Definition,"Bias, Fairness and Ethics","This step examines whether the model produces systematically unfair or harmful outcomes across different groups. It includes analyzing data representation, outcome disparities, and unintended correlations. Ethical considerations may involve transparency, consent, explainability, and regulatory compliance. Addressing bias and fairness is essential for responsible, trustworthy, and legally compliant ML systems.",1.0,0,13
ML Project,Process Step,"Bias, Fairness and Ethics",Comment Needed,1.0,1,13
ML Project,Process Step,Model Summarization/ Model Interpretability,NNNNNNNEEEEEWWWWWWW .Needs comments.,1.0,1,14
ML Project,Definition,Deployment,"Deployment is the process of integrating the trained model into a production environment where it can generate real-world predictions. This may involve APIs, batch pipelines, streaming systems, or embedded applications. Considerations include scalability, latency, reliability, and versioning. Deployment turns a model from an experiment into a usable product.",1.0,0,15
ML Project,Process Step,Deployment,Need to Explain this as a step. If not order will not be restored necessary.,1.0,1,15
ML Project,Process Step,Monitoring,,1.0,1,16
ML Project,Pipeline Stage,Evaluation,"Evaluation measures how well the final model performs against defined success metrics on a truly unseen test dataset. Metrics depend on the problem type (e.g., accuracy, AUC, RMSE, precision-recall). This step provides an objective assessment of whether the model meets business or research requirements. Evaluation results often determine whether a model is production-ready.",1.0,9,34
ML Model,Consideration,Clustering,"Must Clarify this clearly, specifically the distinction between Behavior and Attributes, clustering should focus primarily on behavior. Specifically Demographics can dominate distiance differences relative to behavior without adding value.",2.0,3,17
ML Model,Consideration,Clustering,"Small Number of Stable, Interpretable, Member Archetypes that summaize the global behavior and can be reused for ML and Analysis.",2.0,3,17
ML Model,Consideration,Clustering,Stability over Uniqueness,2.0,3,17
ML Model,Consideration,Clustering,Interpretability over novelty,2.0,3,17
ML Model,Consideration,Clustering,Repeatability over perfection.,2.0,3,17
ML Model,Model Architecture,Reinforcement Learning,"Reinforcement learning trains an agent to make decisions by interacting with an environment and receiving rewards or penalties. The agent learns a policy that maximizes cumulative reward over time through trial and error. It is commonly used in robotics, game playing, and control systems.",2.0,9,34
Problem Solving,Process Step,Problem Definition,"Define problem, in a clear and explicit way such that it can be solved, tested or experiemented. Problem MUST be solvable and should be iterative, or have a series of iterative steps such that it can be effectively managed and solved",3.0,4,1
Problem Solving,Process Step,Problem Definition,"Define Problem Statement. Including clearly articulating why it matters, what is the impact of not having this solution.",3.0,4,1
Problem Solving,Process Step,Problem Definition,"Define the desired end state, in such a way that the contribution of the ML Model or project can achieve granular progress through iteration",3.0,4,1
Problem Solving,Process Step,Problem Definition,"Define the current state, how does the end state look different. Should be Quantifiable via metrics, and montetary impact.",3.0,4,1
Problem Solving,Process Step,Problem Definition,"Proceed Forward Decision. Who is responsible, how does it get made.",3.0,4,1
Problem Solving,Process Step,Problem Definition,"How to effectively and clearly document objection, concern, risks and doubts.",3.0,4,1
Problem Solving,Process Step,Problem Definition,Define EDA Process,3.0,4,1
Process Development,Guiding Principle,Simple,Provide Defintion.,4.0,5,18
Process Development,Guiding Principle,Clear,Provide Defintion.,4.0,5,19
Process Development,Guiding Principle,Evident,Provide Defintion.,4.0,5,20
Process Development,Guiding Principle,Obvious,Provide Defintion.,4.0,5,21
Process Development,Guiding Principle,Accountability,"Are Roles and Responsbilities explicity stated? and Is it clear who is responsible for what. Are goals SMART (or atleast defined) or at a minimum, is our partcipation understood and documented.  ",4.0,5,22
Communication,Guiding Principle,Engaging People,Simple things can make a huge differene.,5.0,6,23
Communication,Guiding Principle,Engaging People,"Giving people meaningful and engaging work, utilizing their thoughts, intellegence and making them feel Good are important.",5.0,6,23
Communication,Guiding Principle,Engaging People,Don’t try and rush change. It takes time and we need to learn and understand.,5.0,6,23
Goals,Guiding Principle,Specific,,6.0,7,24
Goals,Guiding Principle,Measurable,,6.0,7,25
Goals,Guiding Principle,Achievable,,6.0,7,26
Goals,Guiding Principle,Relevant,,6.0,7,27
Goals,Guiding Principle,Time Bound,,6.0,7,28
A|B Testing,Guiding Principle,TBD,,7.0,8,29
Best Linear Unbiased Estimator,Requirement,Homoscedasticity,Variance of the residuals should be constant.,8.0,9,30
Best Linear Unbiased Estimator,Requirement,Independence,Observations should be independent of each other. No Correlation between errors of residuals. Errors are autocorrelated with self. Durbin Watson,8.0,9,31
Best Linear Unbiased Estimator,Requirement,Linearity,Relationship between Independent and Dependent should be Linear. With finite variance,8.0,9,32
Best Linear Unbiased Estimator,Requirement,No Perfect Collinearity,,8.0,9,33
Best Linear Unbiased Estimator,Requirement,Normality of Residuals,,8.0,9,34
Machine Learning,General Principles,Optimization,"Optimization is the process of finding the best possible solution to a problem by systematically adjusting inputs or decisions to maximize or minimize a defined objective, subject to given constraints. In machine learning and analytics, optimization involves selecting model parameters that minimize error or maximize performance according to a chosen loss function. Importantly, what is considered “best” depends entirely on how the objective and constraints are defined.",,9,34
Machine Learning,Model Architecture,Unsupervised Learning,"Unsupervised learning works with unlabeled data and aims to discover hidden patterns or structure. The model groups, compresses, or summarizes the data without being told what the correct outcome is. Typical use cases include clustering, dimensionality reduction, and anomaly detection.",,9,34
Machine Learning,Model Architecture,Supervised Learning,"Supervised learning trains a model using labeled data, where the correct answer is known in advance. The model learns a mapping from inputs to outputs by minimizing the difference between its predictions and the true labels. Common examples include classification and regression problems.",,9,34
Machine Learning,Model Architecture,Semisupervised Learning,Semi-supervised learning combines a small amount of labeled data with a large amount of unlabeled data to improve learning performance. The model leverages the structure in the unlabeled data to generalize better than supervised learning alone. This approach is useful when labeling data is expensive or time-consuming.,,9,34
Machine Learning,General Principles,Deep Learning,"Deep learning is a subset of machine learning that uses multi-layer neural networks to automatically learn hierarchical representations from data, reducing the need for manual feature engineering. By stacking simple processing units called layers—each acting as a filter that transforms inputs into higher-level representations—deep learning models can capture complex patterns through composition. Early challenges such as vanishing gradients, where learning signals faded through many layers, were largely addressed through improved activation functions, optimization methods, and weight initialization strategies. In practice, building a deep learning model involves defining the network architecture (number of layers, connections, and activations) and then specifying how it learns by choosing an optimizer, loss function, and evaluation metrics during compilation.",,9,34
Machine Learning,General Principles,Machine Learning,"Using a process to enable computers to iteratively learn from the data and improve analysis, outcomes or understanding. Intersection of statistics, artificial intelligence and computer science. Machine's don't learn, they find optimal mathematical formulas based on the data it is presented. There is an assumption that this data set is both representative of other data sets,  and possess similiar statistical distributions', You can argue this is not learning, because slight variances can result in materially different responses and output, Term synonymous with machines doing tasks without explicitly being programmed. Building a statistical model, based on a dataset",,9,34
Mathematics,Theorm,Algorithm,"An algorithm is a procedure that unfolds over time and depends on: previous states, iteration history and accumulated information.",,9,34
Mathematics,Property,Colinearity,No perfect linear relationship between residuals,,9,34
Mathematics,Theorem,Best Linear Unbiased Estimator,"The Best Linear Unbiased Estimator (BLUE) is an estimation method in statistics that produces parameter estimates that are linear in the observed data, unbiased, and have the smallest possible variance among all such estimators. It originates from the Gauss–Markov theorem, developed in the early 19th century in the context of least squares and error theory. Its importance lies in providing a theoretical benchmark: under specific assumptions about error structure, no other linear unbiased estimator can be more precise. In practice, BLUE underpins ordinary and generalized least squares, and is widely applied in econometrics, engineering, and data science when modeling relationships with correlated or heteroskedastic errors",,9,34
Mathematics,Concept,Normality,Residuals should be normally distributed.,,9,34
Modelling,Theorm,Curse of Dimensionality,"As dimensionality grows, data points become increasingly sparse, distances lose meaning, and models require exponentially more data to learn reliable patterns. This makes learning, generalization, and computation more difficult, often degrading model performance rather than improving it. In high-dimensional spaces, the optimization landscape also becomes far more complex, with many local minima and saddle points, making it harder to identify or converge toward a meaningful global minimum.",,9,34
Modelling,Model Architecture,Autoregressive,"Autoregressive models generate outputs one step at a time, where each prediction depends on the previously generated outputs. This sequential dependency allows the model to capture context and coherence, making it powerful for tasks like language modeling and time-series forecasting. However, because predictions are made step by step, autoregressive methods can be slower at inference compared to parallel approaches.",,9,34
Orginization,Operational Definition,Process,"Terminology created by myself and utilized to identify the abstract level of how I would classiify items for inclusion of Notes and Definitions. Process is the HIGHEST level of abstraction, within a classification system. NOTE: The use of this differs sligtly across Notes and Definitions tabs, specifically the Highest Level of abstraction differs, with Definitions including MULTIPLE levels of abstraction, both at a individual concept level and at a Overall level. Please refer to Read Me for examples.",,9,34
Orginization,Operational Definition,Categorization,"Terminology created by myself and utilized to identify the abstract level of how I would classiify items for inclusion of Notes and Definitions. Categorization is used to explain process, and provide context  as to the relevance.",,9,34
Orginization,Operational Definition,Word,Self Explanatory,,9,34
Orginization,Operational Definition,Definition,Self Explanatory,,9,34
Training,Model Architecture,Cross Validation,"Model evaluation technique used to assess how well a model generalizes to unseen data by repeatedly splitting the dataset into training and validation subsets. The model is trained on one portion of the data and evaluated on another, and the results are aggregated to provide a more reliable estimate of performance than a single train–test split. This approach helps detect overfitting and supports more robust model selection",,9,34
