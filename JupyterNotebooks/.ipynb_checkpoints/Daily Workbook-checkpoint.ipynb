{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e392d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268839e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Arguments</th>\n",
       "      <th>Return</th>\n",
       "      <th>Code</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BinaryColumnCreator</th>\n",
       "      <td>No description available</td>\n",
       "      <td>[df, column_name, new_column_name, value, calc...</td>\n",
       "      <td>None</td>\n",
       "      <td>def BinaryColumnCreator(df,\\n                 ...</td>\n",
       "      <td>DF_Functions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TextClean</th>\n",
       "      <td>No description available</td>\n",
       "      <td>[df, column_list, clean_type]</td>\n",
       "      <td>None</td>\n",
       "      <td>def TextClean(df, \\n              column_list,...</td>\n",
       "      <td>DF_Functions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FillFromAbove</th>\n",
       "      <td>Purpose: Force Fill Information from above def...</td>\n",
       "      <td>[df, column_name, new_column_name]</td>\n",
       "      <td>None</td>\n",
       "      <td>def FillFromAbove(df,\\n                 column...</td>\n",
       "      <td>DF_Functions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ColumnStatisticalCompare</th>\n",
       "      <td>No description available</td>\n",
       "      <td>[df, df1, column_name]</td>\n",
       "      <td>None</td>\n",
       "      <td>def ColumnStatisticalCompare(df,df1,column_nam...</td>\n",
       "      <td>DF_Functions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategorizeBinaryChange</th>\n",
       "      <td>Function to Simply Apply a Condition to genera...</td>\n",
       "      <td>[change_column (str): Name of Column Created., ]</td>\n",
       "      <td></td>\n",
       "      <td>def CategorizeBinaryChange(df,\\n              ...</td>\n",
       "      <td>DF_Functions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ColumnElementalChange</th>\n",
       "      <td>Function to Compare the Element Level change o...</td>\n",
       "      <td>[df, df1, column_name, primary_key]</td>\n",
       "      <td></td>\n",
       "      <td>def ColumnElementalChange(df,\\n               ...</td>\n",
       "      <td>DF_Functions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFStructureReview</th>\n",
       "      <td>Function to Create a simplified view of the ov...</td>\n",
       "      <td>[primary_key(list): Primary Keys between, ]</td>\n",
       "      <td></td>\n",
       "      <td>def DFStructureReview(df,\\n                   ...</td>\n",
       "      <td>DF_Functions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ColumnPartitioner</th>\n",
       "      <td>Function to create partions from Float or INT ...</td>\n",
       "      <td>[partitions:, Total Number of desired Partitio...</td>\n",
       "      <td>None</td>\n",
       "      <td>def ColumnPartitioner(df,\\n                   ...</td>\n",
       "      <td>DF_Functions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ColumnStatisticalReview</th>\n",
       "      <td>Function to Conduct a Simple Statistical Revie...</td>\n",
       "      <td>[column_name (str): Name of Column, , partitio...</td>\n",
       "      <td>None</td>\n",
       "      <td>def ColumnStatisticalReview(df,\\n             ...</td>\n",
       "      <td>DF_Functions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generate_polynomial_features</th>\n",
       "      <td>Generates polynomial features for all numerica...</td>\n",
       "      <td>[df (pd.DataFrame): The input DataFrame., targ...</td>\n",
       "      <td></td>\n",
       "      <td>def generate_polynomial_features(df, target_co...</td>\n",
       "      <td>FeatureEngineering.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreateMarkdown</th>\n",
       "      <td>Function to Create a Markdown file from Proces...</td>\n",
       "      <td>[Dataframe( Must be of format, Title, Header, ...</td>\n",
       "      <td></td>\n",
       "      <td>def CreateMarkdown(df,return_value=\"\"):\\n    \\...</td>\n",
       "      <td>Organization.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreateMarkdownfromProcess</th>\n",
       "      <td>Function to call Process Map from Google sheet...</td>\n",
       "      <td>[process_name (str): Process Name as defined i...</td>\n",
       "      <td></td>\n",
       "      <td>def CreateMarkdownfromProcess(process_name,ret...</td>\n",
       "      <td>Organization.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extract_function_details_ast</th>\n",
       "      <td>Extracts structured function details from a Py...</td>\n",
       "      <td>[file_content (str): The raw string content of...</td>\n",
       "      <td></td>\n",
       "      <td>def extract_function_details_ast(file_content,...</td>\n",
       "      <td>Organization.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReadPythonFiles</th>\n",
       "      <td>Function which reads a Folder, iterating throu...</td>\n",
       "      <td>[location (str): Folder, ]</td>\n",
       "      <td></td>\n",
       "      <td>def ReadPythonFiles(location='/Users/derekdewa...</td>\n",
       "      <td>Organization.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ParamterMapping</th>\n",
       "      <td>Function to Google Mapping Sheet, which is use...</td>\n",
       "      <td>[Definition (Str): Key word used to Access ind...</td>\n",
       "      <td></td>\n",
       "      <td>def ParamterMapping(Definition=\"\"):\\n    \\n   ...</td>\n",
       "      <td>Connections.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReadDirectory</th>\n",
       "      <td>Function which reads reads a directory and ret...</td>\n",
       "      <td>[folder (str): The path to the directory. Defa...</td>\n",
       "      <td></td>\n",
       "      <td>def ReadDirectory(folder=\"\", file_type=\"\"):\\n ...</td>\n",
       "      <td>SharedFolder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DuplicateFileorFolder</th>\n",
       "      <td>Function to copy a file or folder to another l...</td>\n",
       "      <td>[source_path (str): Path to the file or folder...</td>\n",
       "      <td></td>\n",
       "      <td>def DuplicateFileorFolder(source_path, destina...</td>\n",
       "      <td>SharedFolder.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plot_correlation_matrix</th>\n",
       "      <td>Generates and displays a correlation matrix he...</td>\n",
       "      <td>[df (pd.DataFrame): The input DataFrame.]</td>\n",
       "      <td>None</td>\n",
       "      <td>def plot_correlation_matrix(df):\\n    \"\"\"\\n   ...</td>\n",
       "      <td>EDA.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plot_histograms</th>\n",
       "      <td>Plots histograms for each column in a DataFrame.</td>\n",
       "      <td>[df (pd.DataFrame): The input DataFrame., bins...</td>\n",
       "      <td>None</td>\n",
       "      <td>def plot_histograms(df, bins=30):\\n    \"\"\"\\n  ...</td>\n",
       "      <td>EDA.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plot_scatter_matrix</th>\n",
       "      <td>Plots scatter plots of each feature against th...</td>\n",
       "      <td>[df (pd.DataFrame): The input DataFrame., targ...</td>\n",
       "      <td>None</td>\n",
       "      <td>def plot_scatter_matrix(df, target_col='Target...</td>\n",
       "      <td>EDA.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculate_vif</th>\n",
       "      <td>Computes Variance Inflation Factor (VIF) for e...</td>\n",
       "      <td>[df (pd.DataFrame): DataFrame containing numer...</td>\n",
       "      <td></td>\n",
       "      <td>def calculate_vif(df):\\n    \"\"\"\\n    Computes ...</td>\n",
       "      <td>EDA.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyze_distribution</th>\n",
       "      <td>Analyzes skewness, kurtosis, and visualizes th...</td>\n",
       "      <td>[df (pd.DataFrame): The input DataFrame., ]</td>\n",
       "      <td></td>\n",
       "      <td>def analyze_distribution(df):\\n    \"\"\"\\n    An...</td>\n",
       "      <td>EDA.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    Description  \\\n",
       "BinaryColumnCreator                                    No description available   \n",
       "TextClean                                              No description available   \n",
       "FillFromAbove                 Purpose: Force Fill Information from above def...   \n",
       "ColumnStatisticalCompare                               No description available   \n",
       "CategorizeBinaryChange        Function to Simply Apply a Condition to genera...   \n",
       "ColumnElementalChange         Function to Compare the Element Level change o...   \n",
       "DFStructureReview             Function to Create a simplified view of the ov...   \n",
       "ColumnPartitioner             Function to create partions from Float or INT ...   \n",
       "ColumnStatisticalReview       Function to Conduct a Simple Statistical Revie...   \n",
       "generate_polynomial_features  Generates polynomial features for all numerica...   \n",
       "CreateMarkdown                Function to Create a Markdown file from Proces...   \n",
       "CreateMarkdownfromProcess     Function to call Process Map from Google sheet...   \n",
       "extract_function_details_ast  Extracts structured function details from a Py...   \n",
       "ReadPythonFiles               Function which reads a Folder, iterating throu...   \n",
       "ParamterMapping               Function to Google Mapping Sheet, which is use...   \n",
       "ReadDirectory                 Function which reads reads a directory and ret...   \n",
       "DuplicateFileorFolder         Function to copy a file or folder to another l...   \n",
       "plot_correlation_matrix       Generates and displays a correlation matrix he...   \n",
       "plot_histograms                Plots histograms for each column in a DataFrame.   \n",
       "plot_scatter_matrix           Plots scatter plots of each feature against th...   \n",
       "calculate_vif                 Computes Variance Inflation Factor (VIF) for e...   \n",
       "analyze_distribution          Analyzes skewness, kurtosis, and visualizes th...   \n",
       "\n",
       "                                                                      Arguments  \\\n",
       "BinaryColumnCreator           [df, column_name, new_column_name, value, calc...   \n",
       "TextClean                                         [df, column_list, clean_type]   \n",
       "FillFromAbove                                [df, column_name, new_column_name]   \n",
       "ColumnStatisticalCompare                                 [df, df1, column_name]   \n",
       "CategorizeBinaryChange         [change_column (str): Name of Column Created., ]   \n",
       "ColumnElementalChange                       [df, df1, column_name, primary_key]   \n",
       "DFStructureReview                   [primary_key(list): Primary Keys between, ]   \n",
       "ColumnPartitioner             [partitions:, Total Number of desired Partitio...   \n",
       "ColumnStatisticalReview       [column_name (str): Name of Column, , partitio...   \n",
       "generate_polynomial_features  [df (pd.DataFrame): The input DataFrame., targ...   \n",
       "CreateMarkdown                [Dataframe( Must be of format, Title, Header, ...   \n",
       "CreateMarkdownfromProcess     [process_name (str): Process Name as defined i...   \n",
       "extract_function_details_ast  [file_content (str): The raw string content of...   \n",
       "ReadPythonFiles                                      [location (str): Folder, ]   \n",
       "ParamterMapping               [Definition (Str): Key word used to Access ind...   \n",
       "ReadDirectory                 [folder (str): The path to the directory. Defa...   \n",
       "DuplicateFileorFolder         [source_path (str): Path to the file or folder...   \n",
       "plot_correlation_matrix               [df (pd.DataFrame): The input DataFrame.]   \n",
       "plot_histograms               [df (pd.DataFrame): The input DataFrame., bins...   \n",
       "plot_scatter_matrix           [df (pd.DataFrame): The input DataFrame., targ...   \n",
       "calculate_vif                 [df (pd.DataFrame): DataFrame containing numer...   \n",
       "analyze_distribution                [df (pd.DataFrame): The input DataFrame., ]   \n",
       "\n",
       "                             Return  \\\n",
       "BinaryColumnCreator            None   \n",
       "TextClean                      None   \n",
       "FillFromAbove                  None   \n",
       "ColumnStatisticalCompare       None   \n",
       "CategorizeBinaryChange                \n",
       "ColumnElementalChange                 \n",
       "DFStructureReview                     \n",
       "ColumnPartitioner              None   \n",
       "ColumnStatisticalReview        None   \n",
       "generate_polynomial_features          \n",
       "CreateMarkdown                        \n",
       "CreateMarkdownfromProcess             \n",
       "extract_function_details_ast          \n",
       "ReadPythonFiles                       \n",
       "ParamterMapping                       \n",
       "ReadDirectory                         \n",
       "DuplicateFileorFolder                 \n",
       "plot_correlation_matrix        None   \n",
       "plot_histograms                None   \n",
       "plot_scatter_matrix            None   \n",
       "calculate_vif                         \n",
       "analyze_distribution                  \n",
       "\n",
       "                                                                           Code  \\\n",
       "BinaryColumnCreator           def BinaryColumnCreator(df,\\n                 ...   \n",
       "TextClean                     def TextClean(df, \\n              column_list,...   \n",
       "FillFromAbove                 def FillFromAbove(df,\\n                 column...   \n",
       "ColumnStatisticalCompare      def ColumnStatisticalCompare(df,df1,column_nam...   \n",
       "CategorizeBinaryChange        def CategorizeBinaryChange(df,\\n              ...   \n",
       "ColumnElementalChange         def ColumnElementalChange(df,\\n               ...   \n",
       "DFStructureReview             def DFStructureReview(df,\\n                   ...   \n",
       "ColumnPartitioner             def ColumnPartitioner(df,\\n                   ...   \n",
       "ColumnStatisticalReview       def ColumnStatisticalReview(df,\\n             ...   \n",
       "generate_polynomial_features  def generate_polynomial_features(df, target_co...   \n",
       "CreateMarkdown                def CreateMarkdown(df,return_value=\"\"):\\n    \\...   \n",
       "CreateMarkdownfromProcess     def CreateMarkdownfromProcess(process_name,ret...   \n",
       "extract_function_details_ast  def extract_function_details_ast(file_content,...   \n",
       "ReadPythonFiles               def ReadPythonFiles(location='/Users/derekdewa...   \n",
       "ParamterMapping               def ParamterMapping(Definition=\"\"):\\n    \\n   ...   \n",
       "ReadDirectory                 def ReadDirectory(folder=\"\", file_type=\"\"):\\n ...   \n",
       "DuplicateFileorFolder         def DuplicateFileorFolder(source_path, destina...   \n",
       "plot_correlation_matrix       def plot_correlation_matrix(df):\\n    \"\"\"\\n   ...   \n",
       "plot_histograms               def plot_histograms(df, bins=30):\\n    \"\"\"\\n  ...   \n",
       "plot_scatter_matrix           def plot_scatter_matrix(df, target_col='Target...   \n",
       "calculate_vif                 def calculate_vif(df):\\n    \"\"\"\\n    Computes ...   \n",
       "analyze_distribution          def analyze_distribution(df):\\n    \"\"\"\\n    An...   \n",
       "\n",
       "                                               File  \n",
       "BinaryColumnCreator                 DF_Functions.py  \n",
       "TextClean                           DF_Functions.py  \n",
       "FillFromAbove                       DF_Functions.py  \n",
       "ColumnStatisticalCompare            DF_Functions.py  \n",
       "CategorizeBinaryChange              DF_Functions.py  \n",
       "ColumnElementalChange               DF_Functions.py  \n",
       "DFStructureReview                   DF_Functions.py  \n",
       "ColumnPartitioner                   DF_Functions.py  \n",
       "ColumnStatisticalReview             DF_Functions.py  \n",
       "generate_polynomial_features  FeatureEngineering.py  \n",
       "CreateMarkdown                      Organization.py  \n",
       "CreateMarkdownfromProcess           Organization.py  \n",
       "extract_function_details_ast        Organization.py  \n",
       "ReadPythonFiles                     Organization.py  \n",
       "ParamterMapping                      Connections.py  \n",
       "ReadDirectory                       SharedFolder.py  \n",
       "DuplicateFileorFolder               SharedFolder.py  \n",
       "plot_correlation_matrix                      EDA.py  \n",
       "plot_histograms                              EDA.py  \n",
       "plot_scatter_matrix                          EDA.py  \n",
       "calculate_vif                                EDA.py  \n",
       "analyze_distribution                         EDA.py  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from Organization import ReadPythonFiles\n",
    "ReadPythonFiles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c614ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SharedFolder import DuplicateFileorFolder\n",
    "# Create Backup of Github_Repo\n",
    "DuplicateFileorFolder('/Users/derekdewald/Documents/Python/Github_Repo/',\n",
    "                      '/Users/derekdewald/Documents/GitHub_Repo_BACKUP/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71228ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_heatmap(df,column_name='',corr_value=.1,figsize=(20,15)):\n",
    "    \n",
    "    sns.set(style='white')\n",
    "    \n",
    "    # View column with Abbreviated title or full. Abbreviated displays nicer.\n",
    "    corr = df.corr()\n",
    "    \n",
    "    if len(column_name)!=0:\n",
    "        corr = corr[[column_name]]\n",
    "        corr = corr[abs(corr[column_name])>corr_value]\n",
    "    \n",
    "    mask= np.zeros_like(corr,dtype=bool)\n",
    "    mask[np.triu_indices_from(mask)]=True\n",
    "    f,ax = plt.subplots(figsize=figsize)\n",
    "    cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
    "    sns.heatmap(corr,mask=mask,cmap=cmap,vmax=.3,center=0,square=True,linewidths=.5)\n",
    "    \n",
    "    plt.title('Heat Map of Correlation')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def create_column_inclusion_review(df,\n",
    "                               columns,\n",
    "                               column_type_df='',\n",
    "                               decile_review_df=''):\n",
    "    \n",
    "    df = df[columns].copy()\n",
    "    \n",
    "    temp_df = review_dataset_dict(df)\n",
    "    \n",
    "    if len(column_type_df)!=0:\n",
    "        temp_df = temp_df.merge(column_type_df,on='Financial Ratio',how='left')\n",
    "    if len(decile_review_df)!=0:\n",
    "        temp_df = temp_df.merge(decile_review_df,on='Financial Ratio',how='left')\n",
    "    \n",
    "    return temp_df\n",
    "\n",
    "\n",
    "def variable_review(df,\n",
    "                    column_name,\n",
    "                    og_column,\n",
    "                    column_inclusion_review_df,\n",
    "                    corr_weight=.15):\n",
    "        \n",
    "    print(column_inclusion_review_df[column_inclusion_review_df['Financial Ratio']==column_name].T)\n",
    "    print(f\"\\n\")\n",
    "    \n",
    "    create_heatmap(df[og_columns],column_name)\n",
    "    create_decile(df,column_name)\n",
    "    \n",
    "    print('Top 20 Records')\n",
    "    print(df.sort_values(column_name)[[column_name,'BANKRUPTCY_FLAG']].tail(20))\n",
    "    \n",
    "    print('Bottom 20 Records')\n",
    "    print(df.sort_values(column_name)[[column_name,'BANKRUPTCY_FLAG']].head(20))\n",
    "    \n",
    "    return df[df[column_name].isnull()].T\n",
    "\n",
    "# Process for reviewing Non Tier 1 Elements.\n",
    "\n",
    "def review_single_variable_manully(df,\n",
    "                                   column_name,\n",
    "                                   baseline_columns,\n",
    "                                   column_inclusion_review_df,\n",
    "                                   og_columns,\n",
    "                                   export_to_excel=0):\n",
    "        \n",
    "    import datetime\n",
    "    now = datetime.datetime.now()\n",
    "    \n",
    "    # Currently Included Columns for Simple Reference\n",
    "    print(\"Columns Currently In Scope:\")\n",
    "    for included in baseline_columns:\n",
    "        print(f\"{included}\\n\")\n",
    "    \n",
    "    # EDA\n",
    "    variable_review(df,column_name,og_columns,column_inclusion_review_df)    \n",
    "    print(f\"Number of Null Records with Bankrupcy Flag Yes: {df[df[column_name].isnull()]['BANKRUPTCY_FLAG'].sum()}\")\n",
    "    \n",
    "    # Review Questions\n",
    "    blank_or_remove = input('Remove Null Records/ Zero Null Records/ Exit Loop (remove/zero/exit)')\n",
    "    include_in_model = input('Subjective Belief as to whether variable should be included in model (include/exclude)')\n",
    "    negative_value = input('Remove, Zero or Leave Negative Values (remove/zero/ignore)')\n",
    "    decision_logic = input('Please Provide Comment on Decision for Archival Reference')\n",
    "        \n",
    "    record_df =  pd.DataFrame([blank_or_remove.lower(),include_in_model.lower(),negative_value.lower(),decision_logic.lower(),now],index=['Null Record Approach','Baseline V2 Model Inclusion',\"Negative Valuation\",'Archival Decisioning','Extract Time'],columns=[column_name]).T.reset_index().rename(columns={'index':'Financial Ratio'})\n",
    "    \n",
    "    if export_to_excel==1:\n",
    "        clean_column_name = clean_string(column_name,remove_chars=['+','-',\"(\",\")\",'/','*']).replace(\" \",\"_\")\n",
    "        record_df.to_excel(f\"manual_review/manual_review_{clean_column_name}_{now.strftime('%d%m%y%h%m%s')}.xlsx\",index=False)\n",
    "            \n",
    "    return record_df\n",
    "\n",
    "def read_files_in_folder(folder_location,file_type='*',import_df=0):\n",
    "    \n",
    "    files_ = os.listdir(folder_location)\n",
    "    \n",
    "    if file_type =='*':\n",
    "        files_desired = files_.copy()\n",
    "    else:\n",
    "        files_desired = [x for x in files_ if x.find('xlsx')>-1]\n",
    "        \n",
    "    if import_df ==1:\n",
    "        final_df = pd.DataFrame()\n",
    "        if file_type =='xlsx':\n",
    "            pd_read = pd.read_excel\n",
    "        elif file_type =='csv':\n",
    "            pd_read = pd.read_csv      \n",
    "        else:\n",
    "            print('Update Function')              \n",
    "        for file in files_desired:\n",
    "            final_df = pd.concat([final_df,pd_read(f\"{folder_location}/{file}\")])\n",
    "            \n",
    "        return final_df\n",
    "         \n",
    "    return files_desired\n",
    "\n",
    "\n",
    "\n",
    "def build_binary_classification_model(input_dim, \n",
    "                                      hidden_layer_sizes,\n",
    "                                      activation, \n",
    "                                      optimizer,\n",
    "                                      learning_rate,\n",
    "                                      metrics):\n",
    "\n",
    "    \"\"\"Build a binary classification model using Keras.\n",
    "\n",
    "      Args:\n",
    "        input_dim: Number of features in the input data.\n",
    "        hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "        activation: The activation function to use for the hidden layers.\n",
    "        optimizer: The optimizer\n",
    "        learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "      Returns:\n",
    "        model: A tf.keras model.\n",
    "    \"\"\"\n",
    "    # Instantiate Model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    # Add Input Layer\n",
    "    model.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "\n",
    "    # Add Hidden Layers\n",
    "    for nodes in hidden_layer_sizes:\n",
    "        model.add(layers.Dense(units=nodes, activation=activation))\n",
    "\n",
    "    # Add Output Layer\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Configure optimizer and compile the model\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(X,\n",
    "                y,\n",
    "                input_dim,\n",
    "                metrics,\n",
    "                hidden_layer_sizes,\n",
    "                activation, \n",
    "                optimizer,\n",
    "                learning_rate,\n",
    "                batch_size,\n",
    "                num_epochs,\n",
    "                validation_split,\n",
    "                verbose=0):\n",
    "                       \n",
    "\n",
    "    # Build the model.\n",
    "    model = build_binary_classification_model(input_dim=input_dim,\n",
    "                                              hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                              activation=activation, \n",
    "                                              optimizer=optimizer,\n",
    "                                              learning_rate=learning_rate,\n",
    "                                              metrics=metrics)\n",
    "    \n",
    "    print(model.summary())     \n",
    "                        \n",
    "    # Train the model.\n",
    "    history = model.fit(x=X,\n",
    "                        y=y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        validation_split=validation_split,\n",
    "                        verbose=verbose)\n",
    "\n",
    "    # Retrieve the training metrics (after each train epoch) and the final test\n",
    "    # accuracy.\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(train_accuracy, label='train_accuracy')\n",
    "    plt.plot(val_accuracy, label='validation accuracy')\n",
    "    plt.xticks(range(num_epochs))\n",
    "    plt.xlabel('Train epochs')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    return history,model\n",
    "\n",
    "def create_balanced_dataset(X,y,observations=0,column_name='BANKRUPTCY_FLAG'):\n",
    "    \n",
    "    '''\n",
    "    Function to take observations and labels, combine them together and then select a even numher of random examples\n",
    "    \n",
    "    X - X_Test or X_Training\n",
    "    y - y_test or y_training\n",
    "    observation - Number of records from both Binary On and Binary Off Column\n",
    "    column_name - Name of Binary Column to filter\n",
    "    \n",
    "    \n",
    "    Used Default Value for purposes of reducing typing in code and given function created for Project Exclusively.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # If length of observations is not defined, create a even 50/ 50 dataset\n",
    "    if observations == 0:\n",
    "        observations = y[column_name].sum()\n",
    "        \n",
    "    if observations>y[column_name].sum():\n",
    "        observations = y[column_name].sum()\n",
    "        \n",
    "    temp_df = pd.concat([X,y],axis=1).copy()\n",
    "    \n",
    "    df1 = temp_df[temp_df[column_name]==1].sample(observations).copy()\n",
    "    df2 = temp_df[temp_df[column_name]==0].sample(observations).copy()\n",
    "    \n",
    "    final_df = pd.concat([df1,df2])\n",
    "    final_df = final_df.sample(frac=1)\n",
    "    \n",
    "    X = final_df.drop(column_name,axis=1)\n",
    "    y = final_df[[column_name]]\n",
    "    \n",
    "    \n",
    "    def train_neural_network(X,\n",
    "                y,\n",
    "                input_dim,\n",
    "                metrics,\n",
    "                hidden_layer_sizes,\n",
    "                activation, \n",
    "                optimizer,\n",
    "                learning_rate,\n",
    "                batch_size,\n",
    "                num_epochs,\n",
    "                validation_split,\n",
    "                verbose=0):\n",
    "                       \n",
    "\n",
    "    # Build the model.\n",
    "    model = build_binary_classification_model(input_dim=input_dim,\n",
    "                                              hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                              activation=activation, \n",
    "                                              optimizer=optimizer,\n",
    "                                              learning_rate=learning_rate,\n",
    "                                              metrics=metrics)\n",
    "    \n",
    "    print(model.summary())     \n",
    "                        \n",
    "    # Train the model.\n",
    "    history = model.fit(x=X,\n",
    "                        y=y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        validation_split=validation_split,\n",
    "                        verbose=verbose)\n",
    "\n",
    "    # Retrieve the training metrics (after each train epoch) and the final test\n",
    "    # accuracy.\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(train_accuracy, label='train_accuracy')\n",
    "    plt.plot(val_accuracy, label='validation accuracy')\n",
    "    plt.xticks(range(num_epochs))\n",
    "    plt.xlabel('Train epochs')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    return history,model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def knn_model_creation(X_df,\n",
    "                       y_df,\n",
    "                       neighbors=3):    \n",
    "    model = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "    model.fit(X_df,y_df)    \n",
    "    return model\n",
    "\n",
    "def logistic_regression_creation(X_df,\n",
    "                                 y_df,\n",
    "                                 solver='liblinear'):\n",
    "    '''\n",
    "    ['liblinear','newton-cg','lbfgs','sag','saga']\n",
    "    \n",
    "    for i in [10,20,30]:\n",
    "        temp_df = (y_probabilities >= i/100).astype(int)\n",
    "        knn_df = pd.concat([knn_df,pd.DataFrame(temp_df,columns=[f'LR_{str(i)}p'])],axis=1)\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(X_df,y_df)\n",
    "    return model\n",
    "\n",
    "\n",
    "def random_forest_classifier(X_df,\n",
    "                             y_df):\n",
    "    '''\n",
    "    important_features_rf = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False).head(10)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_df,y_df)\n",
    "    return model\n",
    "\n",
    "def neural_network(X_df,\n",
    "                   y_df,\n",
    "                   input_dim, \n",
    "                   hidden_layer_sizes,\n",
    "                   activation,\n",
    "                   optimizer,\n",
    "                   learning_rate,\n",
    "                   metrics,\n",
    "                   verbose=0):\n",
    "\n",
    "    \"\"\"Build a binary classification model using Keras.\n",
    "\n",
    "      Args:\n",
    "        input_dim: Number of features in the input data.\n",
    "        hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "        activation: The activation function to use for the hidden layers.\n",
    "        optimizer: The optimizer\n",
    "        learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "      Returns:\n",
    "        model: A tf.keras model.\n",
    "    \"\"\"\n",
    "    # Instantiate Model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    # Add Input Layer\n",
    "    model.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "\n",
    "    # Add Hidden Layers\n",
    "    for nodes in hidden_layer_sizes:\n",
    "        model.add(layers.Dense(units=nodes, activation=activation))\n",
    "\n",
    "    # Add Output Layer\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Configure optimizer and compile the model\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "    return model\n",
    "34/22:\n",
    "    # Where am I going to take out the Validation Data.\n",
    "    # Where am I going to do the Standardization of Data?\n",
    "    # Where am I going to take out the testing data.\n",
    "\n",
    "\n",
    "\n",
    "    Takes a Dataframe, which includes Training Data (which includes Label), \n",
    "    \n",
    "\n",
    "    # Step 1 Scale Data\n",
    "if scaling_method.lower() == 'standard_scalar':\n",
    "    X = apply_standard_scaler(X_df,X_df.columns.values)\n",
    "elif scaling_method.lower()=='min_max':\n",
    "    X = apply_min_max_scaler(X_df,X_df.columns.values)\n",
    "\n",
    "    if bankrupcy_observations == 'entire_dataset':\n",
    "a        pass\n",
    "    elif bankrupcy_observations == 'all_bankrupcies':\n",
    "        X,y = create_balanced_dataset(X,y)\n",
    "    else:\n",
    "        X,y = create_balanced_dataset(X,y,bankrupcy_observations)\n",
    "34/23:\n",
    "def create_model(X_df,\n",
    "                 y_df,model,\n",
    "                 scaling_method = 'standard_scalar',\n",
    "                 learning_rate=.05,\n",
    "                 model_parameters={}):\n",
    "    '''\n",
    "    \n",
    "    Function to generate ML Model, based on model type as defined in Parameters.\n",
    "    Below values for illustration purposes, can utilize dictionary to update as desired.\n",
    "\n",
    "    if model is neural_network, \n",
    "    model_parameters = {'hidden_layer_sizes':[8,16,32,64],\n",
    "                                          'activation':'relu',\n",
    "                                          'optimizer':'adam',\n",
    "                                          'learning_rate':.05,\n",
    "                                          'metrics':['accuracy', keras.metrics.Precision(),keras.metrics.Recall()]}\n",
    "    if model Logistic Regression,\n",
    "    model_parameters = {'solver':'liblinear'}\n",
    "\n",
    "    if model knn,\n",
    "    model_parameters = {'n_neighbors':3}\n",
    "\n",
    "    if model random_forsest\n",
    "    model_parameters = {}\n",
    "\n",
    "    '''\n",
    "\n",
    "    if model == 'neural_network':\n",
    "        model = neural_network(X_df,\n",
    "                               y_df,\n",
    "                               input_dim=len(X.columns.values), \n",
    "                               hidden_layer_sizes= model_parameters['hidden_layer_sizes'],\n",
    "                               activation=model_parameters['activation'], \n",
    "                               optimizer=model_parameters['optimizer'],\n",
    "                               learning_rate=model_parameters['learning_rate'],\n",
    "                               metrics=model_parameters['metrics'])\n",
    "\n",
    "    elif model == 'logistic_regression':\n",
    "        model = logistic_regression_creation(X_df,\n",
    "                                             y_df,\n",
    "                                             solver=model_parameters['solver'])\n",
    "    elif model == 'random_forest':\n",
    "        model = random_forest_classifier(X_df,\n",
    "                                         y_df)\n",
    "    elif model == 'knn':\n",
    "        model = knn_model_creation(X_df,\n",
    "                                   y_df,\n",
    "                                   neighbors=model_parameters['n_neighbors'])\n",
    "    return model\n",
    "\n",
    "def generate_predicition(X_test_df,\n",
    "                         y_test_df,\n",
    "                         model,\n",
    "                         py_model,\n",
    "                         model_parameters):\n",
    "\n",
    "    if model == 'neural_network':\n",
    "        history = py_model.fit(x=X_test_df,\n",
    "                            y=y_test_df,\n",
    "                            batch_size=model_parameters['batch_size'],\n",
    "                            epochs=model_parameters['num_epochs'])\n",
    "\n",
    "        acc = pd.DataFrame(history.history['accuracy'],columns=[\"Training Accuracy\"])\n",
    "        loss = pd.DataFrame(history.history['loss'],columns=[\"Training Loss\"])\n",
    "        prec_str = columns=[x for x in history.history.keys() if x.find('pre')!=-1][0]\n",
    "        recall_str = columns=[x for x in history.history.keys() if x.find('reca')!=-1][0]\n",
    "        precision = pd.DataFrame(history.history[prec_str],columns=[prec_str]).rename(columns={prec_str:'Precision'})\n",
    "        recall = pd.DataFrame(history.history[recall_str],columns=[recall_str]).rename(columns={recall_str:'Recall'})\n",
    "\n",
    "        model_results_df = pd.concat([model_results_df,pd.DataFrame([x for x in range(0,len(model_results_df))],columns=['Epoch Number'])],axis=1)\n",
    "        model_results_df['Dataset'] = 'To Be Determined'\n",
    "        model_results_df['Model'] = model\n",
    "        model_results_df['activation'] = model_parameters['activation']\n",
    "        model_results_df['optimizer'] = model_parameters['optimizer']\n",
    "        model_results_df['learning_rate'] = model_parameters['learning_rate']\n",
    "        model_results_df['batch_size'] = model_parameters['batch_size']\n",
    "        model_results_df['epochs'] = model_parameters['num_epochs']\n",
    "        model_results_df['hidden_layer_sizes'] = text_manipulation(model_parameters['hidden_layer_sizes'])\n",
    "        #model_results_df['bankrupt_observations'] = bankrupcy_observations\n",
    "        #model_results_df['total_observations_read'] = len(X)\n",
    "        return model_results_df\n",
    "    \n",
    "    elif model == 'knn':\n",
    "        pred = py_model.predict(X_test_df)\n",
    "        pred_df = pd.DataFrame(pred,columns=['Predicitions'])\n",
    "        final_df = pd.concat([y_test_df.reset_index(drop=True),pred_df],axis=1)\n",
    "        return final_df\n",
    "    \n",
    "    else:\n",
    "        pred = py_model.predict(X_test_df,y_test_df)\n",
    "        pred_df = pd.DataFrame(pred,columns=['Predicitions'])\n",
    "        final_df = pd.concat([y_test_df.reset_index(drop=True),pred_df],axis=1)\n",
    "        return final_df\n",
    "    \n",
    "\n",
    "    # else:\n",
    "    #     predicition = py_model.predict(X_test)\n",
    "    #     temp_x = pd.DataFrame(predicition,columns=[column_name])\n",
    "    #     if df == \"\":\n",
    "    #         return pd.concat([y_test_df,temp_df],axis=1)\n",
    "    #     else:\n",
    "    #         return pd.concat([df,temp_df],axis=1)\n",
    "34/24:\n",
    "X = dataset_dictionary['All Ratios Cleaned']\n",
    "y = dataset_dictionary['labels']\n",
    "\n",
    "model='logistic_regression'\n",
    "model_parameters = {'solver':'liblinear'}\n",
    "\n",
    "lr_  = create_model(X,\n",
    "                      y,\n",
    "                      model=model,\n",
    "                      model_parameters=model_parameters)\n",
    "\n",
    "model = 'knn'\n",
    "model_parameters = {'n_neighbors':3}\n",
    "\n",
    "knn_ = create_model(X,\n",
    "                      y,\n",
    "                      model=model,\n",
    "                      model_parameters=model_parameters)\n",
    "34/25: knn_.predict(X)\n",
    "34/26: X\n",
    "34/27: X_train, X_test, y_train, y_test  = train_test_split(X,y,test_size=0.3, random_state=15)\n",
    "34/28:\n",
    "X = dataset_dictionary['All Ratios Cleaned']\n",
    "y = dataset_dictionary['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X,y,test_size=0.3, random_state=15)\n",
    "\n",
    "\n",
    "model='logistic_regression'\n",
    "model_parameters = {'solver':'liblinear'}\n",
    "\n",
    "lr_  = create_model(X_train,\n",
    "                      y_train,\n",
    "                      model=model,\n",
    "                      model_parameters=model_parameters)\n",
    "\n",
    "model = 'knn'\n",
    "model_parameters = {'n_neighbors':3}\n",
    "\n",
    "knn_ = create_model(X_train,\n",
    "                      y_train,\n",
    "                      model=model,\n",
    "                      model_parameters=model_parameters)\n",
    "34/29: lr_.n_iter_\n",
    "34/30:\n",
    "X = dataset_dictionary['All Ratios Cleaned']\n",
    "y = dataset_dictionary['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X,y,test_size=0.3, random_state=15)\n",
    "\n",
    "\n",
    "model='logistic_regression'\n",
    "model_parameters = {'solver':'lbfgs'}\n",
    "\n",
    "lr_  = create_model(X_train,\n",
    "                      y_train,\n",
    "                      model=model,\n",
    "                      model_parameters=model_parameters)\n",
    "\n",
    "model = 'knn'\n",
    "model_parameters = {'n_neighbors':3}\n",
    "\n",
    "knn_ = create_model(X_train,\n",
    "                      y_train,\n",
    "                      model=model,\n",
    "                      model_parameters=model_parameters)\n",
    "34/31:\n",
    "\n",
    "\n",
    "def knn_model_creation(X_df,\n",
    "                       y_df,\n",
    "                       neighbors=3):    \n",
    "    model = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "    model.fit(X_df,y_df)    \n",
    "    return model\n",
    "\n",
    "def logistic_regression_creation(X_df,\n",
    "                                 y_df,\n",
    "                                 max_iter=100,\n",
    "                                 solver='liblinear'):\n",
    "    '''\n",
    "    ['liblinear','newton-cg','lbfgs','sag','saga']\n",
    "    \n",
    "    for i in [10,20,30]:\n",
    "        temp_df = (y_probabilities >= i/100).astype(int)\n",
    "        knn_df = pd.concat([knn_df,pd.DataFrame(temp_df,columns=[f'LR_{str(i)}p'])],axis=1)\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    model = LogisticRegression(solver='liblinear',max_iter=max_iter)\n",
    "    model.fit(X_df,y_df)\n",
    "    return model\n",
    "\n",
    "\n",
    "def random_forest_classifier(X_df,\n",
    "                             y_df):\n",
    "    '''\n",
    "    important_features_rf = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False).head(10)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_df,y_df)\n",
    "    return model\n",
    "\n",
    "def neural_network(X_df,\n",
    "                   y_df,\n",
    "                   input_dim, \n",
    "                   hidden_layer_sizes,\n",
    "                   activation,\n",
    "                   optimizer,\n",
    "                   learning_rate,\n",
    "                   metrics,\n",
    "                   verbose=0):\n",
    "\n",
    "    \"\"\"Build a binary classification model using Keras.\n",
    "\n",
    "      Args:\n",
    "        input_dim: Number of features in the input data.\n",
    "        hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "        activation: The activation function to use for the hidden layers.\n",
    "        optimizer: The optimizer\n",
    "        learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "      Returns:\n",
    "        model: A tf.keras model.\n",
    "    \"\"\"\n",
    "    # Instantiate Model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    # Add Input Layer\n",
    "    model.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "\n",
    "    # Add Hidden Layers\n",
    "    for nodes in hidden_layer_sizes:\n",
    "        model.add(layers.Dense(units=nodes, activation=activation))\n",
    "\n",
    "    # Add Output Layer\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Configure optimizer and compile the model\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "    return model\n",
    "34/32:\n",
    "def create_model(X_df,\n",
    "                 y_df,model,\n",
    "                 scaling_method = 'standard_scalar',\n",
    "                 learning_rate=.05,\n",
    "                 model_parameters={}):\n",
    "    '''\n",
    "    \n",
    "    Function to generate ML Model, based on model type as defined in Parameters.\n",
    "    Below values for illustration purposes, can utilize dictionary to update as desired.\n",
    "\n",
    "    if model is neural_network, \n",
    "    model_parameters = {'hidden_layer_sizes':[8,16,32,64],\n",
    "                                          'activation':'relu',\n",
    "                                          'optimizer':'adam',\n",
    "                                          'learning_rate':.05,\n",
    "                                          'metrics':['accuracy', keras.metrics.Precision(),keras.metrics.Recall()]}\n",
    "    if model Logistic Regression,\n",
    "    model_parameters = {'solver':'liblinear','max_iter':200}\n",
    "\n",
    "    if model knn,\n",
    "    model_parameters = {'n_neighbors':3}\n",
    "\n",
    "    if model random_forsest\n",
    "    model_parameters = {}\n",
    "\n",
    "    '''\n",
    "\n",
    "    if model == 'neural_network':\n",
    "        model = neural_network(X_df,\n",
    "                               y_df,\n",
    "                               input_dim=len(X.columns.values), \n",
    "                               hidden_layer_sizes= model_parameters['hidden_layer_sizes'],\n",
    "                               activation=model_parameters['activation'], \n",
    "                               optimizer=model_parameters['optimizer'],\n",
    "                               learning_rate=model_parameters['learning_rate'],\n",
    "                               metrics=model_parameters['metrics'])\n",
    "\n",
    "    elif model == 'logistic_regression':\n",
    "        model = logistic_regression_creation(X_df,\n",
    "                                             y_df,\n",
    "                                             max_iter=model_parameters['max_iter'],\n",
    "                                             solver=model_parameters['solver'])\n",
    "    elif model == 'random_forest':\n",
    "        model = random_forest_classifier(X_df,\n",
    "                                         y_df)\n",
    "    elif model == 'knn':\n",
    "        model = knn_model_creation(X_df,\n",
    "                                   y_df,\n",
    "                                   neighbors=model_parameters['n_neighbors'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91ada0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2d02a-01fd-46ec-971b-e5000d3af2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RE has issue with Python escape clauses \\, utilize r to make it string literal\n",
    "r\"\\n\"\n",
    "\n",
    "* \\b: Word boundary ensures that we match whole words.\n",
    "* \\w+: Matches one or more word characters (letters, digits, or underscores).\n",
    "* \\b: Another word boundary to ensure the end of the word.\n",
    "* [^\\w\\s]: Matches any character that is not a word character (letters, digits, or underscores) or a whitespace character.\n",
    "* |: OR operator.\n",
    "* [\\d]: Matches any digit.\n",
    "* [^\\w\\s]: Matches any character that is not a word character (letters, digits, or underscores) or a whitespace character.\n",
    "* |: OR operator.\n",
    "* [\\d]: Matches any digit.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Linux\n",
    "Operating Systems are Layered.\n",
    "Kernel is the inter most layer\n",
    "Outermost layer is a GUI\n",
    "Linux can peel off layers, helps towards simplicity\n",
    "GUI can take  ~50% of processing power\n",
    "\n",
    "Linux Distributions\n",
    "GNU (GNU not Unix)\n",
    "- Red Hat (CentOS)\n",
    "- Fedora\n",
    "Debian\n",
    "- Ubuntu\n",
    "- Raspberry Pi\n",
    "- Various IoT\n",
    "- \n",
    "\n",
    "Resources: \n",
    "- Command Line Help: www.explainshell.com\n",
    "\n",
    "\n",
    "Linux Commands\n",
    "man - Manual\n",
    "History - history\n",
    "Clear - clears history\n",
    "Q - quits from current query\n",
    "pwd- current directory\n",
    "~ - short hand for home\n",
    ". Current Directory\n",
    ".. Parent Directory\n",
    "Ls -l adds 6 additional fields \n",
    "ls -lh - adds file sizes\n",
    "First letter - D: Directory, -: File, l - Link, Permission, Number of Hard links, Users who owns it. Size in bytes, date opened or last maintained  \n",
    "Ls -la - shows hidden files\n",
    "sudo = \"super user (root) do\"\n",
    "mkdir - makes new directory\n",
    "rmdir - removes directory\n",
    "rm -r temp_1_3 - recursively removes directories\n",
    "chmod 765 temp_1_1 - change permissions to directory\n",
    "\n",
    "\n",
    "* r = read = 2^2 = 4\n",
    "* w = write = 2^1 = 2\n",
    "* x = execute = 2^0 = 1\n",
    "* 1 = --x\n",
    "* 2 = -w-\n",
    "* 3 = -wx\n",
    "* 4 = r--\n",
    "* 5 = r-x\n",
    "* 6 = rw-\n",
    "* 7 = rwx\n",
    "\n",
    "* u = user\n",
    "* g = group\n",
    "* o = other (warning: NOT owner!)\n",
    "\n",
    "chmod u=rwx,g=rx,o=r *\n",
    "\n",
    "ls -lhR - recursively list out directory tree\n",
    "cp filename - copy\n",
    "rm filename - remove\n",
    "mv filename new_filename- rename\n",
    "\n",
    "head returns the first few lines of a file; optionally pass the number of lines to return\n",
    "tail returns the last few lines of a file; optionally pass the number of lines to return\n",
    "grep matches a pattern in a file and returns lines that match the pattern\n",
    "grep -v returns the opposite, the rows that do NOT match\n",
    "| is a pipeline; Linux spawn a process for each command; Linux creates an \"anonymous pipe\" aka \"un-named pipe\" between the processes; Linux routes standard output to pipes and routes standard input from pipes for intermediate commands\n",
    "diff finds the differences between two files\n",
    "* vi filename\n",
    "* Movement mode: arrow keys, page up, page down, 0 beginning of line, $ end of line, x delete character, dd delete line\n",
    "* Movement mode to insert mode: i for insert, a for append, note that INSERT appears lower left\n",
    "* Insert mode to movement mode: ESC key\n",
    "* Movement mode to command mode: : note that hitting the enter key will run the command and return to movement mode\n",
    "* Save changes: :w\n",
    "* Save a file and exit: :wq\n",
    "* Quit: :q\n",
    "* Quit with unsaved changes: :q!\n",
    "\n",
    "\n",
    "How to Change to Bash\n",
    "chsh -s /bin/bash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
