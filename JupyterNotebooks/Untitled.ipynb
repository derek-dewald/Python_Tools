{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d4c2fb-252a-4ab6-a429-ed22ef94e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d4f2a9f-08bf-4657-8972-e68c388b1d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_d_dicts import links\n",
    "\n",
    "list_ = ['Process','Categorization','Word','Definition']\n",
    "\n",
    "# Download Data\n",
    "definition_df = pd.read_csv(links['google_definition_csv'])\n",
    "notes_df = pd.read_csv(links['google_notes_csv'])\n",
    "\n",
    "definition_df = definition_df[list_].copy()\n",
    "notes_df = notes_df[list_].copy()\n",
    "\n",
    "# Step 1. Create a list of unique Processes from Notes.\n",
    "process_list = notes_df['Process'].unique().tolist()\n",
    "process_list.extend([x for x in definition_df['Process'].unique() if (x not in process_list)&(pd.notna(x))])\n",
    "process_map = {x:count+0 for count,x in enumerate(process_list)}\n",
    "\n",
    "# Step 2 Create a Unique Classification List\n",
    "categorization_list = [\n",
    "    'Definition','Guiding Principle','Consideration','Process Step','Procedure','Expected Outcomes','Parameter','Algorithm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2bc3f7be-dd57-4415-b74b-15600598cf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process</th>\n",
       "      <th>Categorization</th>\n",
       "      <th>Word</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML Definitions</td>\n",
       "      <td>Model Type</td>\n",
       "      <td>Types of ML</td>\n",
       "      <td>Within the machine learning paradigm, models a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML Model</td>\n",
       "      <td>Process</td>\n",
       "      <td>Definition</td>\n",
       "      <td>ML Models is a process designed to store recor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML Project</td>\n",
       "      <td>Process Step</td>\n",
       "      <td>Goals</td>\n",
       "      <td>It is imperative to have clear goals, specific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML Project</td>\n",
       "      <td>Process Step</td>\n",
       "      <td>Goals</td>\n",
       "      <td>Goals of a ML Project Differ from Goals of BI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML Project</td>\n",
       "      <td>Process Step</td>\n",
       "      <td>Problem Definition</td>\n",
       "      <td>Define, Quantify and Articulate Problem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Langchain</td>\n",
       "      <td>Process Step</td>\n",
       "      <td>TBD</td>\n",
       "      <td>Build a chain using the pipe operator `|` to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Langchain</td>\n",
       "      <td>Process Step</td>\n",
       "      <td>TBD</td>\n",
       "      <td>Invoke the chain with specific inputs to gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Tooling</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>Streamlit and Gradio are both Python framework...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Tooling</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>LangChain and LlamaIndex are complementary but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Tooling</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>LangChain does not have a single, all-encompas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Process Categorization                Word  \\\n",
       "0    ML Definitions     Model Type         Types of ML   \n",
       "1          ML Model        Process          Definition   \n",
       "2        ML Project   Process Step               Goals   \n",
       "3        ML Project   Process Step               Goals   \n",
       "4        ML Project   Process Step  Problem Definition   \n",
       "..              ...            ...                 ...   \n",
       "136       Langchain   Process Step                 TBD   \n",
       "137       Langchain   Process Step                 TBD   \n",
       "138         Tooling            TBD                 TBD   \n",
       "139         Tooling            TBD                 TBD   \n",
       "140         Tooling            TBD                 TBD   \n",
       "\n",
       "                                            Definition  \n",
       "0    Within the machine learning paradigm, models a...  \n",
       "1    ML Models is a process designed to store recor...  \n",
       "2    It is imperative to have clear goals, specific...  \n",
       "3    Goals of a ML Project Differ from Goals of BI ...  \n",
       "4             Define, Quantify and Articulate Problem.  \n",
       "..                                                 ...  \n",
       "136   Build a chain using the pipe operator `|` to ...  \n",
       "137  Invoke the chain with specific inputs to gener...  \n",
       "138  Streamlit and Gradio are both Python framework...  \n",
       "139  LangChain and LlamaIndex are complementary but...  \n",
       "140  LangChain does not have a single, all-encompas...  \n",
       "\n",
       "[141 rows x 4 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd5bd3-12a3-41d6-859e-758dd97dac0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6271678e-9bd9-4190-858a-18b2d63a8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def notes_word_equals_word_definition_categorization(df,notes_df):\n",
    "        df = df.copy()\n",
    "        # Create Definition where Definition Categorization Equals Word.\n",
    "        df['WORD_IS_ZATION'] = np.where(df['Categorization_DEF'].isin(notes_df['Word'].unique().tolist()),1,0)\n",
    "        \n",
    "        merge_ = df[df['WORD_IS_ZATION']==1].copy()\n",
    "        residual_values= df[df['WORD_IS_ZATION']!=1].copy()\n",
    "        \n",
    "        merge_ = merge_[['Categorization_DEF','Word','Definition_DEF']].copy()\n",
    "        merge_['Definition'] = merge_['Word'] + \": \" + merge_['Definition_DEF']\n",
    "        merge_ = merge_.drop(['Definition_DEF','Word'],axis=1).rename(columns={'Categorization_DEF':\"Word\"})\n",
    "        merge_['Categorization'] = 'Definition'\n",
    "    \n",
    "        merge_ = merge_.merge(notes_df.drop_duplicates('Word')[['Word','Process']],on='Word',how='left')\n",
    "\n",
    "        residual_values = residual_values[['Process_DEF','Categorization_DEF','Word','Definition_DEF']].rename(columns={'Process_DEF':'Process',\n",
    "                                                                                             'Categorization_DEF':'Categorization',\n",
    "                                                                                             'Definition_DEF':'Definition'})\n",
    "        return merge_,residual_values\n",
    "\n",
    "    def notes_word_equals_definition_process(examine_further,notes_df):\n",
    "        '''\n",
    "            \n",
    "        '''\n",
    "    \n",
    "        df = examine_further.copy()\n",
    "        notes_df = notes_df.copy()\n",
    "    \n",
    "        # Make List\n",
    "        notes_word_list = notes_df['Word'].unique().tolist()\n",
    "    \n",
    "        examine_further = df[~df['Process'].isin(notes_word_list)].copy()\n",
    "        insert_df = df[df['Process'].isin(notes_word_list)].copy()\n",
    "    \n",
    "        # Clean Up Insert DF so it meets Notes DF Structure, Not Definition DF Structure.\n",
    "        # Definition Updated to Include Word\n",
    "        # Word is Updated to Include Process.\n",
    "        # Categorization Does not Change\n",
    "        # Process Takes on Whatever Value in Notes is, as this is now a input into that Process.\n",
    "        \n",
    "        # Word is Updated to include Categorization (needs to happen After Definition is Change)\n",
    "        \n",
    "        insert_df['Definition'] = insert_df['Word'] + \": \" +  insert_df['Definition'] \n",
    "        insert_df['Word'] = insert_df['Process'].copy()\n",
    "        insert_df.drop(['Process'],axis=1,inplace=True)\n",
    "        insert_df = insert_df.merge(notes_df.drop_duplicates('Word')[['Word','Process']],on='Word',how='left')\n",
    "    \n",
    "        return examine_further,insert_df\n",
    "\n",
    "        \n",
    "    from data_d_dicts import links\n",
    "\n",
    "    try:\n",
    "        notes_df = notes.copy()\n",
    "    except:\n",
    "        notes_df = pd.read_csv(links['google_notes_csv'])\n",
    "        \n",
    "    try:\n",
    "        definition_df = definition_df.copy()\n",
    "        definition_df.rename(columns={'Process':'Process_DEF','Categorization':\"Categorization_DEF\",'Definition':\"Definition_DEF\"},inplace=True)\n",
    "    except:\n",
    "        definition_df = pd.read_csv(links['google_definition_csv']).rename(columns={'Process':'Process_DEF','Categorization':\"Categorization_DEF\",'Definition':\"Definition_DEF\"})\n",
    "        definition_df.sort_values(['Process_DEF','Categorization_DEF','Word'],inplace=True)\n",
    "        \n",
    "    # Step 1: Merge Definitions into Words where they explicitly Match. No logic required.\n",
    "    # Identify Where there is a Record. \n",
    "        # Example 1: ML Project >> Process Step >> Problem Definition\n",
    "            # This is a Definition to a process which has Steps. Need to Merge a NEW RECORD.\n",
    "        # Example 2: Best Linear Unbiased Estimator\n",
    "            # This is a Example which needs Definitions Merged in, some of which arent direct Definitions. \n",
    "    \n",
    "    # We will create a modified Definition DF. To identify where direct matches exist.\n",
    "    # Need to distribute information from temp_def until Empty. Need Data Quality View Steps.\n",
    "\n",
    "    temp_def = definition_df[['Process_DEF','Categorization_DEF','Word','Definition_DEF']].merge(notes_df[['Process','Categorization','Word','Definition']].drop_duplicates('Word'),on='Word',how='left',indicator=True)\n",
    "    merge = temp_def[temp_def['_merge']=='both'].drop('_merge',axis=1)\n",
    "    examine_further = temp_def[temp_def['_merge']!='both'].drop('_merge',axis=1)\n",
    "    # Naming for trouble shooting\n",
    "\n",
    "    # Two Types of Merge\n",
    "    # Inserting New Records, specifically Where the existing Note has a Definition, this means there is an existing Process. So this\n",
    "    # Value Represents a Definition, and there is a New Record Insert\n",
    "\n",
    "    # Merging Definition. WHere the existing note has No Definition, then we will incorporate a definition. This technically could be \n",
    "    # Ignored, but by doing this, I can indirectly influence Order without direct assignment by assuming the Notes Order is Reference Point.\n",
    "\n",
    "    # Insert Record\n",
    "    insert_records = merge[merge['Definition'].notnull()].drop(['Process_DEF','Categorization_DEF','Definition','Categorization'],axis=1).rename(columns={'Definition_DEF':\"Definition\"})\n",
    "    insert_records['Categorization'] = 'Definition'\n",
    "    insert_records['Source'] = 'Insert Records'\n",
    "    \n",
    "    merge_records  = merge[merge['Definition'].isnull()]\n",
    "    \n",
    "    # WAIT TO MERGE UNTIL END IF POSSIBLE. THAT WAY I ONLY NEED TO RANK ONCE.\n",
    "    \n",
    "    notes_df =  notes_df.merge(merge_records[['Word','Definition_DEF']],on='Word',how='left')\n",
    "    notes_df['Definition'] = notes_df['Definition'].fillna(notes_df['Definition_DEF'])\n",
    "    notes_df.drop('Definition_DEF',axis=1,inplace=True)\n",
    "    notes_df['Source'] = 'Notes DF'\n",
    "    #### Step 2: \n",
    "\n",
    "    # Insert Instances where Word In Notes is Equal to Categorization in Definition. \n",
    "    # When a Process as Steps which are defined and need to be included, but Also Represent a Definition unto themselves.\n",
    "    # Example Bias, Bias Variance Trade Off, they are STEPS to in the Feature Selection Process, but also key terms which \n",
    "    # Deserve their own definition and explanation.\n",
    "\n",
    "    insert_records2, examine_further = notes_word_equals_word_definition_categorization(examine_further,notes_df)\n",
    "    insert_records2['Source'] = 'Insert Records2'\n",
    "    # Start To Bring Ordering to the Data Set.\n",
    "\n",
    "    c1_df = notes_df[['Process']].drop_duplicates().reset_index(drop=True).assign(C1_ORDER=lambda df: df.index+1)\n",
    "    c12_df = notes_df[['Process','Categorization']].drop_duplicates().reset_index(drop=True).assign(C12_ORDER=lambda df: df.index+1)\n",
    "    c3_df = notes_df[['Word']].drop_duplicates().reset_index(drop=True).assign(C3_ORDER=lambda df: df.index+1)\n",
    "\n",
    "    examine_further,insert_records3 = notes_word_equals_definition_process(examine_further,notes_df)\n",
    "    insert_records3['Source'] = 'Insert Records3'\n",
    "    examine_further['Source'] = 'Examine Further'\n",
    "    \n",
    "    # Determine Order for Sorting.\n",
    "    notes_df = notes_df.merge(c1_df,on='Process',how='left')\n",
    "    notes_df = notes_df.merge(c3_df,on=['Word'],how='left')\n",
    "\n",
    "    insert_records = pd.concat([\n",
    "        insert_records,\n",
    "        insert_records2,\n",
    "        insert_records3,\n",
    "        examine_further\n",
    "    ])\n",
    "\n",
    "    # Determine COL1 and COL3 Sort Order\n",
    "    insert_records = insert_records.merge(c1_df,on='Process',how='left')\n",
    "    insert_records = insert_records.merge(c3_df,on='Word',how='left')\n",
    "\n",
    "    # Combine ALl DF\n",
    "    notes_df = pd.concat([\n",
    "        notes_df,\n",
    "        insert_records\n",
    "    ])\n",
    "\n",
    "    # Want to have a definitive Order for Classification, however as it's an evolving process, not interested in hardcoding everything. Have list to Hard Code specific desired columns, \n",
    "    # then use default order for residual, with option to update freely.\n",
    "\n",
    "    d_notes_categorization_order = ['Definition',\n",
    "                                    'Guiding Principle',\n",
    "                                    'Consideration',\n",
    "                                    'Process Step',\n",
    "                                    'Procedure',\n",
    "                                    'Expected Outcomes',\n",
    "                                    'Parameter',\n",
    "                                    'Algorithm',                                \n",
    "                                    ]\n",
    "    \n",
    "    residual_list = [x for x in notes_df['Categorization'].unique() if (x not in d_notes_categorization_order) & (pd.notna(x))]\n",
    "    d_notes_categorization_order.extend(residual_list)\n",
    "\n",
    "    # Determine COL2 Sort Order, which is based on Mapping and Can be done once when consolidated.\n",
    "    col2_order_dict = {d_notes_categorization_order[x]:x+1 for x in range(len(d_notes_categorization_order))}\n",
    "    notes_df['C2_ORDER'] = notes_df['Categorization'].map(col2_order_dict)\n",
    "    notes_df['C2_ORDER'] = notes_df['C2_ORDER'].fillna(1000)   \n",
    "\n",
    "    notes_df =  notes_df.sort_values(['C1_ORDER','C3_ORDER','C2_ORDER'])\n",
    "\n",
    "    # Need to insure that every record \n",
    "    \n",
    "    #return notes_df,insert_records,insert_records2,insert_records3,examine_further\n",
    "  \n",
    "    notes_df = notes_df.drop(['C1_ORDER','C3_ORDER','C2_ORDER'],axis=1)\n",
    "\n",
    "    if export_location:\n",
    "        notes_df.to_csv(export_location,index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
