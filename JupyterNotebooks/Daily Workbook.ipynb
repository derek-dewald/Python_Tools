{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b24421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys\n",
    "sys.path.append(\"/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a1e15c-7c97-4cb4-81e2-3ceca7310b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/derekdewald/Documents/Python/Github_Repo/JupyterNotebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93c807-0e46-448b-8f69-68e83638c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449ab250-cd3b-4036-8b20-26a1a9e39517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Returns</th>\n",
       "      <th>Date created</th>\n",
       "      <th>Date last modified</th>\n",
       "      <th>Code</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IterateThroughListuntilText</td>\n",
       "      <td>Function which Iterates through a list of pyth...</td>\n",
       "      <td>lines (list of str): Input lines</td>\n",
       "      <td>str: Concatenated result up to (but not includ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>def IterateThroughListuntilText(list_,text):\\n...</td>\n",
       "      <td>TextFunctions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>extract_doc_sections_all</td>\n",
       "      <td>Function which iterates through text, looking ...</td>\n",
       "      <td>estimator_class: A scikit-learn class (e.g., L...</td>\n",
       "      <td>pd.DataFrame with columns: ['Section', 'Name',...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>def extract_doc_sections_all(estimator_class, ...</td>\n",
       "      <td>TextFunctions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CountWordsinDFColumn</td>\n",
       "      <td>Function which reads a Dataframe Column and re...</td>\n",
       "      <td>df (dataframe) column_name (str): Name of Colu...</td>\n",
       "      <td>df</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>def CountWordsinDFColumn(df,\\n                ...</td>\n",
       "      <td>TextFunctions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RemovePatternFromDFColumn</td>\n",
       "      <td>Removes text matching a regex pattern from a D...</td>\n",
       "      <td></td>\n",
       "      <td>pd.DataFrame: Modified DataFrame with cleaned ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>def RemovePatternFromDFColumn(df,\\n           ...</td>\n",
       "      <td>TextFunctions.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RemoveWordfromDFColumn</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>def RemoveWordfromDFColumn(df,\\n              ...</td>\n",
       "      <td>TextFunctions.py</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Function Name  \\\n",
       "0  IterateThroughListuntilText   \n",
       "1     extract_doc_sections_all   \n",
       "2         CountWordsinDFColumn   \n",
       "3    RemovePatternFromDFColumn   \n",
       "4       RemoveWordfromDFColumn   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Function which Iterates through a list of pyth...   \n",
       "1  Function which iterates through text, looking ...   \n",
       "2  Function which reads a Dataframe Column and re...   \n",
       "3  Removes text matching a regex pattern from a D...   \n",
       "4                                                      \n",
       "\n",
       "                                          Parameters  \\\n",
       "0                   lines (list of str): Input lines   \n",
       "1  estimator_class: A scikit-learn class (e.g., L...   \n",
       "2  df (dataframe) column_name (str): Name of Colu...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                             Returns Date created  \\\n",
       "0  str: Concatenated result up to (but not includ...                \n",
       "1  pd.DataFrame with columns: ['Section', 'Name',...                \n",
       "2                                                 df                \n",
       "3  pd.DataFrame: Modified DataFrame with cleaned ...                \n",
       "4                                                                   \n",
       "\n",
       "  Date last modified                                               Code  \\\n",
       "0                     def IterateThroughListuntilText(list_,text):\\n...   \n",
       "1                     def extract_doc_sections_all(estimator_class, ...   \n",
       "2                     def CountWordsinDFColumn(df,\\n                ...   \n",
       "3                     def RemovePatternFromDFColumn(df,\\n           ...   \n",
       "4                     def RemoveWordfromDFColumn(df,\\n              ...   \n",
       "\n",
       "               File  \n",
       "0  TextFunctions.py  \n",
       "1  TextFunctions.py  \n",
       "2  TextFunctions.py  \n",
       "3  TextFunctions.py  \n",
       "4  TextFunctions.py  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SharedFolder import ExtractPythonFiles\n",
    "\n",
    "d = ExtractPythonFiles(export_file=f\"D_Python_Functions_{datetime.datetime.now().strftime('%d-%b-%y')}\")\n",
    "d.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c31a41-26e7-408c-8c9b-116b9786fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "df = extract_function_details_ast(\"your_script.py\")  # Replace with your actual .py file path\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f230215c-faa9-4059-9715-69cc7031376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FeatureEngineering import CreateRandomDFColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56430852-ec74-48bd-bc35-f494307abc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSets import GenerateFakeMemberDF\n",
    "\n",
    "\n",
    "df = GenerateFakeMemberDF(10000,12)\n",
    "CreateRandomDFColumn(df,['Fenway','Yankee Stadium','Wrigly'],'Stadium')\n",
    "CreateRandomDFColumn(df,['John','Mark','Harry','Sally'],'Vendor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db4719f9-2a04-4e27-80cd-65458282f0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEMBERNBR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>OUTLOOK</th>\n",
       "      <th>DEPOSIT</th>\n",
       "      <th>LENDING</th>\n",
       "      <th>TXN_COUNT</th>\n",
       "      <th>TXN_VALUE</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>Stadium</th>\n",
       "      <th>Vendor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-1</td>\n",
       "      <td>870359</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>263872</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-1</td>\n",
       "      <td>434229</td>\n",
       "      <td>735217</td>\n",
       "      <td>56</td>\n",
       "      <td>271880</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>373</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>0</td>\n",
       "      <td>953019</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>13578</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>437</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-2</td>\n",
       "      <td>141959</td>\n",
       "      <td>335109</td>\n",
       "      <td>61</td>\n",
       "      <td>392169</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>0</td>\n",
       "      <td>464055</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>15631</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179590</th>\n",
       "      <td>16409</td>\n",
       "      <td>12</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-1</td>\n",
       "      <td>334316</td>\n",
       "      <td>651183</td>\n",
       "      <td>46</td>\n",
       "      <td>415200</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179632</th>\n",
       "      <td>16451</td>\n",
       "      <td>12</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-1</td>\n",
       "      <td>376163</td>\n",
       "      <td>345523</td>\n",
       "      <td>47</td>\n",
       "      <td>471080</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179677</th>\n",
       "      <td>16496</td>\n",
       "      <td>12</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-2</td>\n",
       "      <td>630080</td>\n",
       "      <td>233877</td>\n",
       "      <td>74</td>\n",
       "      <td>527605</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180073</th>\n",
       "      <td>16892</td>\n",
       "      <td>12</td>\n",
       "      <td>Baller</td>\n",
       "      <td>0</td>\n",
       "      <td>122217</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>77740</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180146</th>\n",
       "      <td>16965</td>\n",
       "      <td>12</td>\n",
       "      <td>Baller</td>\n",
       "      <td>0</td>\n",
       "      <td>498559</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>330336</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MEMBERNBR  MONTH CLASSIFICATION  OUTLOOK  DEPOSIT  LENDING  TXN_COUNT  \\\n",
       "5               5      0         Baller       -1   870359        0         28   \n",
       "105           105      0         Baller       -1   434229   735217         56   \n",
       "373           373      0         Baller        0   953019        0         73   \n",
       "437           437      0         Baller       -2   141959   335109         61   \n",
       "499           499      0         Baller        0   464055        0         77   \n",
       "...           ...    ...            ...      ...      ...      ...        ...   \n",
       "179590      16409     12         Baller       -1   334316   651183         46   \n",
       "179632      16451     12         Baller       -1   376163   345523         47   \n",
       "179677      16496     12         Baller       -2   630080   233877         74   \n",
       "180073      16892     12         Baller        0   122217        0         52   \n",
       "180146      16965     12         Baller        0   498559        0         93   \n",
       "\n",
       "        TXN_VALUE  ACTIVE Stadium Vendor  \n",
       "5          263872       1  Fenway  Harry  \n",
       "105        271880       1  Fenway  Harry  \n",
       "373         13578       1  Fenway  Harry  \n",
       "437        392169       1  Fenway  Harry  \n",
       "499         15631       1  Fenway  Harry  \n",
       "...           ...     ...     ...    ...  \n",
       "179590     415200       1  Fenway  Harry  \n",
       "179632     471080       1  Fenway  Harry  \n",
       "179677     527605       1  Fenway  Harry  \n",
       "180073      77740       1  Fenway  Harry  \n",
       "180146     330336       1  Fenway  Harry  \n",
       "\n",
       "[1744 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TEST(df,index_,func):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    gb = df.groupby(index_)\n",
    "    gb_list = list(gb.groups.keys())\n",
    "\n",
    "    for combo in gb_list:\n",
    "        temp_df = gb.get_group(combo)\n",
    "        return temp_df\n",
    "\n",
    "TEST(df,columns,None)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4b7737f-5b42-471b-a328-33b1a3730b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['CLASSIFICATION','Stadium','Vendor']\n",
    "\n",
    "gb = df.groupby(columns)\n",
    "gb_list = list(gb.groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fad81cd-071f-4b9b-87ed-639504bdfa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEMBERNBR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>OUTLOOK</th>\n",
       "      <th>DEPOSIT</th>\n",
       "      <th>LENDING</th>\n",
       "      <th>TXN_COUNT</th>\n",
       "      <th>TXN_VALUE</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>Stadium</th>\n",
       "      <th>Vendor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-1</td>\n",
       "      <td>870359</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>263872</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-1</td>\n",
       "      <td>434229</td>\n",
       "      <td>735217</td>\n",
       "      <td>56</td>\n",
       "      <td>271880</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>373</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>0</td>\n",
       "      <td>953019</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>13578</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>437</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-2</td>\n",
       "      <td>141959</td>\n",
       "      <td>335109</td>\n",
       "      <td>61</td>\n",
       "      <td>392169</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>0</td>\n",
       "      <td>464055</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>15631</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179590</th>\n",
       "      <td>16409</td>\n",
       "      <td>12</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-1</td>\n",
       "      <td>334316</td>\n",
       "      <td>651183</td>\n",
       "      <td>46</td>\n",
       "      <td>415200</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179632</th>\n",
       "      <td>16451</td>\n",
       "      <td>12</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-1</td>\n",
       "      <td>376163</td>\n",
       "      <td>345523</td>\n",
       "      <td>47</td>\n",
       "      <td>471080</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179677</th>\n",
       "      <td>16496</td>\n",
       "      <td>12</td>\n",
       "      <td>Baller</td>\n",
       "      <td>-2</td>\n",
       "      <td>630080</td>\n",
       "      <td>233877</td>\n",
       "      <td>74</td>\n",
       "      <td>527605</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180073</th>\n",
       "      <td>16892</td>\n",
       "      <td>12</td>\n",
       "      <td>Baller</td>\n",
       "      <td>0</td>\n",
       "      <td>122217</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>77740</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180146</th>\n",
       "      <td>16965</td>\n",
       "      <td>12</td>\n",
       "      <td>Baller</td>\n",
       "      <td>0</td>\n",
       "      <td>498559</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>330336</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MEMBERNBR  MONTH CLASSIFICATION  OUTLOOK  DEPOSIT  LENDING  TXN_COUNT  \\\n",
       "5               5      0         Baller       -1   870359        0         28   \n",
       "105           105      0         Baller       -1   434229   735217         56   \n",
       "373           373      0         Baller        0   953019        0         73   \n",
       "437           437      0         Baller       -2   141959   335109         61   \n",
       "499           499      0         Baller        0   464055        0         77   \n",
       "...           ...    ...            ...      ...      ...      ...        ...   \n",
       "179590      16409     12         Baller       -1   334316   651183         46   \n",
       "179632      16451     12         Baller       -1   376163   345523         47   \n",
       "179677      16496     12         Baller       -2   630080   233877         74   \n",
       "180073      16892     12         Baller        0   122217        0         52   \n",
       "180146      16965     12         Baller        0   498559        0         93   \n",
       "\n",
       "        TXN_VALUE  ACTIVE Stadium Vendor  \n",
       "5          263872       1  Fenway  Harry  \n",
       "105        271880       1  Fenway  Harry  \n",
       "373         13578       1  Fenway  Harry  \n",
       "437        392169       1  Fenway  Harry  \n",
       "499         15631       1  Fenway  Harry  \n",
       "...           ...     ...     ...    ...  \n",
       "179590     415200       1  Fenway  Harry  \n",
       "179632     471080       1  Fenway  Harry  \n",
       "179677     527605       1  Fenway  Harry  \n",
       "180073      77740       1  Fenway  Harry  \n",
       "180146     330336       1  Fenway  Harry  \n",
       "\n",
       "[1744 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.get_group(gb_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b8ce5-21db-4836-91a9-363318a170e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf48e7e-4583-435b-9fb5-8646c98cbd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952b189-a840-4300-bc65-389d83c6be2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "513301d2-4fb3-4997-867f-6f0bdf341e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--- \\n+++ \\n@@ -1,78 +1,81 @@\\n-def ColumnStatisticalReview(df,\\n+def ColumnStatisticalReview1(df,\\n                             column_name,\\n                             partitions=10,\\n                             top_x_records=10,\\n                             exclude_blanks_from_segments=1,\\n                             exclude_zeroes_from_segments=1):\\n-    \\n+\\n     \\'\\'\\'\\n     Function to Conduct a Simple Statistical Review of a Column, Including Understanding the positional distribution\\n     of values. \\n-    \\n+\\n     Args:\\n         column_name (str): Name of Column\\n-        \\n+\\n         partitions (int): Number of partitions to include (Decile 10)\\n-        \\n+\\n         exclude_blanks_from_segments (int): Binary Flag, whether to exclude Blank Values from Segment determination.\\n         If blank values are excluded it gives a better representation for the members of the set, however it might \\n         provide a misleading representation of the population.\\n-        \\n+\\n         exclude_zeroes_from_segments (int): As above, with respect to 0 values. Is processed after exclude_blanks, as\\n         such it can include both blanks and true 0 values. \\n-        \\n-        \\n+\\n+\\n     \\'\\'\\'\\n-    \\n+\\n     temp_dict = {}\\n     \\n-    try:\\n+    is_numeric = pd.api.types.is_numeric_dtype(df[column_name])\\n+    \\n+    if is_numeric:\\n         temp_dict[\\'SUM\\'] = df[column_name].sum()\\n         temp_dict[\\'MEAN\\'] = df[column_name].mean()\\n         temp_dict[\\'STD_DEV\\'] =  df[column_name].std()\\n         temp_dict[\\'MEDIAN\\'] = df[column_name].median()\\n         temp_dict[\\'MAX\\'] = df[column_name].max()\\n         temp_dict[\\'MIN\\'] = df[column_name].min()\\n-    \\n-    except:\\n-        pass\\n-\\n+        \\n     temp_dict[\\'TOTAL_RECORDS\\'] = len(df)\\n     temp_dict[\\'UNIQUE_RECORDS\\'] = len(df.drop_duplicates(column_name))\\n-    temp_dict[\\'ZERO_RECORDS\\'] = len(df[df[column_name]==0])\\n-    temp_dict[\\'NON_ZERO_RECORDS\\'] = len(df[df[column_name]!=0])\\n     temp_dict[\\'NA_RECORDS\\'] = len(df[df[column_name].isna()])\\n     temp_dict[\\'NULL_RECORDS\\'] = len(df[df[column_name].isnull()])\\n-                             \\n+    \\n+    if is_numeric:\\n+        temp_dict[\\'ZERO_RECORDS\\'] = len(df[df[column_name]==0])\\n+        temp_dict[\\'NON_ZERO_RECORDS\\'] = len(df[df[column_name]!=0])    \\n+\\n     temp_df = pd.DataFrame(temp_dict.values(),index=temp_dict.keys(),columns=[column_name])\\n     \\n-    # Add top X records Based on Frequency\\n-    if top_x_records>0:\\n-        top_instances = pd.DataFrame(df[column_name].value_counts().head(top_x_records)).reset_index()\\n-        top_instances[column_name] = top_instances.apply(lambda row: f\"Value: {row[column_name]}, Frequency: {row[\\'count\\']}\", axis=1)\\n-        top_instances[\\'index\\'] = [f\"Top {x+1}\" for x in range(len(top_instances[column_name]))]\\n-        top_instances = top_instances.drop(\\'count\\',axis=1).set_index(\\'index\\')\\n-\\n-        temp_df = pd.concat([temp_df,top_instances])\\n+    if temp_dict[\\'TOTAL_RECORDS\\']==len(df[df[column_name].isnull()]):\\n+        return temp_df\\n     \\n     try:\\n-        temp_dict[\\'SUM\\']\\n-        segment_df = ColumnPartitioner(df=df,\\n-                                       column_name=column_name,\\n-                                       partitions=partitions,\\n-                                       exclude_blanks=exclude_blanks_from_segments,\\n-                                       exclude_zeros=exclude_zeroes_from_segments,\\n-                                       return_value=\\'\\')\\n-        \\n-        seg_val_df = ColumnPartitioner(df=df,\\n+\\n+        # Add top X records Based on Frequency\\n+        if top_x_records>0:\\n+            top_instances = pd.DataFrame(df[column_name].value_counts(dropna=False).head(top_x_records)).reset_index().rename(columns={column_name:\\'count\\',\\'index\\':column_name})\\n+            if len(top_instances)>0:\\n+                top_instances[column_name] = top_instances.apply(lambda row: f\"Value: {row[column_name]}, Frequency: {row[\\'count\\']}\", axis=1)\\n+                top_instances[\\'index\\'] = [f\"Top {x+1}\" for x in range(len(top_instances[column_name]))]\\n+                top_instances = top_instances.drop(\\'count\\',axis=1).set_index(\\'index\\')\\n+                temp_df = pd.concat([temp_df,top_instances])\\n+\\n+        if (partitions>0)&(pd.api.types.is_numeric_dtype(df[column_name]))&(temp_dict[\\'UNIQUE_RECORDS\\']>1):\\n+            segment_df = ColumnPartitioner(df=df,\\n                                            column_name=column_name,\\n                                            partitions=partitions,\\n                                            exclude_blanks=exclude_blanks_from_segments,\\n                                            exclude_zeros=exclude_zeroes_from_segments,\\n-                                           return_value=\\'agg_value\\').rename(columns={\\'VALUE\\':column_name})\\n+                                           return_value=\\'\\')\\n+            seg_val_df = ColumnPartitioner(df=df,\\n+                                               column_name=column_name,\\n+                                               partitions=partitions,\\n+                                               exclude_blanks=exclude_blanks_from_segments,\\n+                                               exclude_zeros=exclude_zeroes_from_segments,\\n+                                               return_value=\\'agg_value\\').rename(columns={\\'VALUE\\':column_name})\\n+            return pd.concat([temp_df,segment_df.T,seg_val_df])\\n+    except:\\n+        pass\\n             \\n-        return pd.concat([temp_df,segment_df.T,seg_val_df])\\n-\\n-    \\n-    except:\\n-        return temp_df\\n+    return temp_df'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "import difflib\n",
    "\n",
    "def compare_functions(func1, func2):\n",
    "    f1_lines = inspect.getsource(func1).splitlines()\n",
    "    f2_lines = inspect.getsource(func2).splitlines()\n",
    "    diff = difflib.unified_diff(f1_lines, f2_lines, lineterm='')\n",
    "    return '\\n'.join(diff)\n",
    "\n",
    "\n",
    "\n",
    "compare_functions(ColumnStatisticalReview,ColumnStatisticalReview1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53857d77-3860-4ef1-8115-14e7d18a5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColumnStatisticalReview(df,\n",
    "                            column_name,\n",
    "                            partitions=10,\n",
    "                            top_x_records=10,\n",
    "                            exclude_blanks_from_segments=1,\n",
    "                            exclude_zeroes_from_segments=1):\n",
    "    \n",
    "    '''\n",
    "    Function to Conduct a Simple Statistical Review of a Column, Including Understanding the positional distribution\n",
    "    of values. \n",
    "    \n",
    "    Args:\n",
    "        column_name (str): Name of Column\n",
    "        \n",
    "        partitions (int): Number of partitions to include (Decile 10)\n",
    "        \n",
    "        exclude_blanks_from_segments (int): Binary Flag, whether to exclude Blank Values from Segment determination.\n",
    "        If blank values are excluded it gives a better representation for the members of the set, however it might \n",
    "        provide a misleading representation of the population.\n",
    "        \n",
    "        exclude_zeroes_from_segments (int): As above, with respect to 0 values. Is processed after exclude_blanks, as\n",
    "        such it can include both blanks and true 0 values. \n",
    "        \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    temp_dict = {}\n",
    "    \n",
    "    try:\n",
    "        temp_dict['SUM'] = df[column_name].sum()\n",
    "        temp_dict['MEAN'] = df[column_name].mean()\n",
    "        temp_dict['STD_DEV'] =  df[column_name].std()\n",
    "        temp_dict['MEDIAN'] = df[column_name].median()\n",
    "        temp_dict['MAX'] = df[column_name].max()\n",
    "        temp_dict['MIN'] = df[column_name].min()\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    temp_dict['TOTAL_RECORDS'] = len(df)\n",
    "    temp_dict['UNIQUE_RECORDS'] = len(df.drop_duplicates(column_name))\n",
    "    temp_dict['ZERO_RECORDS'] = len(df[df[column_name]==0])\n",
    "    temp_dict['NON_ZERO_RECORDS'] = len(df[df[column_name]!=0])\n",
    "    temp_dict['NA_RECORDS'] = len(df[df[column_name].isna()])\n",
    "    temp_dict['NULL_RECORDS'] = len(df[df[column_name].isnull()])\n",
    "                             \n",
    "    temp_df = pd.DataFrame(temp_dict.values(),index=temp_dict.keys(),columns=[column_name])\n",
    "    \n",
    "    # Add top X records Based on Frequency\n",
    "    if top_x_records>0:\n",
    "        top_instances = pd.DataFrame(df[column_name].value_counts().head(top_x_records)).reset_index()\n",
    "        top_instances[column_name] = top_instances.apply(lambda row: f\"Value: {row[column_name]}, Frequency: {row['count']}\", axis=1)\n",
    "        top_instances['index'] = [f\"Top {x+1}\" for x in range(len(top_instances[column_name]))]\n",
    "        top_instances = top_instances.drop('count',axis=1).set_index('index')\n",
    "\n",
    "        temp_df = pd.concat([temp_df,top_instances])\n",
    "    \n",
    "    try:\n",
    "        temp_dict['SUM']\n",
    "        segment_df = ColumnPartitioner(df=df,\n",
    "                                       column_name=column_name,\n",
    "                                       partitions=partitions,\n",
    "                                       exclude_blanks=exclude_blanks_from_segments,\n",
    "                                       exclude_zeros=exclude_zeroes_from_segments,\n",
    "                                       return_value='')\n",
    "        \n",
    "        seg_val_df = ColumnPartitioner(df=df,\n",
    "                                           column_name=column_name,\n",
    "                                           partitions=partitions,\n",
    "                                           exclude_blanks=exclude_blanks_from_segments,\n",
    "                                           exclude_zeros=exclude_zeroes_from_segments,\n",
    "                                           return_value='agg_value').rename(columns={'VALUE':column_name})\n",
    "            \n",
    "        return pd.concat([temp_df,segment_df.T,seg_val_df])\n",
    "\n",
    "    \n",
    "    except:\n",
    "        return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "251503ab-a507-494d-8d9c-aed4287a54eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56bf632-f12e-4697-a451-9b4adae6f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Visualization import JupyterNotebookMarkdown\n",
    "df1  = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSQF2lNc4WPeTRQ_VzWPkqSZp4RODFkbap8AqmolWp5bKoMaslP2oRVVG21x2POu_JcbF1tGRcBgodu/pub?output=csv')\n",
    "df2 = df1[df1['Process']=='Time Series']\n",
    "JupyterNotebookMarkdown(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e28b355-47e1-4924-9c00-42601268bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSets import GenerateFakeMemberDF\n",
    "\n",
    "\n",
    "\n",
    "df = GenerateFakeMemberDF(100,20)\n",
    "\n",
    "\n",
    "branches = ['Fenway Park','Wrigely Field','The Forum','Maple Leaf Gardens','GM Place','Safeco','Lambeau Stadium']\n",
    "city = ['Boston','Chicago','Philly','Toronto','Vancouver','Chicago','Seattle','Green Bay']\n",
    "lob = ['Retail','Corporate','Mid Market']\n",
    "duration = ['1) Less than 30d','2) 30D - 1Y', '3) 1Y - 5Y','4)5Y+']\n",
    "\n",
    "list_of_lists = [branches,city,lob,duration]\n",
    "\n",
    "df1 = pd.DataFrame(df['MEMBERNBR'].unique(),columns=['MEMBERNBR'])\n",
    "df1['BRANCHNAME'] = [np.random.choice(branches) for x in range(len(df1))]\n",
    "df1['CITY'] = [np.random.choice(city) for x in range(len(df1))]\n",
    "df1['LOB'] = [np.random.choice(lob) for x in range(len(df1))]\n",
    "df1['DURATION'] = [np.random.choice(duration) for x in range(len(df1))]\n",
    "\n",
    "final_df = df.merge(df1,on='MEMBERNBR',how='left')\n",
    "final_df['INTEREST_RATE'] = final_df['MONTH'].apply(lambda x:np.random.uniform(0.02, 0.07))\n",
    "final_df['MATURED_AMOUNT'] = final_df['LENDING'].apply(lambda x:x*np.random.uniform(0, 1)) \n",
    "final_df['RENEWED_AMOUNT'] = final_df['MATURED_AMOUNT'].apply(lambda x:x*.95) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "44053b80-5504-4875-b47d-30bd84d793f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product,permutations,combinations\n",
    "\n",
    "\n",
    "branches = ['Fenway Park','Wrigely Field','The Forum','Maple Leaf Gardens','GM Place','Safeco','Lambeau Stadium']\n",
    "city = ['Boston','Chicago','Philly','Toronto','Vancouver','Chicago','Seattle','Green Bay']\n",
    "lob = ['Retail','Corporate','Mid Market']\n",
    "duration = ['1) Less than 30d','2) 30D - 1Y', '3) 1Y - 5Y','4)5Y+']\n",
    "list_of_lists = [branches,city,lob,duration]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b7746f2d-8695-4277-95df-c509870c64e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRANCHNAME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOB</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>TOTAL_LENDING</th>\n",
       "      <th>WEIGHTED_INTEREST</th>\n",
       "      <th>RENEWAL_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>2) 30D - 1Y</td>\n",
       "      <td>11334</td>\n",
       "      <td>0.034071</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Retail</td>\n",
       "      <td>2) 30D - 1Y</td>\n",
       "      <td>106647122</td>\n",
       "      <td>0.049776</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Retail</td>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>10239882</td>\n",
       "      <td>0.049786</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>68361</td>\n",
       "      <td>0.058088</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>All</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Retail</td>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>2791918</td>\n",
       "      <td>0.039606</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>All</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Retail</td>\n",
       "      <td>2) 30D - 1Y</td>\n",
       "      <td>122177852</td>\n",
       "      <td>0.041723</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>All</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Retail</td>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>472613</td>\n",
       "      <td>0.046927</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>All</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Retail</td>\n",
       "      <td>4)5Y+</td>\n",
       "      <td>3659554</td>\n",
       "      <td>0.051155</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>1421750201</td>\n",
       "      <td>0.045114</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>695 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BRANCHNAME       CITY         LOB          DURATION  TOTAL_LENDING  \\\n",
       "0    Fenway Park     Boston   Corporate  1) Less than 30d              0   \n",
       "1    Fenway Park     Boston  Mid Market       2) 30D - 1Y          11334   \n",
       "2    Fenway Park     Boston      Retail       2) 30D - 1Y      106647122   \n",
       "3    Fenway Park     Boston      Retail        3) 1Y - 5Y       10239882   \n",
       "4    Fenway Park    Chicago  Mid Market  1) Less than 30d          68361   \n",
       "..           ...        ...         ...               ...            ...   \n",
       "690          All  Vancouver      Retail  1) Less than 30d        2791918   \n",
       "691          All  Vancouver      Retail       2) 30D - 1Y      122177852   \n",
       "692          All  Vancouver      Retail        3) 1Y - 5Y         472613   \n",
       "693          All  Vancouver      Retail             4)5Y+        3659554   \n",
       "694          All        All         All               All     1421750201   \n",
       "\n",
       "     WEIGHTED_INTEREST  RENEWAL_RATE  \n",
       "0                  NaN           NaN  \n",
       "1             0.034071          0.95  \n",
       "2             0.049776          0.95  \n",
       "3             0.049786          0.95  \n",
       "4             0.058088          0.95  \n",
       "..                 ...           ...  \n",
       "690           0.039606          0.95  \n",
       "691           0.041723          0.95  \n",
       "692           0.046927          0.95  \n",
       "693           0.051155          0.95  \n",
       "694           0.045114          0.95  \n",
       "\n",
       "[695 rows x 7 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def CreateCalculatedField(df, primary_key, calc_instructions, include_all=1):\n",
    "\n",
    "    '''\n",
    "    calc_instructions = [\n",
    "    {'type': 'sum', 'value1': 'LENDING', 'name': 'TOTAL_LENDING'},\n",
    "    {'type': 'weighted_average', 'value1': 'LENDING', 'value2': 'INTEREST_RATE', 'name': 'WEIGHTED_INTEREST'},\n",
    "    {'type': 'ratio', 'value1': 'RENEWED_AMOUNT', 'value2': 'MATURED_AMOUNT', 'name': 'RENEWAL_RATE'}\n",
    "    ]\n",
    "\n",
    "    output = CreateCalculatedField(final_df, ['BRANCHNAME', 'CITY', 'LOB', 'DURATION'], calc_instructions)\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    base_aggs = {}\n",
    "    \n",
    "    # Collect all fields we need\n",
    "    for calc in calc_instructions:\n",
    "        if calc['type'] == 'sum':\n",
    "            base_aggs[calc['name']] = (calc['value1'], 'sum')\n",
    "        elif calc['type'] == 'weighted_average':\n",
    "            base_aggs[f\"__{calc['name']}_NUM\"] = (\n",
    "                calc['value2'], lambda x, col=calc['value1']: (df.loc[x.index, col] * x).sum()\n",
    "            )\n",
    "            base_aggs[f\"__{calc['name']}_DEN\"] = (calc['value1'], 'sum')\n",
    "        elif calc['type'] == 'ratio':\n",
    "            base_aggs[f\"__{calc['name']}_NUM\"] = (calc['value1'], 'sum')\n",
    "            base_aggs[f\"__{calc['name']}_DEN\"] = (calc['value2'], 'sum')\n",
    "\n",
    "    # Base groupby\n",
    "    grouped = df.groupby(primary_key, dropna=False).agg(**base_aggs).reset_index()\n",
    "\n",
    "    # Compute post-aggregates\n",
    "    for calc in calc_instructions:\n",
    "        if calc['type'] == 'sum':\n",
    "            continue\n",
    "        elif calc['type'] == 'weighted_average':\n",
    "            num = grouped[f\"__{calc['name']}_NUM\"]\n",
    "            den = grouped[f\"__{calc['name']}_DEN\"]\n",
    "            grouped[calc['name']] = np.where(den != 0, num / den, np.nan)\n",
    "            grouped.drop(columns=[f\"__{calc['name']}_NUM\", f\"__{calc['name']}_DEN\"], inplace=True)\n",
    "        elif calc['type'] == 'ratio':\n",
    "            num = grouped[f\"__{calc['name']}_NUM\"]\n",
    "            den = grouped[f\"__{calc['name']}_DEN\"]\n",
    "            grouped[calc['name']] = np.where(den != 0, num / den, np.nan)\n",
    "            grouped.drop(columns=[f\"__{calc['name']}_NUM\", f\"__{calc['name']}_DEN\"], inplace=True)\n",
    "\n",
    "    result_frames = [grouped.copy()]\n",
    "\n",
    "    # Rollup combinations\n",
    "    if include_all:\n",
    "        for r in range(1, len(primary_key)):\n",
    "            for group_cols in combinations(primary_key, r):\n",
    "                temp = df.copy()\n",
    "                for col in primary_key:\n",
    "                    if col not in group_cols:\n",
    "                        temp[col] = 'All'\n",
    "                temp_group = CreateCalculatedField(temp, primary_key, calc_instructions, include_all=0)\n",
    "                result_frames.append(temp_group)\n",
    "\n",
    "        # Full 'All' row\n",
    "        temp = df.copy()\n",
    "        for col in primary_key:\n",
    "            temp[col] = 'All'\n",
    "        temp_group = CreateCalculatedField(temp, primary_key, calc_instructions, include_all=0)\n",
    "        result_frames.append(temp_group)\n",
    "\n",
    "    return pd.concat(result_frames, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "calc_instructions = [\n",
    "    {'type': 'sum', 'value1': 'LENDING', 'name': 'TOTAL_LENDING'},\n",
    "    {'type': 'weighted_average', 'value1': 'LENDING', 'value2': 'INTEREST_RATE', 'name': 'WEIGHTED_INTEREST'},\n",
    "    {'type': 'ratio', 'value1': 'RENEWED_AMOUNT', 'value2': 'MATURED_AMOUNT', 'name': 'RENEWAL_RATE'}\n",
    "]\n",
    "\n",
    "output = CreateCalculatedField(final_df, ['BRANCHNAME', 'CITY', 'LOB', 'DURATION'], calc_instructions)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ec837f9e-8162-447b-abda-d7f9c425ead3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DURATION</th>\n",
       "      <th>LOB</th>\n",
       "      <th>CITY</th>\n",
       "      <th>BRANCHNAME</th>\n",
       "      <th>METRIC</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>AVG_3M</th>\n",
       "      <th>CHG_3M</th>\n",
       "      <th>PERC_CHG_3M</th>\n",
       "      <th>CHG_DF</th>\n",
       "      <th>AVG_DF</th>\n",
       "      <th>PERC_CHG_DF</th>\n",
       "      <th>MEAN</th>\n",
       "      <th>STD</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>23776180.0</td>\n",
       "      <td>23335842.0</td>\n",
       "      <td>24771980.0</td>\n",
       "      <td>2.396133e+07</td>\n",
       "      <td>995800.0</td>\n",
       "      <td>0.041882</td>\n",
       "      <td>995800.0</td>\n",
       "      <td>24771980.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.396133e+07</td>\n",
       "      <td>735754.436988</td>\n",
       "      <td>24771980.0</td>\n",
       "      <td>23335842.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>6477032.0</td>\n",
       "      <td>6577497.0</td>\n",
       "      <td>5693774.0</td>\n",
       "      <td>6.249434e+06</td>\n",
       "      <td>-783258.0</td>\n",
       "      <td>-0.120929</td>\n",
       "      <td>-783258.0</td>\n",
       "      <td>5693774.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.249434e+06</td>\n",
       "      <td>483830.661065</td>\n",
       "      <td>6577497.0</td>\n",
       "      <td>5693774.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>GM Place</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>3056869.0</td>\n",
       "      <td>2506670.0</td>\n",
       "      <td>3273792.0</td>\n",
       "      <td>2.945777e+06</td>\n",
       "      <td>216923.0</td>\n",
       "      <td>0.070962</td>\n",
       "      <td>216923.0</td>\n",
       "      <td>3273792.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.945777e+06</td>\n",
       "      <td>395442.935288</td>\n",
       "      <td>3273792.0</td>\n",
       "      <td>2506670.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>Lambeau Stadium</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>968324.0</td>\n",
       "      <td>1053892.0</td>\n",
       "      <td>1130907.0</td>\n",
       "      <td>1.051041e+06</td>\n",
       "      <td>162583.0</td>\n",
       "      <td>0.167901</td>\n",
       "      <td>162583.0</td>\n",
       "      <td>1130907.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.051041e+06</td>\n",
       "      <td>81328.986979</td>\n",
       "      <td>1130907.0</td>\n",
       "      <td>968324.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>Maple Leaf Gardens</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>3736161.0</td>\n",
       "      <td>2885826.0</td>\n",
       "      <td>3019594.0</td>\n",
       "      <td>3.213860e+06</td>\n",
       "      <td>-716567.0</td>\n",
       "      <td>-0.191792</td>\n",
       "      <td>-716567.0</td>\n",
       "      <td>3019594.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.213860e+06</td>\n",
       "      <td>457243.872847</td>\n",
       "      <td>3736161.0</td>\n",
       "      <td>2885826.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2) 30D - 1Y</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>585 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DURATION         LOB     CITY          BRANCHNAME        METRIC  \\\n",
       "0                All         All      All                 All       DEPOSIT   \n",
       "0                All         All      All         Fenway Park       DEPOSIT   \n",
       "1                All         All      All            GM Place       DEPOSIT   \n",
       "2                All         All      All     Lambeau Stadium       DEPOSIT   \n",
       "3                All         All      All  Maple Leaf Gardens       DEPOSIT   \n",
       "..               ...         ...      ...                 ...           ...   \n",
       "90       2) 30D - 1Y  Mid Market  Seattle       Wrigely Field  RECORD_COUNT   \n",
       "91        3) 1Y - 5Y      Retail  Seattle       Wrigely Field  RECORD_COUNT   \n",
       "92  1) Less than 30d   Corporate  Toronto       Wrigely Field  RECORD_COUNT   \n",
       "93  1) Less than 30d  Mid Market  Toronto       Wrigely Field  RECORD_COUNT   \n",
       "94        3) 1Y - 5Y  Mid Market  Toronto       Wrigely Field  RECORD_COUNT   \n",
       "\n",
       "             0           1           2        AVG_3M    CHG_3M  PERC_CHG_3M  \\\n",
       "0   23776180.0  23335842.0  24771980.0  2.396133e+07  995800.0     0.041882   \n",
       "0    6477032.0   6577497.0   5693774.0  6.249434e+06 -783258.0    -0.120929   \n",
       "1    3056869.0   2506670.0   3273792.0  2.945777e+06  216923.0     0.070962   \n",
       "2     968324.0   1053892.0   1130907.0  1.051041e+06  162583.0     0.167901   \n",
       "3    3736161.0   2885826.0   3019594.0  3.213860e+06 -716567.0    -0.191792   \n",
       "..         ...         ...         ...           ...       ...          ...   \n",
       "90         1.0         1.0         1.0  1.000000e+00       0.0     0.000000   \n",
       "91         1.0         1.0         1.0  1.000000e+00       0.0     0.000000   \n",
       "92         1.0         1.0         1.0  1.000000e+00       0.0     0.000000   \n",
       "93         2.0         2.0         2.0  2.000000e+00       0.0     0.000000   \n",
       "94         1.0         1.0         1.0  1.000000e+00       0.0     0.000000   \n",
       "\n",
       "      CHG_DF      AVG_DF  PERC_CHG_DF          MEAN            STD  \\\n",
       "0   995800.0  24771980.0          1.0  2.396133e+07  735754.436988   \n",
       "0  -783258.0   5693774.0          1.0  6.249434e+06  483830.661065   \n",
       "1   216923.0   3273792.0          1.0  2.945777e+06  395442.935288   \n",
       "2   162583.0   1130907.0          1.0  1.051041e+06   81328.986979   \n",
       "3  -716567.0   3019594.0          1.0  3.213860e+06  457243.872847   \n",
       "..       ...         ...          ...           ...            ...   \n",
       "90       0.0         1.0          1.0  1.000000e+00       0.000000   \n",
       "91       0.0         1.0          1.0  1.000000e+00       0.000000   \n",
       "92       0.0         1.0          1.0  1.000000e+00       0.000000   \n",
       "93       0.0         2.0          1.0  2.000000e+00       0.000000   \n",
       "94       0.0         1.0          1.0  1.000000e+00       0.000000   \n",
       "\n",
       "           MAX         MIN  COUNT  \n",
       "0   24771980.0  23335842.0      3  \n",
       "0    6577497.0   5693774.0      3  \n",
       "1    3273792.0   2506670.0      3  \n",
       "2    1130907.0    968324.0      3  \n",
       "3    3736161.0   2885826.0      3  \n",
       "..         ...         ...    ...  \n",
       "90         1.0         1.0      3  \n",
       "91         1.0         1.0      3  \n",
       "92         1.0         1.0      3  \n",
       "93         2.0         2.0      3  \n",
       "94         1.0         1.0      3  \n",
       "\n",
       "[585 rows x 19 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1131151b-f182-40d3-b629-178e97218799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEMBERNBR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>OUTLOOK</th>\n",
       "      <th>DEPOSIT</th>\n",
       "      <th>LENDING</th>\n",
       "      <th>TXN_COUNT</th>\n",
       "      <th>TXN_VALUE</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>BRANCHNAME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOB</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>RECORD_COUNT</th>\n",
       "      <th>INTEREST_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>2</td>\n",
       "      <td>968820</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>236538</td>\n",
       "      <td>1</td>\n",
       "      <td>Safeco</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Bankrupt</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>864571</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Spender</td>\n",
       "      <td>0</td>\n",
       "      <td>23798</td>\n",
       "      <td>468929</td>\n",
       "      <td>107</td>\n",
       "      <td>96942</td>\n",
       "      <td>1</td>\n",
       "      <td>Maple Leaf Gardens</td>\n",
       "      <td>Philly</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>2) 30D - 1Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>-2</td>\n",
       "      <td>972158</td>\n",
       "      <td>799159</td>\n",
       "      <td>78</td>\n",
       "      <td>53976</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Retail</td>\n",
       "      <td>4)5Y+</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>-2</td>\n",
       "      <td>710889</td>\n",
       "      <td>75000</td>\n",
       "      <td>33</td>\n",
       "      <td>17292</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>Philly</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MEMBERNBR  MONTH CLASSIFICATION  OUTLOOK  DEPOSIT  LENDING  TXN_COUNT  \\\n",
       "0          0      0         Baller        2   968820        0         51   \n",
       "1          1      0       Bankrupt        2       65   864571          2   \n",
       "2          2      0        Spender        0    23798   468929        107   \n",
       "3          3      0   Full_Service       -2   972158   799159         78   \n",
       "4          4      0   Full_Service       -2   710889    75000         33   \n",
       "\n",
       "   TXN_VALUE  ACTIVE          BRANCHNAME       CITY         LOB  \\\n",
       "0     236538       1              Safeco  Vancouver  Mid Market   \n",
       "1        134       1       Wrigely Field    Chicago   Corporate   \n",
       "2      96942       1  Maple Leaf Gardens     Philly  Mid Market   \n",
       "3      53976       1         Fenway Park    Toronto      Retail   \n",
       "4      17292       1         Fenway Park     Philly   Corporate   \n",
       "\n",
       "           DURATION  RECORD_COUNT  INTEREST_RATE  \n",
       "0        3) 1Y - 5Y             1       0.040365  \n",
       "1  1) Less than 30d             1       0.041694  \n",
       "2       2) 30D - 1Y             1       0.036464  \n",
       "3             4)5Y+             1       0.066798  \n",
       "4        3) 1Y - 5Y             1       0.024631  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "da31379a-a46c-41a6-9ce2-c17e86b9fdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEMBERNBR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>OUTLOOK</th>\n",
       "      <th>DEPOSIT</th>\n",
       "      <th>LENDING</th>\n",
       "      <th>TXN_COUNT</th>\n",
       "      <th>TXN_VALUE</th>\n",
       "      <th>ACTIVE</th>\n",
       "      <th>BRANCHNAME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOB</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>RECORD_COUNT</th>\n",
       "      <th>INTEREST_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>2</td>\n",
       "      <td>968820</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>236538</td>\n",
       "      <td>1</td>\n",
       "      <td>Safeco</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Bankrupt</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>864571</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Spender</td>\n",
       "      <td>0</td>\n",
       "      <td>23798</td>\n",
       "      <td>468929</td>\n",
       "      <td>107</td>\n",
       "      <td>96942</td>\n",
       "      <td>1</td>\n",
       "      <td>Maple Leaf Gardens</td>\n",
       "      <td>Philly</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>2) 30D - 1Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>-2</td>\n",
       "      <td>972158</td>\n",
       "      <td>799159</td>\n",
       "      <td>78</td>\n",
       "      <td>53976</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Retail</td>\n",
       "      <td>4)5Y+</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>-2</td>\n",
       "      <td>710889</td>\n",
       "      <td>75000</td>\n",
       "      <td>33</td>\n",
       "      <td>17292</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>Philly</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>179</td>\n",
       "      <td>20</td>\n",
       "      <td>Spender</td>\n",
       "      <td>0</td>\n",
       "      <td>51750</td>\n",
       "      <td>40000</td>\n",
       "      <td>184</td>\n",
       "      <td>18216</td>\n",
       "      <td>1</td>\n",
       "      <td>The Forum</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>180</td>\n",
       "      <td>20</td>\n",
       "      <td>Bankrupt</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>769480</td>\n",
       "      <td>6</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>Lambeau Stadium</td>\n",
       "      <td>Philly</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>181</td>\n",
       "      <td>20</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>1</td>\n",
       "      <td>766938</td>\n",
       "      <td>66132</td>\n",
       "      <td>67</td>\n",
       "      <td>80199</td>\n",
       "      <td>1</td>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>182</td>\n",
       "      <td>20</td>\n",
       "      <td>Borrower</td>\n",
       "      <td>-2</td>\n",
       "      <td>48054</td>\n",
       "      <td>82485</td>\n",
       "      <td>7</td>\n",
       "      <td>833</td>\n",
       "      <td>1</td>\n",
       "      <td>GM Place</td>\n",
       "      <td>Philly</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>183</td>\n",
       "      <td>20</td>\n",
       "      <td>Spender</td>\n",
       "      <td>1</td>\n",
       "      <td>11586</td>\n",
       "      <td>930652</td>\n",
       "      <td>122</td>\n",
       "      <td>50752</td>\n",
       "      <td>1</td>\n",
       "      <td>GM Place</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>4)5Y+</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2928 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MEMBERNBR  MONTH CLASSIFICATION  OUTLOOK  DEPOSIT  LENDING  TXN_COUNT  \\\n",
       "0             0      0         Baller        2   968820        0         51   \n",
       "1             1      0       Bankrupt        2       65   864571          2   \n",
       "2             2      0        Spender        0    23798   468929        107   \n",
       "3             3      0   Full_Service       -2   972158   799159         78   \n",
       "4             4      0   Full_Service       -2   710889    75000         33   \n",
       "...         ...    ...            ...      ...      ...      ...        ...   \n",
       "2923        179     20        Spender        0    51750    40000        184   \n",
       "2924        180     20       Bankrupt        1       75   769480          6   \n",
       "2925        181     20   Full_Service        1   766938    66132         67   \n",
       "2926        182     20       Borrower       -2    48054    82485          7   \n",
       "2927        183     20        Spender        1    11586   930652        122   \n",
       "\n",
       "      TXN_VALUE  ACTIVE          BRANCHNAME       CITY         LOB  \\\n",
       "0        236538       1              Safeco  Vancouver  Mid Market   \n",
       "1           134       1       Wrigely Field    Chicago   Corporate   \n",
       "2         96942       1  Maple Leaf Gardens     Philly  Mid Market   \n",
       "3         53976       1         Fenway Park    Toronto      Retail   \n",
       "4         17292       1         Fenway Park     Philly   Corporate   \n",
       "...         ...     ...                 ...        ...         ...   \n",
       "2923      18216       1           The Forum     Boston  Mid Market   \n",
       "2924        240       1     Lambeau Stadium     Philly  Mid Market   \n",
       "2925      80199       1         Fenway Park  Vancouver  Mid Market   \n",
       "2926        833       1            GM Place     Philly   Corporate   \n",
       "2927      50752       1            GM Place  Vancouver  Mid Market   \n",
       "\n",
       "              DURATION  RECORD_COUNT  INTEREST_RATE  \n",
       "0           3) 1Y - 5Y             1       0.040365  \n",
       "1     1) Less than 30d             1       0.041694  \n",
       "2          2) 30D - 1Y             1       0.036464  \n",
       "3                4)5Y+             1       0.066798  \n",
       "4           3) 1Y - 5Y             1       0.024631  \n",
       "...                ...           ...            ...  \n",
       "2923  1) Less than 30d             1       0.038509  \n",
       "2924        3) 1Y - 5Y             1       0.053251  \n",
       "2925        3) 1Y - 5Y             1       0.039106  \n",
       "2926        3) 1Y - 5Y             1       0.046681  \n",
       "2927             4)5Y+             1       0.058133  \n",
       "\n",
       "[2928 rows x 15 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "00412883-984f-435c-a41f-7a5895a78ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DURATION</th>\n",
       "      <th>LOB</th>\n",
       "      <th>CITY</th>\n",
       "      <th>BRANCHNAME</th>\n",
       "      <th>METRIC</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>AVG_3M</th>\n",
       "      <th>CHG_3M</th>\n",
       "      <th>PERC_CHG_3M</th>\n",
       "      <th>CHG_DF</th>\n",
       "      <th>AVG_DF</th>\n",
       "      <th>PERC_CHG_DF</th>\n",
       "      <th>MEAN</th>\n",
       "      <th>STD</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>4.582576</td>\n",
       "      <td>109.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>GM Place</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>Lambeau Stadium</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>Maple Leaf Gardens</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2) 30D - 1Y</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DURATION         LOB     CITY          BRANCHNAME        METRIC  \\\n",
       "0                All         All      All                 All  RECORD_COUNT   \n",
       "0                All         All      All         Fenway Park  RECORD_COUNT   \n",
       "1                All         All      All            GM Place  RECORD_COUNT   \n",
       "2                All         All      All     Lambeau Stadium  RECORD_COUNT   \n",
       "3                All         All      All  Maple Leaf Gardens  RECORD_COUNT   \n",
       "..               ...         ...      ...                 ...           ...   \n",
       "90       2) 30D - 1Y  Mid Market  Seattle       Wrigely Field  RECORD_COUNT   \n",
       "91        3) 1Y - 5Y      Retail  Seattle       Wrigely Field  RECORD_COUNT   \n",
       "92  1) Less than 30d   Corporate  Toronto       Wrigely Field  RECORD_COUNT   \n",
       "93  1) Less than 30d  Mid Market  Toronto       Wrigely Field  RECORD_COUNT   \n",
       "94        3) 1Y - 5Y  Mid Market  Toronto       Wrigely Field  RECORD_COUNT   \n",
       "\n",
       "        0      1      2      AVG_3M  CHG_3M  PERC_CHG_3M  CHG_DF  AVG_DF  \\\n",
       "0   100.0  103.0  109.0  104.000000     9.0     0.090000     9.0   109.0   \n",
       "0    19.0   20.0   21.0   20.000000     2.0     0.105263     2.0    21.0   \n",
       "1    10.0   10.0   12.0   10.666667     2.0     0.200000     2.0    12.0   \n",
       "2    13.0   13.0   13.0   13.000000     0.0     0.000000     0.0    13.0   \n",
       "3    18.0   18.0   19.0   18.333333     1.0     0.055556     1.0    19.0   \n",
       "..    ...    ...    ...         ...     ...          ...     ...     ...   \n",
       "90    1.0    1.0    1.0    1.000000     0.0     0.000000     0.0     1.0   \n",
       "91    1.0    1.0    1.0    1.000000     0.0     0.000000     0.0     1.0   \n",
       "92    1.0    1.0    1.0    1.000000     0.0     0.000000     0.0     1.0   \n",
       "93    2.0    2.0    2.0    2.000000     0.0     0.000000     0.0     2.0   \n",
       "94    1.0    1.0    1.0    1.000000     0.0     0.000000     0.0     1.0   \n",
       "\n",
       "    PERC_CHG_DF        MEAN       STD    MAX    MIN  COUNT  \n",
       "0           1.0  104.000000  4.582576  109.0  100.0      3  \n",
       "0           1.0   20.000000  1.000000   21.0   19.0      3  \n",
       "1           1.0   10.666667  1.154701   12.0   10.0      3  \n",
       "2           1.0   13.000000  0.000000   13.0   13.0      3  \n",
       "3           1.0   18.333333  0.577350   19.0   18.0      3  \n",
       "..          ...         ...       ...    ...    ...    ...  \n",
       "90          1.0    1.000000  0.000000    1.0    1.0      3  \n",
       "91          1.0    1.000000  0.000000    1.0    1.0      3  \n",
       "92          1.0    1.000000  0.000000    1.0    1.0      3  \n",
       "93          1.0    2.000000  0.000000    2.0    2.0      3  \n",
       "94          1.0    1.000000  0.000000    1.0    1.0      3  \n",
       "\n",
       "[117 rows x 19 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['DEPOSIT','LENDING','TXN_COUNT','TXN_VALUE','RECORD_COUNT']\n",
    "index=['BRANCHNAME','CITY','LOB','DURATION']\n",
    "\n",
    "column='MONTH'\n",
    "\n",
    "final_df['RECORD_COUNT']=1\n",
    "\n",
    "def CreateMultiplePivotTableFromTimeSeries(df,index_list,metric_list,column):\n",
    "    '''\n",
    "    Function to utilize when Attempting to Create Multip[le Times Series. Specifically Multiple Metrics, and Multiple Index's\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through all Possible Metrics Selected.\n",
    "    for metric in metric_list:\n",
    "        all_df = CreatePivotTableFromTimeSeries(df=df,index=None,columns=column,values=metric,aggfunc='sum') \n",
    "        cols = list(all_df.columns)\n",
    "        all_df = all_df.reset_index(drop=True)\n",
    "        all_df['METRIC'] = metric\n",
    "        cols.insert(0,'METRIC')\n",
    "\n",
    "        for key in index:\n",
    "            cols.insert(0,key)\n",
    "            all_df[key] = 'All'\n",
    "\n",
    "        final_df = pd.concat([final_df,all_df[cols]])\n",
    "\n",
    "        # Iterate through all Index Items Individually\n",
    "        for key in index_list:\n",
    "            temp = CreatePivotTableFromTimeSeries(df,index=key,\n",
    "                                                  values=metric,\n",
    "                                                  columns=column).reset_index() \n",
    "            for missing in [x for x in index if x != key]:\n",
    "                temp[missing] = 'All'\n",
    "            temp['METRIC'] = metric\n",
    "            final_df = pd.concat([final_df,temp])\n",
    "        \n",
    "        # Add Value for Metric with Entire Index Combination\n",
    "        temp = CreatePivotTableFromTimeSeries(df,index=index_list,values=metric,columns=column).reset_index()\n",
    "        temp['METRIC'] = metric\n",
    "        final_df = pd.concat([final_df,temp])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "e = CreateMultiplePivotTableFromTimeSeries(df=final_df[final_df['MONTH']<3],\n",
    "                                       index_list= index,\n",
    "                                       metric_list=metrics,\n",
    "                                       column= 'MONTH')\n",
    "        \n",
    "\n",
    "e[\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "58b7a3ea-ce45-4610-98de-d8a549484c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DURATION</th>\n",
       "      <th>LOB</th>\n",
       "      <th>CITY</th>\n",
       "      <th>BRANCHNAME</th>\n",
       "      <th>METRIC</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>AVG_3M</th>\n",
       "      <th>CHG_3M</th>\n",
       "      <th>PERC_CHG_3M</th>\n",
       "      <th>CHG_DF</th>\n",
       "      <th>AVG_DF</th>\n",
       "      <th>PERC_CHG_DF</th>\n",
       "      <th>MEAN</th>\n",
       "      <th>STD</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>23776180.0</td>\n",
       "      <td>23335842.0</td>\n",
       "      <td>24771980.0</td>\n",
       "      <td>2.396133e+07</td>\n",
       "      <td>995800.0</td>\n",
       "      <td>0.041882</td>\n",
       "      <td>995800.0</td>\n",
       "      <td>24771980.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.396133e+07</td>\n",
       "      <td>735754.436988</td>\n",
       "      <td>24771980.0</td>\n",
       "      <td>23335842.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>Fenway Park</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>6477032.0</td>\n",
       "      <td>6577497.0</td>\n",
       "      <td>5693774.0</td>\n",
       "      <td>6.249434e+06</td>\n",
       "      <td>-783258.0</td>\n",
       "      <td>-0.120929</td>\n",
       "      <td>-783258.0</td>\n",
       "      <td>5693774.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.249434e+06</td>\n",
       "      <td>483830.661065</td>\n",
       "      <td>6577497.0</td>\n",
       "      <td>5693774.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>GM Place</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>3056869.0</td>\n",
       "      <td>2506670.0</td>\n",
       "      <td>3273792.0</td>\n",
       "      <td>2.945777e+06</td>\n",
       "      <td>216923.0</td>\n",
       "      <td>0.070962</td>\n",
       "      <td>216923.0</td>\n",
       "      <td>3273792.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.945777e+06</td>\n",
       "      <td>395442.935288</td>\n",
       "      <td>3273792.0</td>\n",
       "      <td>2506670.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>Lambeau Stadium</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>968324.0</td>\n",
       "      <td>1053892.0</td>\n",
       "      <td>1130907.0</td>\n",
       "      <td>1.051041e+06</td>\n",
       "      <td>162583.0</td>\n",
       "      <td>0.167901</td>\n",
       "      <td>162583.0</td>\n",
       "      <td>1130907.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.051041e+06</td>\n",
       "      <td>81328.986979</td>\n",
       "      <td>1130907.0</td>\n",
       "      <td>968324.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>All</td>\n",
       "      <td>Maple Leaf Gardens</td>\n",
       "      <td>DEPOSIT</td>\n",
       "      <td>3736161.0</td>\n",
       "      <td>2885826.0</td>\n",
       "      <td>3019594.0</td>\n",
       "      <td>3.213860e+06</td>\n",
       "      <td>-716567.0</td>\n",
       "      <td>-0.191792</td>\n",
       "      <td>-716567.0</td>\n",
       "      <td>3019594.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.213860e+06</td>\n",
       "      <td>457243.872847</td>\n",
       "      <td>3736161.0</td>\n",
       "      <td>2885826.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2) 30D - 1Y</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1) Less than 30d</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3) 1Y - 5Y</td>\n",
       "      <td>Mid Market</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Wrigely Field</td>\n",
       "      <td>RECORD_COUNT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>585 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DURATION         LOB     CITY          BRANCHNAME        METRIC  \\\n",
       "0                All         All      All                 All       DEPOSIT   \n",
       "0                All         All      All         Fenway Park       DEPOSIT   \n",
       "1                All         All      All            GM Place       DEPOSIT   \n",
       "2                All         All      All     Lambeau Stadium       DEPOSIT   \n",
       "3                All         All      All  Maple Leaf Gardens       DEPOSIT   \n",
       "..               ...         ...      ...                 ...           ...   \n",
       "90       2) 30D - 1Y  Mid Market  Seattle       Wrigely Field  RECORD_COUNT   \n",
       "91        3) 1Y - 5Y      Retail  Seattle       Wrigely Field  RECORD_COUNT   \n",
       "92  1) Less than 30d   Corporate  Toronto       Wrigely Field  RECORD_COUNT   \n",
       "93  1) Less than 30d  Mid Market  Toronto       Wrigely Field  RECORD_COUNT   \n",
       "94        3) 1Y - 5Y  Mid Market  Toronto       Wrigely Field  RECORD_COUNT   \n",
       "\n",
       "             0           1           2        AVG_3M    CHG_3M  PERC_CHG_3M  \\\n",
       "0   23776180.0  23335842.0  24771980.0  2.396133e+07  995800.0     0.041882   \n",
       "0    6477032.0   6577497.0   5693774.0  6.249434e+06 -783258.0    -0.120929   \n",
       "1    3056869.0   2506670.0   3273792.0  2.945777e+06  216923.0     0.070962   \n",
       "2     968324.0   1053892.0   1130907.0  1.051041e+06  162583.0     0.167901   \n",
       "3    3736161.0   2885826.0   3019594.0  3.213860e+06 -716567.0    -0.191792   \n",
       "..         ...         ...         ...           ...       ...          ...   \n",
       "90         1.0         1.0         1.0  1.000000e+00       0.0     0.000000   \n",
       "91         1.0         1.0         1.0  1.000000e+00       0.0     0.000000   \n",
       "92         1.0         1.0         1.0  1.000000e+00       0.0     0.000000   \n",
       "93         2.0         2.0         2.0  2.000000e+00       0.0     0.000000   \n",
       "94         1.0         1.0         1.0  1.000000e+00       0.0     0.000000   \n",
       "\n",
       "      CHG_DF      AVG_DF  PERC_CHG_DF          MEAN            STD  \\\n",
       "0   995800.0  24771980.0          1.0  2.396133e+07  735754.436988   \n",
       "0  -783258.0   5693774.0          1.0  6.249434e+06  483830.661065   \n",
       "1   216923.0   3273792.0          1.0  2.945777e+06  395442.935288   \n",
       "2   162583.0   1130907.0          1.0  1.051041e+06   81328.986979   \n",
       "3  -716567.0   3019594.0          1.0  3.213860e+06  457243.872847   \n",
       "..       ...         ...          ...           ...            ...   \n",
       "90       0.0         1.0          1.0  1.000000e+00       0.000000   \n",
       "91       0.0         1.0          1.0  1.000000e+00       0.000000   \n",
       "92       0.0         1.0          1.0  1.000000e+00       0.000000   \n",
       "93       0.0         2.0          1.0  2.000000e+00       0.000000   \n",
       "94       0.0         1.0          1.0  1.000000e+00       0.000000   \n",
       "\n",
       "           MAX         MIN  COUNT  \n",
       "0   24771980.0  23335842.0      3  \n",
       "0    6577497.0   5693774.0      3  \n",
       "1    3273792.0   2506670.0      3  \n",
       "2    1130907.0    968324.0      3  \n",
       "3    3736161.0   2885826.0      3  \n",
       "..         ...         ...    ...  \n",
       "90         1.0         1.0      3  \n",
       "91         1.0         1.0      3  \n",
       "92         1.0         1.0      3  \n",
       "93         2.0         2.0      3  \n",
       "94         1.0         1.0      3  \n",
       "\n",
       "[585 rows x 19 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "78d0f9d8-2c2a-457e-9d6c-8c6bc78bce58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13306201.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[e['BRANCHNAME']=='Fenway Park'][0].sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "23fa88c4-deb7-4a13-87ce-1d8c3cbc6b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              397892.000000\n",
       "1              401090.000000\n",
       "2              390791.000000\n",
       "3              397730.000000\n",
       "4              413003.000000\n",
       "5              395245.000000\n",
       "6              411525.000000\n",
       "AVG_3M         406591.000000\n",
       "CHG_3M          -1478.000000\n",
       "PERC_CHG_3M        -0.003579\n",
       "AVG_6M         401564.000000\n",
       "CHG_6M          10435.000000\n",
       "PERC_CHG_6M         0.026017\n",
       "CHG_DF          13633.000000\n",
       "AVG_DF         411525.000000\n",
       "PERC_CHG_DF         1.000000\n",
       "MEAN           401039.428571\n",
       "STD              8291.975254\n",
       "MAX            413003.000000\n",
       "MIN            390791.000000\n",
       "COUNT               7.000000\n",
       "Name: (Fenway Park, Boston, Corporate, 1) Less than 30d), dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CreatePivotTableFromTimeSeries(final_df[final_df['MONTH']<=6],index=['BRANCHNAME','CITY','LOB','DURATION'],columns='MONTH',values='DEPOSIT').iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7c6abaea-f52f-4a52-b8d1-e4e2d3cb7675",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CreatePivotTableFromTimeSeries(df,\n",
    "                                   index,\n",
    "                                   columns,\n",
    "                                   values,\n",
    "                                   aggfunc='sum',\n",
    "                                   skipna=True):\n",
    "    \n",
    "    '''\n",
    "    Function to Summaryize a Time Series Dataframe into a Pivot. Creating a number of critical Metrics.\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1. Pivot\n",
    "    if index==None:\n",
    "        df1 = df.pivot_table(columns=columns,values=values,aggfunc=aggfunc)\n",
    "    else:\n",
    "        df1 = df.pivot_table(index=index, columns=columns, values=values, aggfunc=aggfunc)\n",
    "\n",
    "    # 2. Capture original month columns IMMEDIATELY after pivot\n",
    "    month_cols = df1.columns.tolist()\n",
    " \n",
    "    # 3. Add rolling window stats\n",
    "    if len(month_cols) >= 3:\n",
    "        df1['AVG_3M'] = df1[month_cols[-3:]].mean(axis=1, skipna=skipna)\n",
    "        df1['CHG_3M'] = df1[month_cols[-1]]-df1[month_cols[-3]]\n",
    "        try:\n",
    "            df1['PERC_CHG_3M'] = df1['CHG_3M']/df1[month_cols[-3]]\n",
    "        except:\n",
    "            df1['PERC_CHG_3M'] = 0\n",
    "    \n",
    "    if len(month_cols) >= 6:\n",
    "        df1['AVG_6M'] = df1[month_cols[-6:]].mean(axis=1, skipna=skipna)\n",
    "        df1['CHG_6M'] = df1[month_cols[-1]]-df1[month_cols[-6]]\n",
    "        try:\n",
    "            df1['PERC_CHG_6M'] = df1['CHG_6M']/df1[month_cols[-6]]\n",
    "        except:\n",
    "            df1['PERC_CHG_6M'] = 0\n",
    "            \n",
    "    if len(month_cols) >= 12:\n",
    "        df1['AVG_12M'] = df1[month_cols[-12:]].mean(axis=1, skipna=skipna)\n",
    "        df1['CHG_12M'] = df1[month_cols[-1]]-df1[month_cols[-12]]\n",
    "        try:\n",
    "            df1['PERC_CHG_12M'] = df1['CHG_12M']/df1[month_cols[-12]]\n",
    "        except:\n",
    "            df1['PERC_CHG_12M'] = 0\n",
    "\n",
    "    df1['CHG_DF']  = df1[month_cols[-1]]-df1[month_cols[0]]\n",
    "    df1['AVG_DF'] = df1[month_cols[-1:]].mean(axis=1, skipna=skipna)\n",
    "    df1['PERC_CHG_DF'] = df1['AVG_DF']/df1[month_cols[-1]]\n",
    "\n",
    "    \n",
    "    # 4. Now calculate global stats **only using the original month columns**\n",
    "    stats = pd.DataFrame({\n",
    "        'MEAN': df1[month_cols].mean(axis=1, skipna=skipna),\n",
    "        'STD': df1[month_cols].std(axis=1, skipna=skipna),\n",
    "        'MAX': df1[month_cols].max(axis=1, skipna=skipna),\n",
    "        'MIN': df1[month_cols].min(axis=1, skipna=skipna),\n",
    "        'COUNT': df1[month_cols].count(axis=1)\n",
    "    })\n",
    "\n",
    "    # 5. Merge the stats\n",
    "    df1 = pd.concat([df1, stats], axis=1)\n",
    "    \n",
    "    return df1.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3838650a-dba3-40f5-a9bd-def4c37aa577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df.copy()\n",
    "group_vars = ['BRANCHNAME','CITY','LOB','DURATION','MONTH']\n",
    "agg_cols = ['DEPOSIT','LENDING','TXN_COUNT','TXN_VALUE']\n",
    "agg_funcs = ['sum', 'mean','count']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c99e8b-7e53-4cb9-af94-34899439c9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a83c7-1a84-4b34-88e9-2806f2270f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e632e-82f5-4c2e-af8b-40be4793296b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e21907-33f6-4b32-a17c-83ab65124809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1beb98d-bbe3-466a-b216-9fe828ac82a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57159897-cf9c-428d-a226-3cc0af68fb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? lavish production values and solid performances in this straightforward adaption of jane ? satirical classic about the marriage game within and between the classes in ? 18th century england northam and paltrow are a ? mixture as friends who must pass through ? and lies to discover that they love each other good humor is a ? virtue which goes a long way towards explaining the ? of the aged source material which has been toned down a bit in its harsh ? i liked the look of the film and how shots were set up and i thought it didn't rely too much on ? of head shots like most other films of the 80s and 90s do very good results\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict([(value,key) for (key,value) in word_index.items()])\n",
    "\n",
    "\" \".join([d.get(i-3,\"?\") for i in X_train[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53eabbc-703a-46a7-bbe5-a69af44aaccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255187e3-6c15-4d03-b76f-10e7ff19d3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8113e345-72b9-4fe8-8ed1-bacfd4506a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ec13b-262c-464b-8c70-8a66293a048b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb9ec5-415a-49a4-8ab2-16148b0f05a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf903b-61d5-45c7-9561-1ca869bac238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8861f6-a7bb-44af-8717-ddb4ae09f807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f206589-2443-4566-aa65-9e44486ea13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Connections import NavigateUsingDMap\n",
    "NavigateUsingDMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d136b5c6-8c95-44e4-8433-b97e082efd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub Categorization</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Link</th>\n",
       "      <th>Image</th>\n",
       "      <th>Markdown Equation</th>\n",
       "      <th>Dataset Size</th>\n",
       "      <th>Learning Type</th>\n",
       "      <th>Algorithm Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>Number of correctly classified examples divide...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$$ Accuracy = \\frac{TP + TN}{TP + TN + FP + FN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actions</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Spark</td>\n",
       "      <td>In Spark, actions trigger the execution of tra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Activation Functions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Activation Function</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://raw.githubusercontent.com/derek-dewald...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acyclic Graph</td>\n",
       "      <td>Statistics</td>\n",
       "      <td>Definition</td>\n",
       "      <td>A graph that does not contain any cycles. This...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>big</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adadelta</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Adaptive learning rate for nonstationary objec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>TunedThresholdClassifierCV</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Model</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>TweedieRegressor</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Model</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>VarianceThreshold</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Model</td>\n",
       "      <td>Large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Model</td>\n",
       "      <td>Medium, Large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium, Large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>VotingRegressor</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Model</td>\n",
       "      <td>Medium, Large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium, Large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Word          Category   Sub Categorization  \\\n",
       "0                      Accuracy  Machine Learning           Evaluation   \n",
       "1                       Actions        Technology                Spark   \n",
       "2          Activation Functions               NaN  Activation Function   \n",
       "3                 Acyclic Graph        Statistics           Definition   \n",
       "4                      Adadelta  Machine Learning         Optimization   \n",
       "..                          ...               ...                  ...   \n",
       "578  TunedThresholdClassifierCV  Machine Learning                Model   \n",
       "579            TweedieRegressor  Machine Learning                Model   \n",
       "580           VarianceThreshold  Machine Learning                Model   \n",
       "581            VotingClassifier  Machine Learning                Model   \n",
       "582             VotingRegressor  Machine Learning                Model   \n",
       "\n",
       "                                            Definition Notes Link  \\\n",
       "0    Number of correctly classified examples divide...   NaN  NaN   \n",
       "1    In Spark, actions trigger the execution of tra...   NaN  NaN   \n",
       "2                                                  NaN   NaN  NaN   \n",
       "3    A graph that does not contain any cycles. This...   NaN  NaN   \n",
       "4    Adaptive learning rate for nonstationary objec...   NaN  NaN   \n",
       "..                                                 ...   ...  ...   \n",
       "578                                            Unknown   NaN  NaN   \n",
       "579                                             Medium   NaN  NaN   \n",
       "580                                              Large   NaN  NaN   \n",
       "581                                      Medium, Large   NaN  NaN   \n",
       "582                                      Medium, Large   NaN  NaN   \n",
       "\n",
       "                                                 Image  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2    https://raw.githubusercontent.com/derek-dewald...   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "578                                                NaN   \n",
       "579                                                NaN   \n",
       "580                                                NaN   \n",
       "581                                                NaN   \n",
       "582                                                NaN   \n",
       "\n",
       "                                     Markdown Equation   Dataset Size  \\\n",
       "0    $$ Accuracy = \\frac{TP + TN}{TP + TN + FP + FN...            NaN   \n",
       "1                                                  NaN            NaN   \n",
       "2                                                  NaN            NaN   \n",
       "3                                                  big            NaN   \n",
       "4                                                  NaN            NaN   \n",
       "..                                                 ...            ...   \n",
       "578                                                NaN        Unknown   \n",
       "579                                                NaN         Medium   \n",
       "580                                                NaN          Large   \n",
       "581                                                NaN  Medium, Large   \n",
       "582                                                NaN  Medium, Large   \n",
       "\n",
       "    Learning Type Algorithm Class  \n",
       "0             NaN             NaN  \n",
       "1             NaN             NaN  \n",
       "2             NaN             NaN  \n",
       "3             NaN             NaN  \n",
       "4             NaN             NaN  \n",
       "..            ...             ...  \n",
       "578           NaN             NaN  \n",
       "579           NaN             NaN  \n",
       "580           NaN             NaN  \n",
       "581           NaN             NaN  \n",
       "582           NaN             NaN  \n",
       "\n",
       "[583 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQq1-3cTas8DCWBa2NKYhVFXpl8kLaFDohg0zMfNTAU_Fiw6aIFLWfA5zRem4eSaGPa7UiQvkz05loW/pub?output=csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3ec4f-9001-4888-9451-160d924363e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "\n",
    "def long_format_summary(df, group_vars, agg_cols, agg_funcs):\n",
    "    \"\"\"\n",
    "    Summarizes df grouped by group_vars, with one row per (group, metric, function) and a single VALUE column.\n",
    "\n",
    "    Parameters:\n",
    "    - df: input DataFrame\n",
    "    - group_vars: list of columns to group by\n",
    "    - agg_cols: list of numeric columns to summarize\n",
    "    - agg_funcs: list of aggregation functions (e.g., ['sum', 'mean', 'min', 'max'])\n",
    "\n",
    "    Returns:\n",
    "    - long_df: tidy DataFrame with columns: group_vars + ['METRIC', 'FUNCTION', 'VALUE']\n",
    "    \"\"\"\n",
    "    # Multi-level aggregation\n",
    "    agg_df = df.groupby(group_vars)[agg_cols].agg(agg_funcs).reset_index()\n",
    "\n",
    "    # Flatten multi-index columns\n",
    "    agg_df.columns = group_vars + [f\"{col}_{func}\" for col in agg_cols for func in agg_funcs]\n",
    "\n",
    "    # Melt to long format\n",
    "    long_df = agg_df.melt(id_vars=group_vars, var_name='METRIC_FUNC', value_name='VALUE')\n",
    "\n",
    "    # Split \"DEPOSIT_sum\" → \"DEPOSIT\", \"sum\"\n",
    "    long_df[['METRIC', 'FUNCTION']] = long_df['METRIC_FUNC'].str.rsplit('_', n=1, expand=True)\n",
    "    long_df = long_df.drop(columns='METRIC_FUNC')\n",
    "\n",
    "    # Optional: sort for readability\n",
    "    return long_df.sort_values(by=group_vars + ['METRIC', 'FUNCTION']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8011243-cada-480b-9db7-8cf2f3d03730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Identity Access Management (IAM)', 'Reciever Operating Characterisitcs (ROC) ', 'Centrality', 'Neural Network', 'Hive']\n",
      "\n",
      "=== Linear Regression ===\n",
      "Category: Machine Learning\n",
      "Sub Category: Model\n",
      "Definition: Linear Regression models the relationship between an independent variable ( X ) and a dependent variable ( Y ) using a linear function. Model strengths include : Simple, interpretable, computationally efficient, works well for linearly separable data. Weaknesses, Assumes linear relationships, sensitive to outliers.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Equation:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle Y = w_0 + w_1 X + \\epsilon$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RidgeCV ===\n",
      "Category: Machine Learning\n",
      "Sub Category: Model\n",
      "Definition: Medium, Large\n",
      "\n",
      "\n",
      "=== BLUF ===\n",
      "Category: nan\n",
      "Sub Category: nan\n",
      "Definition: Bottom Line Up Front\n",
      "\n",
      "\n",
      "=== Beaucratic Politics ===\n",
      "Category: nan\n",
      "Sub Category: nan\n",
      "Definition: That people only do what is best for them and the decision is made based solely on who is making the decision. They are operating solely on their own best interests.\n",
      "\n",
      "\n",
      "=== Lag ===\n",
      "Category: nan\n",
      "Sub Category: nan\n",
      "Definition: A lag can be introduced to identify a relationship which occurs over a period of time, opposed to immediatley. A common example is Economic Data, when you need to wait to see the impact of the effect, such as inflation rate.\n",
      "\n",
      "\n",
      "\n",
      "=== Ensemble Learning ===\n",
      "Category: nan\n",
      "Sub Category: nan\n",
      "Definition: Aggregate the prediction of a group of predictions. Often used at the end of project after you've put together a series of high quality models. Take a Logistic Classifier, Random Forest, SVM and several other models, average them out and take the most frequent entry. Ensembles work best when the error is independently distributed, if trained on the same data set it is highly likely they will contain the same error.\n",
      "\n",
      "\n",
      "=== FastICA ===\n",
      "Category: Machine Learning\n",
      "Sub Category: Model\n",
      "Definition: Small\n",
      "\n",
      "\n",
      "=== XOR ===\n",
      "Category: nan\n",
      "Sub Category: nan\n",
      "Definition: Not Linearly Seperable. Problem for ML. Nand as Function of (x1,x2) new function (h1, h2) - \n",
      "\n",
      "\n",
      "=== Margin of Error ===\n",
      "Category: Statistics\n",
      "Sub Category: Calculation\n",
      "Definition: The margin of error represents the range within which the true population value is expected to lie, given the sample estimate. It is usually expressed as a percentage (e.g., ±5%). It helps determine how precise or reliable the sample estimate is, indicating the level of uncertainty in the results.\n",
      "\n",
      "\n",
      "=== Control ===\n",
      "Category: Experiement Design\n",
      "Sub Category: nan\n",
      "Definition: The ability to influence or manipulate a system's behavior or outcomes through deliberate intervention. Focuses on cause-effect relationships that can be reliably acted upon. Doesn't necessarily require full understanding — only that the action works. Example: A thermostat controls room temperature by adjusting heating/cooling based on feedback.\n",
      "\n",
      "We control things without understanding - A Pilot.\n",
      "\n",
      "\n",
      "=== VarianceThreshold ===\n",
      "Category: Machine Learning\n",
      "Sub Category: Model\n",
      "Definition: Large\n",
      "\n",
      "\n",
      "=== Research Approach ===\n",
      "Category: Experiement Design\n",
      "Sub Category: nan\n",
      "Definition: Broad Plan. I includes phiosophical world view about research, design and methods\n",
      "\n",
      "\n",
      "=== Strongly Typed ===\n",
      "Category: nan\n",
      "Sub Category: nan\n",
      "Definition: Restrict Operation you can perform based on Object Type Python is Strongly Typed\n",
      "\n",
      "\n",
      "=== Illusion of Asymmetric Insights ===\n",
      "Category: Behavioural Economics\n",
      "Sub Category: nan\n",
      "Definition: The Belief that we know others better than they know us and that we may have insights about them that they lack (but not vice versa). As explained by the fill in the blanks word game, the words don’t define me, yet they do define others. CIA Officers. Judges. \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pd.notna(row[\u001b[33m'\u001b[39m\u001b[33mLink\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m     57\u001b[39m         display(Markdown(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[More Info](\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mLink\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m DailyTest()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mDailyTest\u001b[39m\u001b[34m(questions, updates)\u001b[39m\n\u001b[32m     12\u001b[39m questions = df[df[\u001b[33m'\u001b[39m\u001b[33mDefinition\u001b[39m\u001b[33m'\u001b[39m].notnull()].sample(questions)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     display_term_latex_dynamic(questions.iloc[row])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mdisplay_term_latex_dynamic\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSub Category: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mSub Categorization\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDefinition: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mDefinition\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m time.sleep(\u001b[32m5\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pd.notna(row[\u001b[33m'\u001b[39m\u001b[33mMarkdown Equation\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m     39\u001b[39m     eq_text = row[\u001b[33m'\u001b[39m\u001b[33mMarkdown Equation\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Math\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def DailyTest(questions=20,updates=5):\n",
    "    \n",
    "    df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQq1-3cTas8DCWBa2NKYhVFXpl8kLaFDohg0zMfNTAU_Fiw6aIFLWfA5zRem4eSaGPa7UiQvkz05loW/pub?output=csv')\n",
    "    \n",
    "    updates = df[df['Definition'].isnull()].sample(updates)\n",
    "    print(updates['Word'].tolist())\n",
    "    \n",
    "    questions = df[df['Definition'].notnull()].sample(questions)\n",
    "    \n",
    "    for row in range(len(df)):\n",
    "        display_term_latex_dynamic(questions.iloc[row])\n",
    "\n",
    "def display_term_latex_dynamic(row):\n",
    "    '''\n",
    "    Function Created to Sample Data Dictionary Rows and present information in incremental Format\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "        Series\n",
    "        \n",
    "    Returns:\n",
    "        Nil\n",
    "    \n",
    "\n",
    "    '''\n",
    "    import time\n",
    "    \n",
    "    print(f\"\\n=== {row['Word']} ===\")\n",
    "    print(f\"Category: {row['Category']}\")\n",
    "    print(f\"Sub Category: {row['Sub Categorization']}\")\n",
    "    \n",
    "    print(f\"Definition: {row['Definition']}\\n\")\n",
    "    time.sleep(5)\n",
    "    if pd.notna(row['Markdown Equation']):\n",
    "        eq_text = row['Markdown Equation']\n",
    "        \n",
    "        # Extract equation\n",
    "        main_eq = re.search(r\"\\$\\$(.*?)\\$\\$\", eq_text, re.DOTALL)\n",
    "        if main_eq:\n",
    "            display(Markdown(\"**Equation:**\"))\n",
    "            display(Math(main_eq.group(1).strip()))\n",
    "        \n",
    "        # Extract \"where\" section\n",
    "        where_part = re.split(r\"\\bwhere:\\b\", eq_text, flags=re.IGNORECASE)\n",
    "        if len(where_part) > 1:\n",
    "            display(Markdown(\"**Where:**\"))\n",
    "            where_lines = where_part[1].strip().splitlines()\n",
    "            for line in where_lines:\n",
    "                cleaned = line.strip(\"-• \").strip()\n",
    "                if cleaned:\n",
    "                    display(Math(cleaned))\n",
    "    if pd.notna(row['Link']):\n",
    "        display(Markdown(f\"[More Info]({row['Link']})\"))\n",
    "\n",
    "\n",
    "DailyTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f57ec933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['True Negative', 'Kmeans can only do circular clusters because of centroids', 'Relu', 'Normal Distance', 'LightGBM']\n",
      "\n",
      "=== ElasticNet Regularization ===\n",
      "Category: Machine Learning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mD_Testing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DailyTest\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m DailyTest()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Python/Github_Repo/d_py_functions/D_Testing.py:15\u001b[39m, in \u001b[36mDailyTest\u001b[39m\u001b[34m(questions, updates)\u001b[39m\n\u001b[32m     12\u001b[39m questions = df[df[\u001b[33m'\u001b[39m\u001b[33mDefinition\u001b[39m\u001b[33m'\u001b[39m].notnull()].sample(questions)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     display_term_latex_dynamic(questions.iloc[row])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Python/Github_Repo/d_py_functions/D_Testing.py:32\u001b[39m, in \u001b[36mdisplay_term_latex_dynamic\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mWord\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCategory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mCategory\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28minput\u001b[39m()\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSub Category: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mSub Categorization\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28minput\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/D2/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1280\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._input_request(\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28mself\u001b[39m._parent_ident[\u001b[33m\"\u001b[39m\u001b[33mshell\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   1285\u001b[39m     \u001b[38;5;28mself\u001b[39m.get_parent(\u001b[33m\"\u001b[39m\u001b[33mshell\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1286\u001b[39m     password=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1287\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/D2/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1323\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1324\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1327\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from D_Testing import DailyTest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trends(data, id_column, time_columns):\n",
    "    \"\"\"\n",
    "    Calculate trends (slopes) for entities over time using linear regression.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input DataFrame containing entity IDs and time-based columns.\n",
    "        id_column (str): Column name for the unique entity identifier (e.g., member_id).\n",
    "        time_columns (list of str): List of column names representing the time periods (e.g., months).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing entity IDs, slopes, and trends.\n",
    "    \"\"\"\n",
    "    # Extract unique entity IDs and the time-series data\n",
    "    entity_ids = data[id_column].unique()\n",
    "    time_data = data[time_columns].values\n",
    "    \n",
    "    # Prepare the X (time) matrix\n",
    "    time_indices = np.arange(1, len(time_columns) + 1)  # Generate time indices\n",
    "    X = np.vstack([time_indices, np.ones(len(time_indices))]).T  # Add a bias term for the intercept\n",
    "\n",
    "    # Perform linear regression for all entities\n",
    "    slopes = np.linalg.lstsq(X, time_data.T, rcond=None)[0][0]  # Extract slopes\n",
    "    \n",
    "    # Prepare results DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        id_column: entity_ids,\n",
    "        \"slope\": slopes\n",
    "    })\n",
    "    \n",
    "    # Classify trends\n",
    "    results[\"trend\"] = np.where(\n",
    "        results[\"slope\"] > 0, \"increasing\",\n",
    "        np.where(results[\"slope\"] < 0, \"decreasing\", \"stable\")\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for model in models:\n",
    "    for metric in ['F1','AUC','Accuracy']:   \n",
    "        test_dict.setdefault('Top 5 Performing Models',{})[metric] = np.mean(value_list[:4])\n",
    "        test_dict.setdefault('Top Performing Model',{})[metric] = value_list[0]\n",
    "        test_dict.setdefault('All Models Mean',{})[metric] = np.mean(value_list)\n",
    "        \n",
    "        temp_df = pd.DataFrame(test_dict).T.reset_index().rename(columns={'index':'Type'})\n",
    "        temp_df['Observed Value'] = model\n",
    "    \n",
    "    final_df = pd.concat([final_df,temp_df])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638dc14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateMLModels(df,\n",
    "                     Features,\n",
    "                     Target,\n",
    "                     model_list,\n",
    "                     scaler_list,\n",
    "                     balance_list,\n",
    "                     log_max_it=1000,\n",
    "                     rf_estimators=50,\n",
    "                     include_narrative=0):\n",
    "    \n",
    "    model_dict = {}\n",
    "    final_result_df = pd.DataFrame()\n",
    "    \n",
    "    param_list = list(product(model_list,scaler_list,balance_list))\n",
    "    \n",
    "    for count,params in enumerate(param_list):\n",
    "        print(count,params)\n",
    "        \n",
    "        model = params[0]\n",
    "        scaler = params[1]\n",
    "        if params[2]!=0:\n",
    "            balance_target_observations = [1,params[2]]\n",
    "        else:\n",
    "            balance_target_observations = [0,0]\n",
    "        \n",
    "        run_dict,result = MLManualPipeline(df=df,\n",
    "                                           Features=Features,\n",
    "                                           Target=Target,\n",
    "                                           model=model,\n",
    "                                           scaler_=scaler,\n",
    "                                           balance_target_observations=balance_target_observations,\n",
    "                                           include_narrative=include_narrative,\n",
    "                                           rf_estimators=rf_estimators,\n",
    "                                           SequenceNumber=count,\n",
    "                                           log_max_it=log_max_it)\n",
    "        \n",
    "        model_dict[count] = run_dict\n",
    "        final_result_df = pd.concat([final_result_df,result])\n",
    "        \n",
    "    return model_dict,final_result_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ModelPerformanceByCategory(df,\n",
    "                               primary_key='SequenceNumber',\n",
    "                               ml_parameters=['Model','Scaler','Training Set Balance Perc'],\n",
    "                               observations=20,\n",
    "                               metrics=['AUC','F1','Accuracy']):\n",
    "    \n",
    "    # Create List of Models Based on Original Input Dataframe\n",
    "    models = list(df['Model'].unique())\n",
    "    \n",
    "    # Create Values for Particular Metric under review\n",
    "    for metric in metrics:\n",
    "        # Sort Value based on Metric\n",
    "        metric_df = df.sort_values(metric,ascending=False)\n",
    "        # Iterate through Categories as defined by Function\n",
    "        temp = pd.DataFrame()\n",
    "        for ml_ in ml_parameters:\n",
    "            _ = pd.DataFrame(metric_df[ml_].fillna(\"\").head(observations).value_counts()).reset_index().rename(columns={'index':'Observed Value',ml_:metric})\n",
    "            _['Type'] = ml_\n",
    "            \n",
    "            temp = pd.concat([temp,_])\n",
    "            \n",
    "        # Generate Metric Summary Value \n",
    "        # Create Segments\n",
    "        brackets_v3(metric_df,metric,f\"{metric}_segment\",[0,.25,.5,.6,.75,.9])\n",
    "        perc = pd.DataFrame(metric_df[f\"{metric}_segment\"].value_counts()).reset_index().rename(columns={'index':\"Observed Value\",f\"{metric}_segment\":metric})\n",
    "        perc['Type'] = 'Model Performance'\n",
    "        \n",
    "        temp = pd.concat([temp,perc[perc[metric]!=0]])\n",
    "        \n",
    "        try:\n",
    "            final_df = final_df.merge(temp,on=['Observed Value','Type'],how='outer')\n",
    "        except:\n",
    "            final_df = temp.copy()\n",
    "            \n",
    "        test_dict = {}\n",
    "        perf_df = pd.DataFrame()\n",
    "        for model in models:\n",
    "            for metric in ['F1','AUC','Accuracy']:\n",
    "        \n",
    "                value_list = df[df['Model']==model].sort_values(metric,ascending=False)[metric].tolist()\n",
    "                test_dict.setdefault('Model Best Five',{})[metric] = np.mean(value_list[:4])\n",
    "                test_dict.setdefault('Model Best Performing',{})[metric] = value_list[0]\n",
    "                test_dict.setdefault('Model Mean Performance',{})[metric] = np.mean(value_list)\n",
    "\n",
    "                temp_df = pd.DataFrame(test_dict).T.reset_index().rename(columns={'index':'Type'})\n",
    "                temp_df['Observed Value'] = model\n",
    "            \n",
    "            perf_df = pd.concat([perf_df,temp_df])\n",
    "\n",
    "    return pd.concat([final_df,perf_df]).sort_values(['Type',metrics[0]],ascending=[True,False]).set_index(['Observed Value','Type']).fillna(0)\n",
    "    \n",
    "\n",
    "\n",
    "def MLManualPipeline(df,\n",
    "                     Features,\n",
    "                     Target,\n",
    "                     model,\n",
    "                     balance_target_observations=[0,.25],\n",
    "                     scaler_=None,\n",
    "                     test_size=.3,\n",
    "                     random_state=42,\n",
    "                     include_narrative=1,\n",
    "                     rf_estimators=50,\n",
    "                     log_max_it=100,\n",
    "                     SequenceNumber=0,\n",
    "                     time_model=1,\n",
    "                     xgb_objective='binary:logistic',\n",
    "                     xgb_eval_metric='logloss'):\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "        \n",
    "    generated_models = {}\n",
    "    \n",
    "    # Create Copy to ensure original data is not altered\n",
    "    df = df.copy()\n",
    "\n",
    "    if balance_target_observations[0]==1:\n",
    "        df = BalanceTargetDistribution(df=df,\n",
    "                                       Target=Target,\n",
    "                                       desired_percentage=balance_target_observations[1])\n",
    "        balance_target_observations = f'{balance_target_observations[1]}'\n",
    "    else:\n",
    "        balance_target_observations = '0'\n",
    "        \n",
    "    # If features not specified, entire Dataset to be processed (less Target), otherwise include only features\n",
    "    if len(Features) == 0:\n",
    "        Features = list(df.drop(Target,axis=1).columns)\n",
    "        X = np.array(df[Features].copy())\n",
    "        df_len = len(df)\n",
    "        feature_count = len(X[0])\n",
    "    else:\n",
    "        X = np.array(df[Features])\n",
    "        df_len = len(df)\n",
    "        feature_count = len(X[0])\n",
    "        \n",
    "    # Create Target Array - Target already provided as a List\n",
    "    y = np.array(df[Target].squeeze())\n",
    "    target_vc = df[Target].value_counts()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    if scaler_ in scaler_dict.keys():\n",
    "        scaler = scaler_dict[scaler_]\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        x_test = scaler.transform(X_test)\n",
    "    else:\n",
    "        scaler = None\n",
    "        \n",
    "    if include_narrative==1:\n",
    "        print(f\"Total Number of Records in Dataset: {df_len}\\ntotal features: {feature_count}\\nTarget Distribution:\\n{target_vc}\\n\")\n",
    "        print(f\"Training Data Set:\\nTraining Features:{len(X_train)}, Training Target:{len(y_train)}\\nTraining Target Distribution:\\n{pd.DataFrame(y_train).value_counts()}\\n\")\n",
    "        print(f\"Testing Data Set:\\nTest Features:{len(X_test)}, Test Target:{len(y_test)}Training Target Distribution:\\n{pd.DataFrame(y_test).value_counts()}\\n\")\n",
    "        \n",
    "    if model=='Logistic Regression':\n",
    "        \n",
    "        # Create Model\n",
    "        logreg=LogisticRegression(max_iter=log_max_it)\n",
    "        \n",
    "        # Train Model\n",
    "        logreg.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on Text\n",
    "        y_pred = logreg.predict(X_test)\n",
    "        \n",
    "        # Generate Test DataFrame\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        \n",
    "        # Create Feature Importance DataFrame\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':np.abs(logreg.coef_[0]),}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        # Generate Results and Dataframe\n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        \n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':logreg,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "        try:\n",
    "            # Generate a Balanced Variant of the Logistic Regression Where \n",
    "            perc_dist = len(df[df[Target]==0])/len(df)\n",
    "            if perc_dist>.6:\n",
    "                lr0=LogisticRegression(max_iter=log_max_it,class_weight='balanced')\n",
    "                lr0.fit(X_train, y_train)\n",
    "                y_pred_rf = lr0.predict(X_test)\n",
    "                result_df = pd.concat([pd.DataFrame(y_pred_rf,columns=['PREDICTION']),\n",
    "                                       pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "                feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                                   'IMPORTANCE':rf.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "                result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                               model='Logistic Regression - Balanced',\n",
    "                                                               scaler=scaler_,\n",
    "                                                               balance=balance_target_observations,\n",
    "                                                               sequence_num=SequenceNumber+1000000)\n",
    "                stop_time = timeit.default_timer() - start_time\n",
    "                performance['RunTime'] = stop_time\n",
    "                generated_models[SequenceNumber+1000000] = {'ModelType':'Logistic Regression - Balanced',\n",
    "                                                        'Model':lr0,\n",
    "                                                        'Scaler':scaler,\n",
    "                                                        'FeatureImportance':feature_importance,\n",
    "                                                        'BinaryResultDF':result_df,\n",
    "                                                        'ModelPerformance':performance}\n",
    "        except:\n",
    "            print('Attempted to Review Random Forrest - Balanced, could not')\n",
    "\n",
    "    elif model =='Decision Tree':    \n",
    "        ############################################ ESTIMATORS\n",
    "        dt = DecisionTreeClassifier(random_state=random_state)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred_dt = dt.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_dt,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':dt.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        \n",
    "        \n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':dt,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "\n",
    "    elif model =='Random Forest':    \n",
    "        ############################################ ESTIMATORS\n",
    "        rf = RandomForestClassifier(random_state=random_state, n_estimators=rf_estimators)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred_rf = rf.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_rf,columns=['PREDICTION']),\n",
    "                               pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':rf.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':rf,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "        try:\n",
    "            # Generate a Balanced Variant of the Random Forest Where \n",
    "            perc_dist = len(df[df[Target]==0])/len(df)\n",
    "            if perc_dist>.6:\n",
    "                rf0 = RandomForestClassifier(random_state=random_state, n_estimators=rf_estimators,class_weight='balanced')\n",
    "                rf0.fit(X_train, y_train)\n",
    "                y_pred_rf = rf0.predict(X_test)\n",
    "                result_df = pd.concat([pd.DataFrame(y_pred_rf,columns=['PREDICTION']),\n",
    "                                       pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "                feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                                   'IMPORTANCE':rf.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "                result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                               model='Random Forest - Balanced',\n",
    "                                                               scaler=scaler_,\n",
    "                                                               balance=balance_target_observations,\n",
    "                                                               sequence_num=SequenceNumber+1000000)\n",
    "                stop_time = timeit.default_timer() - start_time\n",
    "                performance['RunTime'] = stop_time\n",
    "                generated_models[SequenceNumber+1000000] = {'ModelType':'Random Forest - Balanced',\n",
    "                                                        'Model':rf0,\n",
    "                                                        'Scaler':scaler,\n",
    "                                                        'FeatureImportance':feature_importance,\n",
    "                                                        'BinaryResultDF':result_df,\n",
    "                                                        'ModelPerformance':performance}\n",
    "        except:\n",
    "            print('Attempted to Review Random Forrest - Balanced, could not')\n",
    "                \n",
    "    elif model == 'Gradient Boosting':\n",
    "        gb = GradientBoostingClassifier()\n",
    "        gb.fit(X_train, y_train)\n",
    "        y_pred_gb = gb.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_gb,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':gb.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':gb,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "    elif model == 'Ada':\n",
    "        ada = AdaBoostClassifier()\n",
    "        ada.fit(X_train, y_train)\n",
    "        y_pred_ada = ada.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_ada,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':ada.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':ada,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "    elif model == 'Extra Tree':\n",
    "        et = ExtraTreesClassifier()\n",
    "        et.fit(X_train, y_train)\n",
    "        y_pred_et = et.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_et,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':et.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':et,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "    elif model == 'XGBoost':\n",
    "        xgb_ = xgb.XGBClassifier(objective=xgb_objective,\n",
    "                                eval_metric=xgb_eval_metric,\n",
    "                                use_label_encoder=False,\n",
    "                                random_state=random_state)\n",
    "        xgb_.fit(X_train, y_train)\n",
    "        y_pred_et = xgb_.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_et,columns=['PREDICTION']),\n",
    "                               pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':xgb_.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        \n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':xgb,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}    \n",
    "    else:\n",
    "        print('Model Not Defined, please update function')\n",
    "        \n",
    "    performance_metrics = pd.DataFrame()\n",
    "    for key in generated_models.keys():\n",
    "        performance_metrics = pd.concat([performance_metrics,generated_models[key]['ModelPerformance']])\n",
    "        \n",
    "    return generated_models,performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71228ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(X,\n",
    "                y,\n",
    "                input_dim,\n",
    "                metrics,\n",
    "                hidden_layer_sizes,\n",
    "                activation, \n",
    "                optimizer,\n",
    "                learning_rate,\n",
    "                batch_size,\n",
    "                num_epochs,\n",
    "                validation_split,\n",
    "                verbose=0):\n",
    "                       \n",
    "\n",
    "    # Build the model.\n",
    "    model = build_binary_classification_model(input_dim=input_dim,\n",
    "                                              hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                              activation=activation, \n",
    "                                              optimizer=optimizer,\n",
    "                                              learning_rate=learning_rate,\n",
    "                                              metrics=metrics)\n",
    "    \n",
    "    print(model.summary())     \n",
    "                        \n",
    "    # Train the model.\n",
    "    history = model.fit(x=X,\n",
    "                        y=y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        validation_split=validation_split,\n",
    "                        verbose=verbose)\n",
    "\n",
    "    # Retrieve the training metrics (after each train epoch) and the final test\n",
    "    # accuracy.\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(train_accuracy, label='train_accuracy')\n",
    "    plt.plot(val_accuracy, label='validation accuracy')\n",
    "    plt.xticks(range(num_epochs))\n",
    "    plt.xlabel('Train epochs')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    return history,model\n",
    "\n",
    "    \n",
    "def neural_network(X_df,\n",
    "                   y_df,\n",
    "                   input_dim, \n",
    "                   hidden_layer_sizes,\n",
    "                   activation,\n",
    "                   optimizer,\n",
    "                   learning_rate,\n",
    "                   metrics,\n",
    "                   verbose=0):\n",
    "\n",
    "    \"\"\"Build a binary classification model using Keras.\n",
    "\n",
    "      Args:\n",
    "        input_dim: Number of features in the input data.\n",
    "        hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "        activation: The activation function to use for the hidden layers.\n",
    "        optimizer: The optimizer\n",
    "        learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "      Returns:\n",
    "        model: A tf.keras model.\n",
    "    \"\"\"\n",
    "    # Instantiate Model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    # Add Input Layer\n",
    "    model.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "\n",
    "    # Add Hidden Layers\n",
    "    for nodes in hidden_layer_sizes:\n",
    "        model.add(layers.Dense(units=nodes, activation=activation))\n",
    "\n",
    "    # Add Output Layer\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Configure optimizer and compile the model\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
