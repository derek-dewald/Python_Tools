{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b24421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16789660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Connections import GoogleProcessSheetLinks\n",
    "\n",
    "GoogleProcessSheetLinks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e2055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DFProcessing import DataFrameColumnObservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4294fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f16d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da995e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataSets import GenerateFakeMemberDF\n",
    "\n",
    "df = GenerateFakeMemberDF(10000,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce9bcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEMBERNBR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>OUTLOOK</th>\n",
       "      <th>DEPOSIT</th>\n",
       "      <th>LENDING</th>\n",
       "      <th>TXN_COUNT</th>\n",
       "      <th>TXN_VALUE</th>\n",
       "      <th>ACTIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Baller</td>\n",
       "      <td>1</td>\n",
       "      <td>319209</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>240996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Broke</td>\n",
       "      <td>-1</td>\n",
       "      <td>1773</td>\n",
       "      <td>741464</td>\n",
       "      <td>11</td>\n",
       "      <td>1760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Borrower</td>\n",
       "      <td>0</td>\n",
       "      <td>2866</td>\n",
       "      <td>593348</td>\n",
       "      <td>3</td>\n",
       "      <td>351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>2</td>\n",
       "      <td>542898</td>\n",
       "      <td>202116</td>\n",
       "      <td>76</td>\n",
       "      <td>5700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1</td>\n",
       "      <td>919273</td>\n",
       "      <td>5000</td>\n",
       "      <td>9</td>\n",
       "      <td>3654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MEMBERNBR  MONTH CLASSIFICATION  OUTLOOK  DEPOSIT  LENDING  TXN_COUNT  \\\n",
       "0          0      0         Baller        1   319209        0         28   \n",
       "1          1      0          Broke       -1     1773   741464         11   \n",
       "2          2      0       Borrower        0     2866   593348          3   \n",
       "3          3      0   Full_Service        2   542898   202116         76   \n",
       "4          4      0           Norm        1   919273     5000          9   \n",
       "\n",
       "   TXN_VALUE  ACTIVE  \n",
       "0     240996       1  \n",
       "1       1760       1  \n",
       "2        351       1  \n",
       "3       5700       1  \n",
       "4       3654       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656266f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MONTH</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMBERNBR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>319209.0</td>\n",
       "      <td>333010.0</td>\n",
       "      <td>361239.0</td>\n",
       "      <td>376177.0</td>\n",
       "      <td>416083.0</td>\n",
       "      <td>435820.0</td>\n",
       "      <td>481473.0</td>\n",
       "      <td>526666.0</td>\n",
       "      <td>586733.0</td>\n",
       "      <td>590696.0</td>\n",
       "      <td>631445.0</td>\n",
       "      <td>694856.0</td>\n",
       "      <td>777695.0</td>\n",
       "      <td>891676.0</td>\n",
       "      <td>934344.0</td>\n",
       "      <td>1025183.0</td>\n",
       "      <td>1106759.0</td>\n",
       "      <td>1127271.0</td>\n",
       "      <td>1164414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1773.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2866.0</td>\n",
       "      <td>2813.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>2925.0</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>2904.0</td>\n",
       "      <td>2892.0</td>\n",
       "      <td>2944.0</td>\n",
       "      <td>2963.0</td>\n",
       "      <td>2970.0</td>\n",
       "      <td>3012.0</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>2977.0</td>\n",
       "      <td>2901.0</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>2754.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>2762.0</td>\n",
       "      <td>2659.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>542898.0</td>\n",
       "      <td>627636.0</td>\n",
       "      <td>736594.0</td>\n",
       "      <td>928534.0</td>\n",
       "      <td>1198377.0</td>\n",
       "      <td>1532637.0</td>\n",
       "      <td>1895119.0</td>\n",
       "      <td>2460235.0</td>\n",
       "      <td>2989497.0</td>\n",
       "      <td>3618772.0</td>\n",
       "      <td>4266283.0</td>\n",
       "      <td>4964883.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>919273.0</td>\n",
       "      <td>1016700.0</td>\n",
       "      <td>1129557.0</td>\n",
       "      <td>1276652.0</td>\n",
       "      <td>1294702.0</td>\n",
       "      <td>1483313.0</td>\n",
       "      <td>1636933.0</td>\n",
       "      <td>1803160.0</td>\n",
       "      <td>1971507.0</td>\n",
       "      <td>2236550.0</td>\n",
       "      <td>2483608.0</td>\n",
       "      <td>2558747.0</td>\n",
       "      <td>2647586.0</td>\n",
       "      <td>2674487.0</td>\n",
       "      <td>2971157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14526</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14527</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>436969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14528</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14529</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14530</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>437088.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14531 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "MONTH            0          1          2          3          4          5   \\\n",
       "MEMBERNBR                                                                    \n",
       "0          319209.0   333010.0   361239.0   376177.0   416083.0   435820.0   \n",
       "1            1773.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2            2866.0     2813.0     2800.0     2925.0     2989.0     2904.0   \n",
       "3          542898.0   627636.0   736594.0   928534.0  1198377.0  1532637.0   \n",
       "4          919273.0  1016700.0  1129557.0  1276652.0  1294702.0  1483313.0   \n",
       "...             ...        ...        ...        ...        ...        ...   \n",
       "14526           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14527           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14528           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14529           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14530           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "MONTH             6          7          8          9          10         11  \\\n",
       "MEMBERNBR                                                                     \n",
       "0           481473.0   526666.0   586733.0   590696.0   631445.0   694856.0   \n",
       "1                0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2             2892.0     2944.0     2963.0     2970.0     3012.0     2940.0   \n",
       "3          1895119.0  2460235.0  2989497.0  3618772.0  4266283.0  4964883.0   \n",
       "4          1636933.0  1803160.0  1971507.0  2236550.0  2483608.0  2558747.0   \n",
       "...              ...        ...        ...        ...        ...        ...   \n",
       "14526            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14527            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14528            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14529            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14530            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "MONTH             12         13         14         15         16         17  \\\n",
       "MEMBERNBR                                                                     \n",
       "0           777695.0   891676.0   934344.0  1025183.0  1106759.0  1127271.0   \n",
       "1                0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2             2977.0     2901.0     2860.0     2754.0     2755.0     2762.0   \n",
       "3                0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4          2647586.0  2674487.0  2971157.0        0.0        0.0        0.0   \n",
       "...              ...        ...        ...        ...        ...        ...   \n",
       "14526            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14527            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14528            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14529            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "14530            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "MONTH             18  \n",
       "MEMBERNBR             \n",
       "0          1164414.0  \n",
       "1                0.0  \n",
       "2             2659.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "14526         3997.0  \n",
       "14527       436969.0  \n",
       "14528        43317.0  \n",
       "14529        42121.0  \n",
       "14530       437088.0  \n",
       "\n",
       "[14531 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index='MEMBERNBR',columns='MONTH',values='DEPOSIT',aggfunc='sum').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "5cd13472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEMBERNBR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>OUTLOOK</th>\n",
       "      <th>DEPOSIT</th>\n",
       "      <th>LENDING</th>\n",
       "      <th>TXN_COUNT</th>\n",
       "      <th>TXN_VALUE</th>\n",
       "      <th>ACTIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>4672</td>\n",
       "      <td>614655</td>\n",
       "      <td>13</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>4834</td>\n",
       "      <td>692052</td>\n",
       "      <td>14</td>\n",
       "      <td>2278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>5410</td>\n",
       "      <td>759629</td>\n",
       "      <td>14</td>\n",
       "      <td>2615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32529</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>5840</td>\n",
       "      <td>833346</td>\n",
       "      <td>14</td>\n",
       "      <td>2742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44709</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>6295</td>\n",
       "      <td>855917</td>\n",
       "      <td>14</td>\n",
       "      <td>2963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57373</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>6687</td>\n",
       "      <td>868845</td>\n",
       "      <td>15</td>\n",
       "      <td>3065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70227</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>6969</td>\n",
       "      <td>975638</td>\n",
       "      <td>16</td>\n",
       "      <td>3388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83593</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>7418</td>\n",
       "      <td>1046786</td>\n",
       "      <td>17</td>\n",
       "      <td>3749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97048</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>8288</td>\n",
       "      <td>1121946</td>\n",
       "      <td>17</td>\n",
       "      <td>4038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110652</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>8857</td>\n",
       "      <td>1142790</td>\n",
       "      <td>19</td>\n",
       "      <td>4340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124985</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>9774</td>\n",
       "      <td>1181089</td>\n",
       "      <td>19</td>\n",
       "      <td>4486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139629</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>10541</td>\n",
       "      <td>1227333</td>\n",
       "      <td>19</td>\n",
       "      <td>4967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155238</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>11390</td>\n",
       "      <td>1241438</td>\n",
       "      <td>19</td>\n",
       "      <td>5569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171738</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>11513</td>\n",
       "      <td>1263801</td>\n",
       "      <td>21</td>\n",
       "      <td>6277</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188256</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>11717</td>\n",
       "      <td>1344804</td>\n",
       "      <td>21</td>\n",
       "      <td>6317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205254</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>11916</td>\n",
       "      <td>1392299</td>\n",
       "      <td>22</td>\n",
       "      <td>6488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222259</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>12383</td>\n",
       "      <td>1410364</td>\n",
       "      <td>23</td>\n",
       "      <td>6656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239959</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>13300</td>\n",
       "      <td>1522101</td>\n",
       "      <td>24</td>\n",
       "      <td>7462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258432</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>Broke</td>\n",
       "      <td>1</td>\n",
       "      <td>14057</td>\n",
       "      <td>1630072</td>\n",
       "      <td>24</td>\n",
       "      <td>8257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MEMBERNBR  MONTH CLASSIFICATION  OUTLOOK  DEPOSIT  LENDING  TXN_COUNT  \\\n",
       "9               9      1          Broke        1     4672   614655         13   \n",
       "10009           9      1          Broke        1     4834   692052         14   \n",
       "20997           9      2          Broke        1     5410   759629         14   \n",
       "32529           9      3          Broke        1     5840   833346         14   \n",
       "44709           9      4          Broke        1     6295   855917         14   \n",
       "57373           9      5          Broke        1     6687   868845         15   \n",
       "70227           9      6          Broke        1     6969   975638         16   \n",
       "83593           9      7          Broke        1     7418  1046786         17   \n",
       "97048           9      8          Broke        1     8288  1121946         17   \n",
       "110652          9      9          Broke        1     8857  1142790         19   \n",
       "124985          9     10          Broke        1     9774  1181089         19   \n",
       "139629          9     11          Broke        1    10541  1227333         19   \n",
       "155238          9     12          Broke        1    11390  1241438         19   \n",
       "171738          9     13          Broke        1    11513  1263801         21   \n",
       "188256          9     14          Broke        1    11717  1344804         21   \n",
       "205254          9     15          Broke        1    11916  1392299         22   \n",
       "222259          9     16          Broke        1    12383  1410364         23   \n",
       "239959          9     17          Broke        1    13300  1522101         24   \n",
       "258432          9     18          Broke        1    14057  1630072         24   \n",
       "\n",
       "        TXN_VALUE  ACTIVE  \n",
       "9            2002       1  \n",
       "10009        2278       1  \n",
       "20997        2615       1  \n",
       "32529        2742       1  \n",
       "44709        2963       1  \n",
       "57373        3065       1  \n",
       "70227        3388       1  \n",
       "83593        3749       1  \n",
       "97048        4038       1  \n",
       "110652       4340       1  \n",
       "124985       4486       1  \n",
       "139629       4967       1  \n",
       "155238       5569       1  \n",
       "171738       6277       1  \n",
       "188256       6317       1  \n",
       "205254       6488       1  \n",
       "222259       6656       1  \n",
       "239959       7462       1  \n",
       "258432       8257       1  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['MEMBERNBR']==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "8911fd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEMBERNBR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>OUTLOOK</th>\n",
       "      <th>DEPOSIT</th>\n",
       "      <th>LENDING</th>\n",
       "      <th>TXN_COUNT</th>\n",
       "      <th>TXN_VALUE</th>\n",
       "      <th>ACTIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>779930</td>\n",
       "      <td>135462</td>\n",
       "      <td>65</td>\n",
       "      <td>112710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20992</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32524</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44704</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57368</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70222</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83588</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97043</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110647</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124980</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139624</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155233</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171733</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188251</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205249</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222254</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239954</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258427</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>Full_Service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MEMBERNBR  MONTH CLASSIFICATION  OUTLOOK  DEPOSIT  LENDING  TXN_COUNT  \\\n",
       "4               4      1   Full_Service        0   779930   135462         65   \n",
       "10004           4      1   Full_Service        0        0        0          0   \n",
       "20992           4      2   Full_Service        0        0        0          0   \n",
       "32524           4      3   Full_Service        0        0        0          0   \n",
       "44704           4      4   Full_Service        0        0        0          0   \n",
       "57368           4      5   Full_Service        0        0        0          0   \n",
       "70222           4      6   Full_Service        0        0        0          0   \n",
       "83588           4      7   Full_Service        0        0        0          0   \n",
       "97043           4      8   Full_Service        0        0        0          0   \n",
       "110647          4      9   Full_Service        0        0        0          0   \n",
       "124980          4     10   Full_Service        0        0        0          0   \n",
       "139624          4     11   Full_Service        0        0        0          0   \n",
       "155233          4     12   Full_Service        0        0        0          0   \n",
       "171733          4     13   Full_Service        0        0        0          0   \n",
       "188251          4     14   Full_Service        0        0        0          0   \n",
       "205249          4     15   Full_Service        0        0        0          0   \n",
       "222254          4     16   Full_Service        0        0        0          0   \n",
       "239954          4     17   Full_Service        0        0        0          0   \n",
       "258427          4     18   Full_Service        0        0        0          0   \n",
       "\n",
       "        TXN_VALUE  ACTIVE  \n",
       "4          112710       1  \n",
       "10004           0       0  \n",
       "20992           0       0  \n",
       "32524           0       0  \n",
       "44704           0       0  \n",
       "57368           0       0  \n",
       "70222           0       0  \n",
       "83588           0       0  \n",
       "97043           0       0  \n",
       "110647          0       0  \n",
       "124980          0       0  \n",
       "139624          0       0  \n",
       "155233          0       0  \n",
       "171733          0       0  \n",
       "188251          0       0  \n",
       "205249          0       0  \n",
       "222254          0       0  \n",
       "239954          0       0  \n",
       "258427          0       0  "
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['MEMBERNBR']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e327b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7499643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137b83df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ec933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from D_Testing import DailyTest\n",
    "\n",
    "DailyTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import all_estimators\n",
    "import mlflow\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "dddd\n",
    "\n",
    "\n",
    "# ML Pipeline Function\n",
    "def MLPipeline(df, project_name, scaler=None, ml_model_type='regressor', target_column='Target', test_size=0.2):\n",
    "    mlflow.set_experiment(project_name)\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_train, X_test = apply_scaling(X_train, X_test, scaler=scaler)\n",
    "\n",
    "    model_list = all_estimators(type_filter=ml_model_type)\n",
    "    results = []\n",
    "\n",
    "    for name, model_class in model_list:\n",
    "        try:\n",
    "            model = model_class()\n",
    "            start_time = time.time()\n",
    "\n",
    "            with mlflow.start_run(run_name=name):\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                if ml_model_type == \"classifier\":\n",
    "                    metric = accuracy_score(y_test, y_pred)\n",
    "                    mlflow.log_metric(\"Accuracy\", metric)\n",
    "                else:\n",
    "                    # Compute RMSE manually (fix for 'squared' error)\n",
    "                    metric = mean_squared_error(y_test, y_pred) ** 0.5  \n",
    "                    mlflow.log_metric(\"RMSE\", metric)\n",
    "\n",
    "                mlflow.sklearn.log_model(model, name)\n",
    "                mlflow.log_param(\"Model\", name)\n",
    "                mlflow.log_param(\"Training Time\", round(time.time() - start_time, 2))\n",
    "\n",
    "                results.append({\n",
    "                    \"Model\": name,\n",
    "                    \"Metric\": metric,\n",
    "                    \"Time (s)\": round(time.time() - start_time, 2)\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ {name} failed: {str(e)}\")  # Handle model failures but continue\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(by=\"Metric\", ascending=(ml_model_type == \"regressor\"))\n",
    "\n",
    "    # Display DataFrame\n",
    "    import ace_tools as tools\n",
    "    tools.display_dataframe_to_user(name=\"ML Model Performance\", dataframe=results_df)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def calculate_trends(data, id_column, time_columns):\n",
    "    \"\"\"\n",
    "    Calculate trends (slopes) for entities over time using linear regression.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input DataFrame containing entity IDs and time-based columns.\n",
    "        id_column (str): Column name for the unique entity identifier (e.g., member_id).\n",
    "        time_columns (list of str): List of column names representing the time periods (e.g., months).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing entity IDs, slopes, and trends.\n",
    "    \"\"\"\n",
    "    # Extract unique entity IDs and the time-series data\n",
    "    entity_ids = data[id_column].unique()\n",
    "    time_data = data[time_columns].values\n",
    "    \n",
    "    # Prepare the X (time) matrix\n",
    "    time_indices = np.arange(1, len(time_columns) + 1)  # Generate time indices\n",
    "    X = np.vstack([time_indices, np.ones(len(time_indices))]).T  # Add a bias term for the intercept\n",
    "\n",
    "    # Perform linear regression for all entities\n",
    "    slopes = np.linalg.lstsq(X, time_data.T, rcond=None)[0][0]  # Extract slopes\n",
    "    \n",
    "    # Prepare results DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        id_column: entity_ids,\n",
    "        \"slope\": slopes\n",
    "    })\n",
    "    \n",
    "    # Classify trends\n",
    "    results[\"trend\"] = np.where(\n",
    "        results[\"slope\"] > 0, \"increasing\",\n",
    "        np.where(results[\"slope\"] < 0, \"decreasing\", \"stable\")\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for model in models:\n",
    "    for metric in ['F1','AUC','Accuracy']:   \n",
    "        test_dict.setdefault('Top 5 Performing Models',{})[metric] = np.mean(value_list[:4])\n",
    "        test_dict.setdefault('Top Performing Model',{})[metric] = value_list[0]\n",
    "        test_dict.setdefault('All Models Mean',{})[metric] = np.mean(value_list)\n",
    "        \n",
    "        temp_df = pd.DataFrame(test_dict).T.reset_index().rename(columns={'index':'Type'})\n",
    "        temp_df['Observed Value'] = model\n",
    "    \n",
    "    final_df = pd.concat([final_df,temp_df])\n",
    "\n",
    "\n",
    "    'Extra Tree': {\n",
    "        'Type': 'Ensemble',\n",
    "        'Description': 'Similar to Random Forest but selects splits randomly rather than optimizing them.',\n",
    "        'UseCase': [\"Classification\", \"Regression\"],\n",
    "        'ModelStrengths': \"Reduces overfitting further, computationally efficient compared to Random Forest.\",\n",
    "        'Model Weaknesses': \"Slightly less accurate in some cases, still computationally heavy.\",\n",
    "        'lowerbound_feature_threshold':.05,\n",
    "        'upperbound_feature_threshold':.1,\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'SKlearn': ExtraTreesClassifier(random_state=random_state)\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'Type': 'Ensemble',\n",
    "        'Description': 'Builds models sequentially, correcting errors from previous models in an additive fashion.',\n",
    "        'UseCase': [\"Classification\", \"Regression\"],\n",
    "        'ModelStrengths': \"Highly accurate, handles non-linear relationships well.\",\n",
    "        'Model Weaknesses': \"Sensitive to hyperparameters, prone to overfitting on noisy data.\",\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'lowerbound_feature_threshold':.05,\n",
    "        'upperbound_feature_threshold':.1,\n",
    "        'SKlearn': GradientBoostingClassifier(random_state=random_state)\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'Type': 'Ensemble',\n",
    "        'Description': 'An optimized gradient boosting model with regularization to prevent overfitting.',\n",
    "        'UseCase': [\"Classification\", \"Regression\"],\n",
    "        'ModelStrengths': \"Fast, scalable, handles sparse data, regularization prevents overfitting.\",\n",
    "        'Model Weaknesses': \"Requires careful tuning of hyperparameters, computationally expensive.\",\n",
    "        'lowerbound_feature_threshold':.05,\n",
    "        'upperbound_feature_threshold':.1,\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'SKlearn': xgb.XGBClassifier(objective=xgb_objective, eval_metric=xgb_eval_metric, use_label_encoder=False, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd38665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Connections import ParamterMapping\n",
    "\n",
    "dd = pd.read_csv(ParamterMapping('DataDashboardSheet')['CSV'].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "328f9c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub Categorization</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Link</th>\n",
       "      <th>Image</th>\n",
       "      <th>Markdown Equation</th>\n",
       "      <th>Is Model</th>\n",
       "      <th>Learning Type</th>\n",
       "      <th>Algorithm Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>Number of correctly classified examples divide...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$$ Accuracy = \\frac{TP + TN}{TP + TN + FP + FN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F1 is harmonic mean is a type of average that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Precision</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>Precision is the ratio of correct positive pre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$$ P = \\frac{TP}{TP + FP} $$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Recall</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Evaluation</td>\n",
       "      <td>Recall is the correct positive predicitions to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$$ R = \\frac{TP}{TP + FN} $$</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word          Category Sub Categorization  \\\n",
       "0     Accuracy  Machine Learning         Evaluation   \n",
       "118   F1 Score  Machine Learning                NaN   \n",
       "248  Precision  Machine Learning         Evaluation   \n",
       "269     Recall  Machine Learning         Evaluation   \n",
       "\n",
       "                                            Definition Notes Link Image  \\\n",
       "0    Number of correctly classified examples divide...   NaN  NaN   NaN   \n",
       "118  F1 is harmonic mean is a type of average that ...   NaN  NaN   NaN   \n",
       "248  Precision is the ratio of correct positive pre...   NaN  NaN   NaN   \n",
       "269  Recall is the correct positive predicitions to...   NaN  NaN   NaN   \n",
       "\n",
       "                                     Markdown Equation  Is Model  \\\n",
       "0    $$ Accuracy = \\frac{TP + TN}{TP + TN + FP + FN...       NaN   \n",
       "118                                                NaN       NaN   \n",
       "248                       $$ P = \\frac{TP}{TP + FP} $$       NaN   \n",
       "269                       $$ R = \\frac{TP}{TP + FN} $$       NaN   \n",
       "\n",
       "    Learning Type Algorithm Class  \n",
       "0             NaN             NaN  \n",
       "118           NaN             NaN  \n",
       "248           NaN             NaN  \n",
       "269           NaN             NaN  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd[dd['Word'].isin(['Accuracy','Precision','Recall','F1 Score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638dc14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateMLModels(df,\n",
    "                     Features,\n",
    "                     Target,\n",
    "                     model_list,\n",
    "                     scaler_list,\n",
    "                     balance_list,\n",
    "                     log_max_it=1000,\n",
    "                     rf_estimators=50,\n",
    "                     include_narrative=0):\n",
    "    \n",
    "    model_dict = {}\n",
    "    final_result_df = pd.DataFrame()\n",
    "    \n",
    "    param_list = list(product(model_list,scaler_list,balance_list))\n",
    "    \n",
    "    for count,params in enumerate(param_list):\n",
    "        print(count,params)\n",
    "        \n",
    "        model = params[0]\n",
    "        scaler = params[1]\n",
    "        if params[2]!=0:\n",
    "            balance_target_observations = [1,params[2]]\n",
    "        else:\n",
    "            balance_target_observations = [0,0]\n",
    "        \n",
    "        run_dict,result = MLManualPipeline(df=df,\n",
    "                                           Features=Features,\n",
    "                                           Target=Target,\n",
    "                                           model=model,\n",
    "                                           scaler_=scaler,\n",
    "                                           balance_target_observations=balance_target_observations,\n",
    "                                           include_narrative=include_narrative,\n",
    "                                           rf_estimators=rf_estimators,\n",
    "                                           SequenceNumber=count,\n",
    "                                           log_max_it=log_max_it)\n",
    "        \n",
    "        model_dict[count] = run_dict\n",
    "        final_result_df = pd.concat([final_result_df,result])\n",
    "        \n",
    "    return model_dict,final_result_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ModelPerformanceByCategory(df,\n",
    "                               primary_key='SequenceNumber',\n",
    "                               ml_parameters=['Model','Scaler','Training Set Balance Perc'],\n",
    "                               observations=20,\n",
    "                               metrics=['AUC','F1','Accuracy']):\n",
    "    \n",
    "    # Create List of Models Based on Original Input Dataframe\n",
    "    models = list(df['Model'].unique())\n",
    "    \n",
    "    # Create Values for Particular Metric under review\n",
    "    for metric in metrics:\n",
    "        # Sort Value based on Metric\n",
    "        metric_df = df.sort_values(metric,ascending=False)\n",
    "        # Iterate through Categories as defined by Function\n",
    "        temp = pd.DataFrame()\n",
    "        for ml_ in ml_parameters:\n",
    "            _ = pd.DataFrame(metric_df[ml_].fillna(\"\").head(observations).value_counts()).reset_index().rename(columns={'index':'Observed Value',ml_:metric})\n",
    "            _['Type'] = ml_\n",
    "            \n",
    "            temp = pd.concat([temp,_])\n",
    "            \n",
    "        # Generate Metric Summary Value \n",
    "        # Create Segments\n",
    "        brackets_v3(metric_df,metric,f\"{metric}_segment\",[0,.25,.5,.6,.75,.9])\n",
    "        perc = pd.DataFrame(metric_df[f\"{metric}_segment\"].value_counts()).reset_index().rename(columns={'index':\"Observed Value\",f\"{metric}_segment\":metric})\n",
    "        perc['Type'] = 'Model Performance'\n",
    "        \n",
    "        temp = pd.concat([temp,perc[perc[metric]!=0]])\n",
    "        \n",
    "        try:\n",
    "            final_df = final_df.merge(temp,on=['Observed Value','Type'],how='outer')\n",
    "        except:\n",
    "            final_df = temp.copy()\n",
    "            \n",
    "        test_dict = {}\n",
    "        perf_df = pd.DataFrame()\n",
    "        for model in models:\n",
    "            for metric in ['F1','AUC','Accuracy']:\n",
    "        \n",
    "                value_list = df[df['Model']==model].sort_values(metric,ascending=False)[metric].tolist()\n",
    "                test_dict.setdefault('Model Best Five',{})[metric] = np.mean(value_list[:4])\n",
    "                test_dict.setdefault('Model Best Performing',{})[metric] = value_list[0]\n",
    "                test_dict.setdefault('Model Mean Performance',{})[metric] = np.mean(value_list)\n",
    "\n",
    "                temp_df = pd.DataFrame(test_dict).T.reset_index().rename(columns={'index':'Type'})\n",
    "                temp_df['Observed Value'] = model\n",
    "            \n",
    "            perf_df = pd.concat([perf_df,temp_df])\n",
    "\n",
    "    return pd.concat([final_df,perf_df]).sort_values(['Type',metrics[0]],ascending=[True,False]).set_index(['Observed Value','Type']).fillna(0)\n",
    "    \n",
    "\n",
    "\n",
    "def MLManualPipeline(df,\n",
    "                     Features,\n",
    "                     Target,\n",
    "                     model,\n",
    "                     balance_target_observations=[0,.25],\n",
    "                     scaler_=None,\n",
    "                     test_size=.3,\n",
    "                     random_state=42,\n",
    "                     include_narrative=1,\n",
    "                     rf_estimators=50,\n",
    "                     log_max_it=100,\n",
    "                     SequenceNumber=0,\n",
    "                     time_model=1,\n",
    "                     xgb_objective='binary:logistic',\n",
    "                     xgb_eval_metric='logloss'):\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "        \n",
    "    generated_models = {}\n",
    "    \n",
    "    # Create Copy to ensure original data is not altered\n",
    "    df = df.copy()\n",
    "\n",
    "    if balance_target_observations[0]==1:\n",
    "        df = BalanceTargetDistribution(df=df,\n",
    "                                       Target=Target,\n",
    "                                       desired_percentage=balance_target_observations[1])\n",
    "        balance_target_observations = f'{balance_target_observations[1]}'\n",
    "    else:\n",
    "        balance_target_observations = '0'\n",
    "        \n",
    "    # If features not specified, entire Dataset to be processed (less Target), otherwise include only features\n",
    "    if len(Features) == 0:\n",
    "        Features = list(df.drop(Target,axis=1).columns)\n",
    "        X = np.array(df[Features].copy())\n",
    "        df_len = len(df)\n",
    "        feature_count = len(X[0])\n",
    "    else:\n",
    "        X = np.array(df[Features])\n",
    "        df_len = len(df)\n",
    "        feature_count = len(X[0])\n",
    "        \n",
    "    # Create Target Array - Target already provided as a List\n",
    "    y = np.array(df[Target].squeeze())\n",
    "    target_vc = df[Target].value_counts()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    if scaler_ in scaler_dict.keys():\n",
    "        scaler = scaler_dict[scaler_]\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        x_test = scaler.transform(X_test)\n",
    "    else:\n",
    "        scaler = None\n",
    "        \n",
    "    if include_narrative==1:\n",
    "        print(f\"Total Number of Records in Dataset: {df_len}\\ntotal features: {feature_count}\\nTarget Distribution:\\n{target_vc}\\n\")\n",
    "        print(f\"Training Data Set:\\nTraining Features:{len(X_train)}, Training Target:{len(y_train)}\\nTraining Target Distribution:\\n{pd.DataFrame(y_train).value_counts()}\\n\")\n",
    "        print(f\"Testing Data Set:\\nTest Features:{len(X_test)}, Test Target:{len(y_test)}Training Target Distribution:\\n{pd.DataFrame(y_test).value_counts()}\\n\")\n",
    "        \n",
    "    if model=='Logistic Regression':\n",
    "        \n",
    "        # Create Model\n",
    "        logreg=LogisticRegression(max_iter=log_max_it)\n",
    "        \n",
    "        # Train Model\n",
    "        logreg.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on Text\n",
    "        y_pred = logreg.predict(X_test)\n",
    "        \n",
    "        # Generate Test DataFrame\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        \n",
    "        # Create Feature Importance DataFrame\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':np.abs(logreg.coef_[0]),}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        # Generate Results and Dataframe\n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        \n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':logreg,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "        try:\n",
    "            # Generate a Balanced Variant of the Logistic Regression Where \n",
    "            perc_dist = len(df[df[Target]==0])/len(df)\n",
    "            if perc_dist>.6:\n",
    "                lr0=LogisticRegression(max_iter=log_max_it,class_weight='balanced')\n",
    "                lr0.fit(X_train, y_train)\n",
    "                y_pred_rf = lr0.predict(X_test)\n",
    "                result_df = pd.concat([pd.DataFrame(y_pred_rf,columns=['PREDICTION']),\n",
    "                                       pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "                feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                                   'IMPORTANCE':rf.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "                result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                               model='Logistic Regression - Balanced',\n",
    "                                                               scaler=scaler_,\n",
    "                                                               balance=balance_target_observations,\n",
    "                                                               sequence_num=SequenceNumber+1000000)\n",
    "                stop_time = timeit.default_timer() - start_time\n",
    "                performance['RunTime'] = stop_time\n",
    "                generated_models[SequenceNumber+1000000] = {'ModelType':'Logistic Regression - Balanced',\n",
    "                                                        'Model':lr0,\n",
    "                                                        'Scaler':scaler,\n",
    "                                                        'FeatureImportance':feature_importance,\n",
    "                                                        'BinaryResultDF':result_df,\n",
    "                                                        'ModelPerformance':performance}\n",
    "        except:\n",
    "            print('Attempted to Review Random Forrest - Balanced, could not')\n",
    "\n",
    "    elif model =='Decision Tree':    \n",
    "        ############################################ ESTIMATORS\n",
    "        dt = DecisionTreeClassifier(random_state=random_state)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred_dt = dt.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_dt,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':dt.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        \n",
    "        \n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':dt,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "\n",
    "    elif model =='Random Forest':    \n",
    "        ############################################ ESTIMATORS\n",
    "        rf = RandomForestClassifier(random_state=random_state, n_estimators=rf_estimators)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred_rf = rf.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_rf,columns=['PREDICTION']),\n",
    "                               pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':rf.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':rf,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "        try:\n",
    "            # Generate a Balanced Variant of the Random Forest Where \n",
    "            perc_dist = len(df[df[Target]==0])/len(df)\n",
    "            if perc_dist>.6:\n",
    "                rf0 = RandomForestClassifier(random_state=random_state, n_estimators=rf_estimators,class_weight='balanced')\n",
    "                rf0.fit(X_train, y_train)\n",
    "                y_pred_rf = rf0.predict(X_test)\n",
    "                result_df = pd.concat([pd.DataFrame(y_pred_rf,columns=['PREDICTION']),\n",
    "                                       pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "                feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                                   'IMPORTANCE':rf.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "                result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                               model='Random Forest - Balanced',\n",
    "                                                               scaler=scaler_,\n",
    "                                                               balance=balance_target_observations,\n",
    "                                                               sequence_num=SequenceNumber+1000000)\n",
    "                stop_time = timeit.default_timer() - start_time\n",
    "                performance['RunTime'] = stop_time\n",
    "                generated_models[SequenceNumber+1000000] = {'ModelType':'Random Forest - Balanced',\n",
    "                                                        'Model':rf0,\n",
    "                                                        'Scaler':scaler,\n",
    "                                                        'FeatureImportance':feature_importance,\n",
    "                                                        'BinaryResultDF':result_df,\n",
    "                                                        'ModelPerformance':performance}\n",
    "        except:\n",
    "            print('Attempted to Review Random Forrest - Balanced, could not')\n",
    "                \n",
    "    elif model == 'Gradient Boosting':\n",
    "        gb = GradientBoostingClassifier()\n",
    "        gb.fit(X_train, y_train)\n",
    "        y_pred_gb = gb.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_gb,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':gb.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':gb,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "    elif model == 'Ada':\n",
    "        ada = AdaBoostClassifier()\n",
    "        ada.fit(X_train, y_train)\n",
    "        y_pred_ada = ada.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_ada,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':ada.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':ada,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "    elif model == 'Extra Tree':\n",
    "        et = ExtraTreesClassifier()\n",
    "        et.fit(X_train, y_train)\n",
    "        y_pred_et = et.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_et,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':et.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':et,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "    elif model == 'XGBoost':\n",
    "        xgb_ = xgb.XGBClassifier(objective=xgb_objective,\n",
    "                                eval_metric=xgb_eval_metric,\n",
    "                                use_label_encoder=False,\n",
    "                                random_state=random_state)\n",
    "        xgb_.fit(X_train, y_train)\n",
    "        y_pred_et = xgb_.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_et,columns=['PREDICTION']),\n",
    "                               pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':xgb_.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        \n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':xgb,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}    \n",
    "    else:\n",
    "        print('Model Not Defined, please update function')\n",
    "        \n",
    "    performance_metrics = pd.DataFrame()\n",
    "    for key in generated_models.keys():\n",
    "        performance_metrics = pd.concat([performance_metrics,generated_models[key]['ModelPerformance']])\n",
    "        \n",
    "    return generated_models,performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71228ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "adef train_neural_network(X,\n",
    "                y,\n",
    "                input_dim,\n",
    "                metrics,\n",
    "                hidden_layer_sizes,\n",
    "                activation, \n",
    "                optimizer,\n",
    "                learning_rate,\n",
    "                batch_size,\n",
    "                num_epochs,\n",
    "                validation_split,\n",
    "                verbose=0):\n",
    "                       \n",
    "\n",
    "    # Build the model.\n",
    "    model = build_binary_classification_model(input_dim=input_dim,\n",
    "                                              hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                              activation=activation, \n",
    "                                              optimizer=optimizer,\n",
    "                                              learning_rate=learning_rate,\n",
    "                                              metrics=metrics)\n",
    "    \n",
    "    print(model.summary())     \n",
    "                        \n",
    "    # Train the model.\n",
    "    history = model.fit(x=X,\n",
    "                        y=y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        validation_split=validation_split,\n",
    "                        verbose=verbose)\n",
    "\n",
    "    # Retrieve the training metrics (after each train epoch) and the final test\n",
    "    # accuracy.\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(train_accuracy, label='train_accuracy')\n",
    "    plt.plot(val_accuracy, label='validation accuracy')\n",
    "    plt.xticks(range(num_epochs))\n",
    "    plt.xlabel('Train epochs')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    return history,model\n",
    "\n",
    "    \n",
    "def neural_network(X_df,\n",
    "                   y_df,\n",
    "                   input_dim, \n",
    "                   hidden_layer_sizes,\n",
    "                   activation,\n",
    "                   optimizer,\n",
    "                   learning_rate,\n",
    "                   metrics,\n",
    "                   verbose=0):\n",
    "\n",
    "    \"\"\"Build a binary classification model using Keras.\n",
    "\n",
    "      Args:\n",
    "        input_dim: Number of features in the input data.\n",
    "        hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "        activation: The activation function to use for the hidden layers.\n",
    "        optimizer: The optimizer\n",
    "        learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "      Returns:\n",
    "        model: A tf.keras model.\n",
    "    \"\"\"\n",
    "    # Instantiate Model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    # Add Input Layer\n",
    "    model.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "\n",
    "    # Add Hidden Layers\n",
    "    for nodes in hidden_layer_sizes:\n",
    "        model.add(layers.Dense(units=nodes, activation=activation))\n",
    "\n",
    "    # Add Output Layer\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Configure optimizer and compile the model\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
