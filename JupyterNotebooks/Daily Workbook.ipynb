{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b98e26af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/derekdewald/Documents/Python/Github_Repo/JupyterNotebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6dcc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/derekdewald/Documents/Python/Github_Repo/d_py_functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08bd1c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/ProcessSheet\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/DataDashboardSheet\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/CodingDDashboard\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/ML_Pipeline\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/Mapping Sheet\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/SKLearn Models\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/Notes\n",
      "Counld Not Print Record 7\n",
      "Counld Not Print Record 8\n"
     ]
    }
   ],
   "source": [
    "from Connections import DownloadFilesFromGit,BackUpGoogleSheets\n",
    "\n",
    "DownloadFilesFromGit(output_folder='/Users/derekdewald/Documents/Python/Github_Repo/JupyterNotebooks/downloaded_py_files/')\n",
    "BackUpGoogleSheets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b0949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638dc14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import all_estimators\n",
    "import mlflow\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load Diabetes Dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "df = pd.DataFrame(diabetes['data'], columns=diabetes['feature_names'])\n",
    "df['Target'] = diabetes['target']\n",
    "\n",
    "# Function to Apply Scaling\n",
    "def apply_scaling(X_train, X_test, scaler=None):\n",
    "    scalers = {\n",
    "        'standard': StandardScaler(),\n",
    "        'normalization': MinMaxScaler()\n",
    "    }\n",
    "    if scaler in scalers:\n",
    "        scaler_instance = scalers[scaler]\n",
    "        X_train = scaler_instance.fit_transform(X_train)\n",
    "        X_test = scaler_instance.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "# ML Pipeline Function\n",
    "def MLPipeline(df, project_name, scaler=None, ml_model_type='regressor', target_column='Target', test_size=0.2):\n",
    "    mlflow.set_experiment(project_name)\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_train, X_test = apply_scaling(X_train, X_test, scaler=scaler)\n",
    "\n",
    "    model_list = all_estimators(type_filter=ml_model_type)\n",
    "    results = []\n",
    "\n",
    "    for name, model_class in model_list:\n",
    "        try:\n",
    "            model = model_class()\n",
    "            start_time = time.time()\n",
    "\n",
    "            with mlflow.start_run(run_name=name):\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                if ml_model_type == \"classifier\":\n",
    "                    metric = accuracy_score(y_test, y_pred)\n",
    "                    mlflow.log_metric(\"Accuracy\", metric)\n",
    "                else:\n",
    "                    # Compute RMSE manually (fix for 'squared' error)\n",
    "                    metric = mean_squared_error(y_test, y_pred) ** 0.5  \n",
    "                    mlflow.log_metric(\"RMSE\", metric)\n",
    "\n",
    "                mlflow.sklearn.log_model(model, name)\n",
    "                mlflow.log_param(\"Model\", name)\n",
    "                mlflow.log_param(\"Training Time\", round(time.time() - start_time, 2))\n",
    "\n",
    "                results.append({\n",
    "                    \"Model\": name,\n",
    "                    \"Metric\": metric,\n",
    "                    \"Time (s)\": round(time.time() - start_time, 2)\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ {name} failed: {str(e)}\")  # Handle model failures but continue\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(by=\"Metric\", ascending=(ml_model_type == \"regressor\"))\n",
    "\n",
    "    # Display DataFrame\n",
    "    import ace_tools as tools\n",
    "    tools.display_dataframe_to_user(name=\"ML Model Performance\", dataframe=results_df)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "sql = '''\n",
    "with base as (\n",
    "    select\n",
    "        membernbr\n",
    "        ,membername\n",
    "        ,taxid\n",
    "        ,memberstatus\n",
    "        ,PERSDOB\n",
    "    from member\n",
    "    where memberstatus in ('GOOD STANDING','ACTIVE')\n",
    "),\n",
    "\n",
    "share_bal as (\n",
    "     select \n",
    "        membernbr\n",
    "        ,sum(case when MINOR = 'ES01' then currbal else 0 end) as CURRENT_ES01\n",
    "        ,max(case when daysdelinq >=90 then 1 else 0 end) as CURRENT_DELINQ\n",
    "        from account\n",
    "        group by membernbr\n",
    "),\n",
    "\n",
    "dec_del as (\n",
    "    select distinct \n",
    "        membernbr, \n",
    "        1 as DELIQUENT_DEC2024\n",
    "    from accounthist \n",
    "    where effdate = '30-Nov-24' and daysdelinq>=90 and major !='LEAS'\n",
    "),\n",
    "\n",
    "dec_shar_bal as (\n",
    "    select \n",
    "        t2.membernbr,\n",
    "        sum(t1.notebal) as BAL_DEC13\n",
    "    from acctbal t1\n",
    "    left join account t2 \n",
    "    on t1.acctnbr=t2.acctnbr\n",
    "    where t1.effdate='13-Dec-24' and t1.minor='ES01'\n",
    "    group by t2.membernbr\n",
    " ),\n",
    " \n",
    " feb_shar_bal as (\n",
    "    select \n",
    "        t2.membernbr,\n",
    "        sum(t1.notebal) as BAL_FEB13\n",
    "    from acctbal t1\n",
    "    left join account t2 \n",
    "    on t1.acctnbr=t2.acctnbr\n",
    "    where t1.effdate='13-Feb-25' and t1.minor='ES01'\n",
    "    group by t2.membernbr\n",
    " )\n",
    " \n",
    "select t1.*, t2.CURRENT_ES01,t2.CURRENT_DELINQ,t3.DELIQUENT_DEC2024,t4.bal_dec13,t5.bal_feb13\n",
    "from base t1\n",
    "left join share_bal t2 on t1.membernbr=t2.membernbr\n",
    "left join dec_del   t3 on t1.membernbr=t3.membernbr\n",
    "left join dec_shar_bal t4 on t1.membernbr=t4.membernbr\n",
    "left join feb_shar_bal t5 on t1.membernbr=t5.membernbr\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_trends(data, id_column, time_columns):\n",
    "    \"\"\"\n",
    "    Calculate trends (slopes) for entities over time using linear regression.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input DataFrame containing entity IDs and time-based columns.\n",
    "        id_column (str): Column name for the unique entity identifier (e.g., member_id).\n",
    "        time_columns (list of str): List of column names representing the time periods (e.g., months).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing entity IDs, slopes, and trends.\n",
    "    \"\"\"\n",
    "    # Extract unique entity IDs and the time-series data\n",
    "    entity_ids = data[id_column].unique()\n",
    "    time_data = data[time_columns].values\n",
    "    \n",
    "    # Prepare the X (time) matrix\n",
    "    time_indices = np.arange(1, len(time_columns) + 1)  # Generate time indices\n",
    "    X = np.vstack([time_indices, np.ones(len(time_indices))]).T  # Add a bias term for the intercept\n",
    "\n",
    "    # Perform linear regression for all entities\n",
    "    slopes = np.linalg.lstsq(X, time_data.T, rcond=None)[0][0]  # Extract slopes\n",
    "    \n",
    "    # Prepare results DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        id_column: entity_ids,\n",
    "        \"slope\": slopes\n",
    "    })\n",
    "    \n",
    "    # Classify trends\n",
    "    results[\"trend\"] = np.where(\n",
    "        results[\"slope\"] > 0, \"increasing\",\n",
    "        np.where(results[\"slope\"] < 0, \"decreasing\", \"stable\")\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for model in models:\n",
    "    for metric in ['F1','AUC','Accuracy']:   \n",
    "        test_dict.setdefault('Top 5 Performing Models',{})[metric] = np.mean(value_list[:4])\n",
    "        test_dict.setdefault('Top Performing Model',{})[metric] = value_list[0]\n",
    "        test_dict.setdefault('All Models Mean',{})[metric] = np.mean(value_list)\n",
    "        \n",
    "        temp_df = pd.DataFrame(test_dict).T.reset_index().rename(columns={'index':'Type'})\n",
    "        temp_df['Observed Value'] = model\n",
    "    \n",
    "    final_df = pd.concat([final_df,temp_df])\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "list_1 = [1,2,3,4]\n",
    "list_2 = [5,6,7,8]\n",
    "list_3 = ['d','e','f','g']\n",
    "list_4 = ['&','*',')','(']\n",
    "\n",
    "combinations = list(itertools.product(list_1,list_2,list_3,list_4))\n",
    "combinations[0:10]\n",
    "\n",
    "\n",
    "import os \n",
    "os.startfile(file_location)\n",
    "\n",
    "\n",
    "import bcdata\n",
    "bcevacdata = bcdata.get_data('evacuation-orders-and-alerts', as_gdf=True)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,roc_curve,roc_auc_score,mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from gffg.DF_PROCESSING import brackets_v3\n",
    "\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "# Define Macro Variables\n",
    "random_state = 42\n",
    "rf_nodes = 100\n",
    "xgb_objective='binary:logistic'\n",
    "xgb_eval_metric='logloss'\n",
    "\n",
    "ml_model_dict = {\n",
    "    'Linear Regression': {\n",
    "        'Type': 'Linear',\n",
    "        'Description': 'A linear approach to modeling the relationship between a dependent variable and one or more independent variables.',\n",
    "        'UseCase': \"Regression\",\n",
    "        'ModelStrengths': \"Simple, interpretable, computationally efficient, works well for linearly separable data.\",\n",
    "        'Model Weaknesses': \"Assumes linear relationships, sensitive to outliers.\",\n",
    "        'lowerbound_feature_threshold':.1,\n",
    "        'upperbound_feature_threshold':.5,\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'SKlearn': LinearRegression()\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'Type': 'Linear',\n",
    "        'Description': 'A regression model that predicts probabilities using the sigmoid function for binary classification problems.',\n",
    "        'UseCase': [\"Classification\"],\n",
    "        'ModelStrengths': \"Simple, interpretable, performs well for linearly separable data.\",\n",
    "        'Model Weaknesses': \"Struggles with non-linear relationships, assumes linear relationship between features and log-odds.\",\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'lowerbound_feature_threshold':.1,\n",
    "        'upperbound_feature_threshold':.5,\n",
    "        'SKlearn': LogisticRegression(random_state=random_state,class_weight=None)\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'Type': 'Tree',\n",
    "        'Description': 'A model that splits data into branches to make predictions based on feature values.',\n",
    "        'UseCase': [\"Classification\", \"Regression\"],\n",
    "        'ModelStrengths': \"Easy to interpret, handles both numerical and categorical data.\",\n",
    "        'Model Weaknesses': \"Prone to overfitting, unstable with small changes in data.\",\n",
    "        'lowerbound_feature_threshold':.05,\n",
    "        'upperbound_feature_threshold':.1,\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'SKlearn': DecisionTreeClassifier(random_state=random_state)\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'Type': 'Ensemble',\n",
    "        'Description': 'An ensemble of decision trees using bagging to reduce overfitting and improve accuracy.',\n",
    "        'UseCase': [\"Classification\", \"Regression\"],\n",
    "        'ModelStrengths': \"Reduces overfitting, robust to noise, handles high-dimensional data well.\",\n",
    "        'Model Weaknesses': \"Computationally expensive, less interpretable than a single tree.\",\n",
    "        'lowerbound_feature_threshold':.05,\n",
    "        'upperbound_feature_threshold':.1,\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'Parameters':{'n_estimators':'Total Number of Decision Trees which are created by the model. The more trees the more likely to overfit and longer to process, the fewer decision nodes, the less unique information is captured',\n",
    "                     'class_weight':'Model Automatically Adjusts the weight of each sample, attempting to adjust for the pertinent data imbalance. It does not undersample or remove.'},\n",
    "        'SKlearn': RandomForestClassifier(random_state=random_state, n_estimators=rf_nodes,class_weight=None)\n",
    "    },\n",
    "    'Extra Tree': {\n",
    "        'Type': 'Ensemble',\n",
    "        'Description': 'Similar to Random Forest but selects splits randomly rather than optimizing them.',\n",
    "        'UseCase': [\"Classification\", \"Regression\"],\n",
    "        'ModelStrengths': \"Reduces overfitting further, computationally efficient compared to Random Forest.\",\n",
    "        'Model Weaknesses': \"Slightly less accurate in some cases, still computationally heavy.\",\n",
    "        'lowerbound_feature_threshold':.05,\n",
    "        'upperbound_feature_threshold':.1,\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'SKlearn': ExtraTreesClassifier(random_state=random_state)\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'Type': 'Ensemble',\n",
    "        'Description': 'Builds models sequentially, correcting errors from previous models in an additive fashion.',\n",
    "        'UseCase': [\"Classification\", \"Regression\"],\n",
    "        'ModelStrengths': \"Highly accurate, handles non-linear relationships well.\",\n",
    "        'Model Weaknesses': \"Sensitive to hyperparameters, prone to overfitting on noisy data.\",\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'lowerbound_feature_threshold':.05,\n",
    "        'upperbound_feature_threshold':.1,\n",
    "        'SKlearn': GradientBoostingClassifier(random_state=random_state)\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'Type': 'Ensemble',\n",
    "        'Description': 'An optimized gradient boosting model with regularization to prevent overfitting.',\n",
    "        'UseCase': [\"Classification\", \"Regression\"],\n",
    "        'ModelStrengths': \"Fast, scalable, handles sparse data, regularization prevents overfitting.\",\n",
    "        'Model Weaknesses': \"Requires careful tuning of hyperparameters, computationally expensive.\",\n",
    "        'lowerbound_feature_threshold':.05,\n",
    "        'upperbound_feature_threshold':.1,\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'SKlearn': xgb.XGBClassifier(objective=xgb_objective, eval_metric=xgb_eval_metric, use_label_encoder=False, random_state=random_state)\n",
    "    },\n",
    "    'Ada': {\n",
    "        'Type': 'Ensemble',\n",
    "        'Description': 'Boosting technique that combines multiple weak learners (usually decision stumps) into a strong learner.',\n",
    "        'UseCase': [\"Classification\", \"Regression\"],\n",
    "        'ModelStrengths': \"Handles weak learners well, reduces overfitting.\",\n",
    "        'Model Weaknesses': \"Sensitive to noisy data, requires careful tuning of learning rate.\",\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'lowerbound_feature_threshold':.05,\n",
    "        'upperbound_feature_threshold':.1,\n",
    "        'SKlearn': AdaBoostClassifier(random_state=random_state)\n",
    "    },\n",
    "    'Support Vector Machine (SVM)': {\n",
    "        'Type': 'Kernel-Based',\n",
    "        'Description': 'A model that finds the optimal hyperplane for separating classes.',\n",
    "        'UseCase': [\"Classification\", \"Regression\"],\n",
    "        'ModelStrengths': \"Effective in high-dimensional spaces, works well with clear margins of separation.\",\n",
    "        'Model Weaknesses': \"Computationally expensive, struggles with large datasets.\",\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'SKlearn': None\n",
    "    },\n",
    "    'K-Nearest Neighbors (KNN)': {\n",
    "        'Type': 'Instance-Based',\n",
    "        'Description': 'A model that classifies points based on their proximity to neighbors.',\n",
    "        'UseCase': [\"Classification\", \"Regression\"],\n",
    "        'ModelStrengths': \"Simple to implement, works well with small datasets.\",\n",
    "        'Model Weaknesses': \"Computationally expensive with large datasets, sensitive to irrelevant features.\",\n",
    "        'ReferenceWorkbooks': \"\",\n",
    "        'SKlearn': None\n",
    "    }\n",
    "}\n",
    "\n",
    "ml_dict_df = pd.DataFrame(ml_model_dict).T.reset_index().rename(columns={'index':'Model'})\n",
    "\n",
    "scaler_dict = {\n",
    "    'Standard':StandardScaler(),\n",
    "    'Min Max': MinMaxScaler(),\n",
    "    'Robust':RobustScaler()}\n",
    "\n",
    "\n",
    "def BalanceTargetDistribution(df,\n",
    "                              Target,\n",
    "                              desired_percentage,\n",
    "                              TargetValue=1,):\n",
    "    \n",
    "    df = df.copy()\n",
    "\n",
    "    df0 = df[df[Target]==TargetValue].copy()\n",
    "    df1 = df[df[Target]!=TargetValue].copy()\n",
    "    \n",
    "    if (desired_percentage>0)&(desired_percentage<1):\n",
    "        req_columns = int(round(len(df0)/desired_percentage,0))\n",
    "        \n",
    "        return pd.concat([df0,df1.sample(req_columns)]).sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    else:\n",
    "        print('Desired Percentage Outside of Allowable Range (0-1), Please Select a New Value')\n",
    "\n",
    "\n",
    "def ClassificationMetrics(df,\n",
    "                          model=\"\",\n",
    "                          scaler=\"\",\n",
    "                          balance=\"\",\n",
    "                          sequence_num=0,\n",
    "                          prediction='PREDICTION',\n",
    "                          actual='ACTUAL',\n",
    "                          new_column_name='RESULT'):\n",
    "    '''\n",
    "    \n",
    "    Accuracy: Number of Correct Preditions. Can be misleading with Imbalanced data, where it simply predicts Majority Class\n",
    "    \n",
    "    Precision: Number of Positive Correctly Predicted as a Percentage of Total Positive Instances. Can be misleading when the total number of predictions is very high (IE Predict EVerything Positive, this number will be 100%, but will waste so much time because of false predictions)\n",
    "    \n",
    "    Recall: The Percentage of Correct Predictions as a Percentage of Total Positive Predictions. How Accurate your prediction is. This number can be misleading because you can have a High Recall by simply predicting things only with a high degress of certainty, missing out on fringe cases.\n",
    "    \n",
    "    F1: Harmonic Mean when Balancing Precision and Recall\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    \n",
    "    results_dict['SequenceNumber'] = sequence_num\n",
    "\n",
    "    print(scaler)\n",
    "    \n",
    "    if len(model)!=0:\n",
    "        results_dict['Model'] = model\n",
    "    if isinstance(scaler,str):\n",
    "        results_dict['Scaler'] = scaler \n",
    "    if len(balance)!=0:\n",
    "        results_dict['Training Set Balance Perc'] = balance\n",
    "    \n",
    "    condition = [(df[prediction]==1)&(df[actual]==df[prediction]),\n",
    "                 (df[prediction]==0)&(df[actual]==df[prediction]),\n",
    "                 (df[prediction]==1)&(df[actual]!=df[prediction]),\n",
    "                 (df[prediction]==0)&(df[actual]!=df[prediction])]\n",
    "    \n",
    "    values = ['True Positives','True Negatives','False Positives (I)','False Negatives (II)']\n",
    "    \n",
    "    df[new_column_name] = np.select(condition,values)\n",
    "    \n",
    "    results_dict['True Positives'] =       len(df[df['RESULT']=='True Positives'])\n",
    "    results_dict['True Negatives'] =       len(df[df['RESULT']=='True Negatives'])\n",
    "    results_dict['False Positives (I)'] =  len(df[df['RESULT']=='False Positives (I)'])\n",
    "    results_dict['False Negatives (II)'] = len(df[df['RESULT']=='False Negatives (II)'])\n",
    "    \n",
    "    \n",
    "    results_dict['Total Records'] = len(df)\n",
    "    results_dict['Correct Predictions'] =   len(df[df['RESULT'].isin(['True Negatives','True Positives'])])\n",
    "    results_dict['Incorrect Predictions'] = len(df[df['RESULT'].isin(['False Negatives (II)','False Positives (I)'])])\n",
    "    results_dict['Actual Positives'] = len(df[df['RESULT'].isin(['False Negatives (II)','True Positives'])])\n",
    "    results_dict['Actual Negatives'] = len(df[df['RESULT'].isin(['False Positives (I)','True Negatives'])])\n",
    "    \n",
    "    try:\n",
    "        results_dict['Recall'] = results_dict['True Positives']/(results_dict['True Positives']+results_dict['False Negatives (II)'])     # How Many Positives were Actually Predicted\n",
    "        results_dict['Precision']    = results_dict['True Positives']/(results_dict['True Positives']+results_dict['False Positives (I)']) # How Many Predictions were Correct\n",
    "        results_dict['F1'] = 2*(results_dict['Precision']*results_dict['Recall'])/(results_dict['Precision']+results_dict['Recall'])  # Harmonic Mean \n",
    "        \n",
    "    except:\n",
    "        results_dict['Recall'] = 0\n",
    "        results_dict['Precision'] = 0\n",
    "        results_dict['F1'] = 0\n",
    "        \n",
    "    results_dict['Accuracy']  = results_dict['Correct Predictions']/results_dict['Total Records']     # How Correct your Model was overall\n",
    "    results_dict['AUC']       = roc_auc_score(df[actual],df[prediction])\n",
    "    \n",
    "    return df,pd.DataFrame([results_dict.values()],columns=results_dict.keys())\n",
    "\n",
    "def GenerateMLModels(df,\n",
    "                     Features,\n",
    "                     Target,\n",
    "                     model_list,\n",
    "                     scaler_list,\n",
    "                     balance_list,\n",
    "                     log_max_it=1000,\n",
    "                     rf_estimators=50,\n",
    "                     include_narrative=0):\n",
    "    \n",
    "    model_dict = {}\n",
    "    final_result_df = pd.DataFrame()\n",
    "    \n",
    "    param_list = list(product(model_list,scaler_list,balance_list))\n",
    "    \n",
    "    for count,params in enumerate(param_list):\n",
    "        print(count,params)\n",
    "        \n",
    "        model = params[0]\n",
    "        scaler = params[1]\n",
    "        if params[2]!=0:\n",
    "            balance_target_observations = [1,params[2]]\n",
    "        else:\n",
    "            balance_target_observations = [0,0]\n",
    "        \n",
    "        run_dict,result = MLManualPipeline(df=df,\n",
    "                                           Features=Features,\n",
    "                                           Target=Target,\n",
    "                                           model=model,\n",
    "                                           scaler_=scaler,\n",
    "                                           balance_target_observations=balance_target_observations,\n",
    "                                           include_narrative=include_narrative,\n",
    "                                           rf_estimators=rf_estimators,\n",
    "                                           SequenceNumber=count,\n",
    "                                           log_max_it=log_max_it)\n",
    "        \n",
    "        model_dict[count] = run_dict\n",
    "        final_result_df = pd.concat([final_result_df,result])\n",
    "        \n",
    "    return model_dict,final_result_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ModelPerformanceByCategory(df,\n",
    "                               primary_key='SequenceNumber',\n",
    "                               ml_parameters=['Model','Scaler','Training Set Balance Perc'],\n",
    "                               observations=20,\n",
    "                               metrics=['AUC','F1','Accuracy']):\n",
    "    \n",
    "    # Create List of Models Based on Original Input Dataframe\n",
    "    models = list(df['Model'].unique())\n",
    "    \n",
    "    # Create Values for Particular Metric under review\n",
    "    for metric in metrics:\n",
    "        # Sort Value based on Metric\n",
    "        metric_df = df.sort_values(metric,ascending=False)\n",
    "        # Iterate through Categories as defined by Function\n",
    "        temp = pd.DataFrame()\n",
    "        for ml_ in ml_parameters:\n",
    "            _ = pd.DataFrame(metric_df[ml_].fillna(\"\").head(observations).value_counts()).reset_index().rename(columns={'index':'Observed Value',ml_:metric})\n",
    "            _['Type'] = ml_\n",
    "            \n",
    "            temp = pd.concat([temp,_])\n",
    "            \n",
    "        # Generate Metric Summary Value \n",
    "        # Create Segments\n",
    "        brackets_v3(metric_df,metric,f\"{metric}_segment\",[0,.25,.5,.6,.75,.9])\n",
    "        perc = pd.DataFrame(metric_df[f\"{metric}_segment\"].value_counts()).reset_index().rename(columns={'index':\"Observed Value\",f\"{metric}_segment\":metric})\n",
    "        perc['Type'] = 'Model Performance'\n",
    "        \n",
    "        temp = pd.concat([temp,perc[perc[metric]!=0]])\n",
    "        \n",
    "        try:\n",
    "            final_df = final_df.merge(temp,on=['Observed Value','Type'],how='outer')\n",
    "        except:\n",
    "            final_df = temp.copy()\n",
    "            \n",
    "        test_dict = {}\n",
    "        perf_df = pd.DataFrame()\n",
    "        for model in models:\n",
    "            for metric in ['F1','AUC','Accuracy']:\n",
    "        \n",
    "                value_list = df[df['Model']==model].sort_values(metric,ascending=False)[metric].tolist()\n",
    "                test_dict.setdefault('Model Best Five',{})[metric] = np.mean(value_list[:4])\n",
    "                test_dict.setdefault('Model Best Performing',{})[metric] = value_list[0]\n",
    "                test_dict.setdefault('Model Mean Performance',{})[metric] = np.mean(value_list)\n",
    "\n",
    "                temp_df = pd.DataFrame(test_dict).T.reset_index().rename(columns={'index':'Type'})\n",
    "                temp_df['Observed Value'] = model\n",
    "            \n",
    "            perf_df = pd.concat([perf_df,temp_df])\n",
    "\n",
    "    return pd.concat([final_df,perf_df]).sort_values(['Type',metrics[0]],ascending=[True,False]).set_index(['Observed Value','Type']).fillna(0)\n",
    "    \n",
    "\n",
    "\n",
    "def MLManualPipeline(df,\n",
    "                     Features,\n",
    "                     Target,\n",
    "                     model,\n",
    "                     balance_target_observations=[0,.25],\n",
    "                     scaler_=None,\n",
    "                     test_size=.3,\n",
    "                     random_state=42,\n",
    "                     include_narrative=1,\n",
    "                     rf_estimators=50,\n",
    "                     log_max_it=100,\n",
    "                     SequenceNumber=0,\n",
    "                     time_model=1,\n",
    "                     xgb_objective='binary:logistic',\n",
    "                     xgb_eval_metric='logloss'):\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "        \n",
    "    generated_models = {}\n",
    "    \n",
    "    # Create Copy to ensure original data is not altered\n",
    "    df = df.copy()\n",
    "\n",
    "    if balance_target_observations[0]==1:\n",
    "        df = BalanceTargetDistribution(df=df,\n",
    "                                       Target=Target,\n",
    "                                       desired_percentage=balance_target_observations[1])\n",
    "        balance_target_observations = f'{balance_target_observations[1]}'\n",
    "    else:\n",
    "        balance_target_observations = '0'\n",
    "        \n",
    "    # If features not specified, entire Dataset to be processed (less Target), otherwise include only features\n",
    "    if len(Features) == 0:\n",
    "        Features = list(df.drop(Target,axis=1).columns)\n",
    "        X = np.array(df[Features].copy())\n",
    "        df_len = len(df)\n",
    "        feature_count = len(X[0])\n",
    "    else:\n",
    "        X = np.array(df[Features])\n",
    "        df_len = len(df)\n",
    "        feature_count = len(X[0])\n",
    "        \n",
    "    # Create Target Array - Target already provided as a List\n",
    "    y = np.array(df[Target].squeeze())\n",
    "    target_vc = df[Target].value_counts()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    if scaler_ in scaler_dict.keys():\n",
    "        scaler = scaler_dict[scaler_]\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        x_test = scaler.transform(X_test)\n",
    "    else:\n",
    "        scaler = None\n",
    "        \n",
    "    if include_narrative==1:\n",
    "        print(f\"Total Number of Records in Dataset: {df_len}\\ntotal features: {feature_count}\\nTarget Distribution:\\n{target_vc}\\n\")\n",
    "        print(f\"Training Data Set:\\nTraining Features:{len(X_train)}, Training Target:{len(y_train)}\\nTraining Target Distribution:\\n{pd.DataFrame(y_train).value_counts()}\\n\")\n",
    "        print(f\"Testing Data Set:\\nTest Features:{len(X_test)}, Test Target:{len(y_test)}Training Target Distribution:\\n{pd.DataFrame(y_test).value_counts()}\\n\")\n",
    "        \n",
    "    if model=='Logistic Regression':\n",
    "        \n",
    "        # Create Model\n",
    "        logreg=LogisticRegression(max_iter=log_max_it)\n",
    "        \n",
    "        # Train Model\n",
    "        logreg.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on Text\n",
    "        y_pred = logreg.predict(X_test)\n",
    "        \n",
    "        # Generate Test DataFrame\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        \n",
    "        # Create Feature Importance DataFrame\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':np.abs(logreg.coef_[0]),}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        # Generate Results and Dataframe\n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        \n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':logreg,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "        try:\n",
    "            # Generate a Balanced Variant of the Logistic Regression Where \n",
    "            perc_dist = len(df[df[Target]==0])/len(df)\n",
    "            if perc_dist>.6:\n",
    "                lr0=LogisticRegression(max_iter=log_max_it,class_weight='balanced')\n",
    "                lr0.fit(X_train, y_train)\n",
    "                y_pred_rf = lr0.predict(X_test)\n",
    "                result_df = pd.concat([pd.DataFrame(y_pred_rf,columns=['PREDICTION']),\n",
    "                                       pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "                feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                                   'IMPORTANCE':rf.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "                result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                               model='Logistic Regression - Balanced',\n",
    "                                                               scaler=scaler_,\n",
    "                                                               balance=balance_target_observations,\n",
    "                                                               sequence_num=SequenceNumber+1000000)\n",
    "                stop_time = timeit.default_timer() - start_time\n",
    "                performance['RunTime'] = stop_time\n",
    "                generated_models[SequenceNumber+1000000] = {'ModelType':'Logistic Regression - Balanced',\n",
    "                                                        'Model':lr0,\n",
    "                                                        'Scaler':scaler,\n",
    "                                                        'FeatureImportance':feature_importance,\n",
    "                                                        'BinaryResultDF':result_df,\n",
    "                                                        'ModelPerformance':performance}\n",
    "        except:\n",
    "            print('Attempted to Review Random Forrest - Balanced, could not')\n",
    "\n",
    "    elif model =='Decision Tree':    \n",
    "        ############################################ ESTIMATORS\n",
    "        dt = DecisionTreeClassifier(random_state=random_state)\n",
    "        dt.fit(X_train, y_train)\n",
    "        y_pred_dt = dt.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_dt,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':dt.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        \n",
    "        \n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':dt,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "\n",
    "    elif model =='Random Forest':    \n",
    "        ############################################ ESTIMATORS\n",
    "        rf = RandomForestClassifier(random_state=random_state, n_estimators=rf_estimators)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred_rf = rf.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_rf,columns=['PREDICTION']),\n",
    "                               pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':rf.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':rf,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "        try:\n",
    "            # Generate a Balanced Variant of the Random Forest Where \n",
    "            perc_dist = len(df[df[Target]==0])/len(df)\n",
    "            if perc_dist>.6:\n",
    "                rf0 = RandomForestClassifier(random_state=random_state, n_estimators=rf_estimators,class_weight='balanced')\n",
    "                rf0.fit(X_train, y_train)\n",
    "                y_pred_rf = rf0.predict(X_test)\n",
    "                result_df = pd.concat([pd.DataFrame(y_pred_rf,columns=['PREDICTION']),\n",
    "                                       pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "                feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                                   'IMPORTANCE':rf.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "                result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                               model='Random Forest - Balanced',\n",
    "                                                               scaler=scaler_,\n",
    "                                                               balance=balance_target_observations,\n",
    "                                                               sequence_num=SequenceNumber+1000000)\n",
    "                stop_time = timeit.default_timer() - start_time\n",
    "                performance['RunTime'] = stop_time\n",
    "                generated_models[SequenceNumber+1000000] = {'ModelType':'Random Forest - Balanced',\n",
    "                                                        'Model':rf0,\n",
    "                                                        'Scaler':scaler,\n",
    "                                                        'FeatureImportance':feature_importance,\n",
    "                                                        'BinaryResultDF':result_df,\n",
    "                                                        'ModelPerformance':performance}\n",
    "        except:\n",
    "            print('Attempted to Review Random Forrest - Balanced, could not')\n",
    "                \n",
    "    elif model == 'Gradient Boosting':\n",
    "        gb = GradientBoostingClassifier()\n",
    "        gb.fit(X_train, y_train)\n",
    "        y_pred_gb = gb.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_gb,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':gb.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':gb,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "    elif model == 'Ada':\n",
    "        ada = AdaBoostClassifier()\n",
    "        ada.fit(X_train, y_train)\n",
    "        y_pred_ada = ada.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_ada,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':ada.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':ada,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "    elif model == 'Extra Tree':\n",
    "        et = ExtraTreesClassifier()\n",
    "        et.fit(X_train, y_train)\n",
    "        y_pred_et = et.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_et,columns=['PREDICTION']),pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':et.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':et,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}\n",
    "        \n",
    "    elif model == 'XGBoost':\n",
    "        xgb_ = xgb.XGBClassifier(objective=xgb_objective,\n",
    "                                eval_metric=xgb_eval_metric,\n",
    "                                use_label_encoder=False,\n",
    "                                random_state=random_state)\n",
    "        xgb_.fit(X_train, y_train)\n",
    "        y_pred_et = xgb_.predict(X_test)\n",
    "        result_df = pd.concat([pd.DataFrame(y_pred_et,columns=['PREDICTION']),\n",
    "                               pd.DataFrame(y_test,columns=['ACTUAL'])],axis=1)\n",
    "        feature_importance = pd.DataFrame({'FEATURE':Features,\n",
    "                                           'IMPORTANCE':xgb_.feature_importances_}).sort_values(by='IMPORTANCE',ascending=False)\n",
    "        \n",
    "        result_df, performance = ClassificationMetrics(df=result_df,\n",
    "                                                       model=model,\n",
    "                                                       scaler=scaler_,\n",
    "                                                       balance=balance_target_observations,\n",
    "                                                       sequence_num=SequenceNumber)\n",
    "        stop_time = timeit.default_timer() - start_time\n",
    "        performance['RunTime'] = stop_time\n",
    "        \n",
    "        generated_models[SequenceNumber] = {'ModelType':model,\n",
    "                                            'Model':xgb,\n",
    "                                            'Scaler':scaler,\n",
    "                                            'FeatureImportance':feature_importance,\n",
    "                                            'BinaryResultDF':result_df,\n",
    "                                            'ModelPerformance':performance}    \n",
    "    else:\n",
    "        print('Model Not Defined, please update function')\n",
    "        \n",
    "    performance_metrics = pd.DataFrame()\n",
    "    for key in generated_models.keys():\n",
    "        performance_metrics = pd.concat([performance_metrics,generated_models[key]['ModelPerformance']])\n",
    "        \n",
    "    return generated_models,performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77931bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/ProcessSheet\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/DataDashboardSheet\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/CodingDDashboard\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/ML_Pipeline\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/Mapping Sheet\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/SKLearn Models\n",
      "Back Up Saved, /Users/derekdewald/Documents/Python/Github_Repo/CSV Backup Files/Notes\n",
      "Counld Not Print Record 7\n",
      "Counld Not Print Record 8\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c614ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SharedFolder import DuplicateFileorFolder\n",
    "# Create Backup of Github_Repo\n",
    "DuplicateFileorFolder('/Users/derekdewald/Documents/Python/Github_Repo/',\n",
    "                      '/Users/derekdewald/Documents/GitHub_Repo_BACKUP/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f84af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1afaff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71228ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_dataset(X,y,observations=0,column_name='BANKRUPTCY_FLAG'):\n",
    "    \n",
    "    '''\n",
    "    Function to take observations and labels, combine them together and then select a even numher of random examples\n",
    "    \n",
    "    X - X_Test or X_Training\n",
    "    y - y_test or y_training\n",
    "    observation - Number of records from both Binary On and Binary Off Column\n",
    "    column_name - Name of Binary Column to filter\n",
    "    \n",
    "    \n",
    "    Used Default Value for purposes of reducing typing in code and given function created for Project Exclusively.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # If length of observations is not defined, create a even 50/ 50 dataset\n",
    "    if observations == 0:\n",
    "        observations = y[column_name].sum()\n",
    "        \n",
    "    if observations>y[column_name].sum():\n",
    "        observations = y[column_name].sum()\n",
    "        \n",
    "    temp_df = pd.concat([X,y],axis=1).copy()\n",
    "    \n",
    "    df1 = temp_df[temp_df[column_name]==1].sample(observations).copy()\n",
    "    df2 = temp_df[temp_df[column_name]==0].sample(observations).copy()\n",
    "    \n",
    "    final_df = pd.concat([df1,df2])\n",
    "    final_df = final_df.sample(frac=1)\n",
    "    \n",
    "    X = final_df.drop(column_name,axis=1)\n",
    "    y = final_df[[column_name]]\n",
    "    \n",
    "    \n",
    "def train_neural_network(X,\n",
    "                y,\n",
    "                input_dim,\n",
    "                metrics,\n",
    "                hidden_layer_sizes,\n",
    "                activation, \n",
    "                optimizer,\n",
    "                learning_rate,\n",
    "                batch_size,\n",
    "                num_epochs,\n",
    "                validation_split,\n",
    "                verbose=0):\n",
    "                       \n",
    "\n",
    "    # Build the model.\n",
    "    model = build_binary_classification_model(input_dim=input_dim,\n",
    "                                              hidden_layer_sizes=hidden_layer_sizes,\n",
    "                                              activation=activation, \n",
    "                                              optimizer=optimizer,\n",
    "                                              learning_rate=learning_rate,\n",
    "                                              metrics=metrics)\n",
    "    \n",
    "    print(model.summary())     \n",
    "                        \n",
    "    # Train the model.\n",
    "    history = model.fit(x=X,\n",
    "                        y=y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=num_epochs,\n",
    "                        validation_split=validation_split,\n",
    "                        verbose=verbose)\n",
    "\n",
    "    # Retrieve the training metrics (after each train epoch) and the final test\n",
    "    # accuracy.\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(train_accuracy, label='train_accuracy')\n",
    "    plt.plot(val_accuracy, label='validation accuracy')\n",
    "    plt.xticks(range(num_epochs))\n",
    "    plt.xlabel('Train epochs')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    " \n",
    "    return history,model\n",
    "\n",
    "    \n",
    "def neural_network(X_df,\n",
    "                   y_df,\n",
    "                   input_dim, \n",
    "                   hidden_layer_sizes,\n",
    "                   activation,\n",
    "                   optimizer,\n",
    "                   learning_rate,\n",
    "                   metrics,\n",
    "                   verbose=0):\n",
    "\n",
    "    \"\"\"Build a binary classification model using Keras.\n",
    "\n",
    "      Args:\n",
    "        input_dim: Number of features in the input data.\n",
    "        hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "        activation: The activation function to use for the hidden layers.\n",
    "        optimizer: The optimizer\n",
    "        learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "      Returns:\n",
    "        model: A tf.keras model.\n",
    "    \"\"\"\n",
    "    # Instantiate Model\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    # Add Input Layer\n",
    "    model.add(layers.InputLayer(input_shape=(input_dim,)))\n",
    "\n",
    "    # Add Hidden Layers\n",
    "    for nodes in hidden_layer_sizes:\n",
    "        model.add(layers.Dense(units=nodes, activation=activation))\n",
    "\n",
    "    # Add Output Layer\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Configure optimizer and compile the model\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2d02a-01fd-46ec-971b-e5000d3af2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
